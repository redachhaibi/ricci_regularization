{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256 #was 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "#loss_fn = myloss2\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 5e-4 #0.001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 2\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "# Check if the GPU is available\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#print(f'Selected device: {device}')\n",
    "\n",
    "#Force CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc4fb70e",
   "metadata": {},
   "source": [
    "## Functions for the computation of the integral of the absolute value of scalar curvature: Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b549ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "def makegrid(encoded_data, numsteps):\n",
    "    latent = encoded_data\n",
    "    latent = latent.detach().cpu()\n",
    "    mean = latent.mean(dim=0)\n",
    "    #print(mean)\n",
    "    std = (latent - mean).pow(2).mean(dim=0).sqrt()\n",
    "    #print(std)\n",
    "    xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)\n",
    "    ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)\n",
    "    tgrid = torch.cartesian_prod(ys, xs)\n",
    "    tgrid = tgrid.roll(1,1)\n",
    "    return tgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric on a grid\n",
    "def g(grid, decoded_grid):\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    #latent = grid\n",
    "    #latent = latent.to(device)\n",
    "    #psi = decoder(latent)\n",
    "    psi = decoded_grid\n",
    "\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    \n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*hx)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*hy)\n",
    "    \n",
    "    metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    metric = metric.view(4, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simultaneous differentiation on a grid with torch.roll\n",
    "def diff_by_x(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*h)\n",
    "    return dpsidx\n",
    "def diff_by_y(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of the metric on a grid\n",
    "def dg_grid (grid, decoded_grid): #dg\n",
    "    \n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    #latent = grid\n",
    "    #latent = latent.to(device)\n",
    "    psi = decoded_grid\n",
    "    \n",
    "    dpsidx = diff_by_x(psi, numsteps, hx)\n",
    "    dpsidy = diff_by_x(psi, numsteps, hy)\n",
    "    dpsidx_second = diff_by_x(dpsidx, numsteps, hx)\n",
    "    dpsidx_dy = diff_by_y(dpsidx, numsteps, hy)\n",
    "    dpsidy_second = diff_by_y(dpsidy, numsteps, hy)\n",
    "    \n",
    "    #metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),\n",
    "    #                  (dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    \n",
    "    dgdx = torch.cat((2*(dpsidx*dpsidx_second).sum((1,2,3)),(dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),2*(dpsidy * dpsidx_dy).sum((1,2,3))),0)\n",
    "    dgdy = torch.cat((2*(dpsidx*dpsidx_dy).sum((1,2,3)),(dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),2*(dpsidy*dpsidy_second).sum((1,2,3))),0)\n",
    "    metric_der = torch.cat((dgdx, dgdy), 0)\n",
    "    metric = metric_der\n",
    "    metric = metric.view(8, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 4)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a459453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols on a grid\n",
    "def Ch_grid(grid, metric_inv, metric_der):\n",
    "    #x = grid[:,0]\n",
    "    #y = grid[:, 1]\n",
    "    n = grid.shape[0]\n",
    "    Ch = torch.zeros((n, 2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    #Ch^l_ij\n",
    "                    Ch[:,l,i,j] += 0.5 * metric_inv[:,l,k] * (metric_der[:,i,k,j] + metric_der[:,j,i,k] - metric_der[:,k,i,j])\n",
    "    return Ch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66138d4b",
   "metadata": {},
   "source": [
    "Derivatives of Christoffel symbols on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of Christoffel symbols on a grid\n",
    "def Ch_der_grid(grid, metric_inv, metric_der):\n",
    "    n = grid.shape[0]\n",
    "\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    Chdx = diff_by_x(Ch_grid(grid, metric_inv, metric_der), numsteps, hx)\n",
    "    Chdy = diff_by_y(Ch_grid(grid, metric_inv, metric_der), numsteps, hy)\n",
    "    Chder = torch.cat((Chdx, Chdy), -1)\n",
    "    Chder = Chder.view(n,2,2,2,2)\n",
    "    Chder = Chder.transpose(-1,-2)\n",
    "    return Chder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem(grid, metric_inv, metric_der):\n",
    "    n = grid.shape[0]\n",
    "    Ch_der = Ch_der_grid(grid, metric_inv, metric_der)\n",
    "    Ch = Ch_grid(grid, metric_inv, metric_der)\n",
    "\n",
    "    Riem = torch.zeros(n, 2, 2, 2, 2)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                for l in range(2):                    \n",
    "                    Riem[:, i, j, k, l] = Ch_der[:, i, l, j, k] - Ch_der[:, i, k, j, l] \n",
    "                    for p in range(2):\n",
    "                        Riem[:, i, j, k, l] += (Ch[:, i, k, p]*Ch[:, p, l, j] - Ch[:, i, l, p]*Ch[:, p, k, j])\n",
    "    return Riem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4409e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricci curvature tensor via Riemann\n",
    "# R_ab = Riem^c_acb\n",
    "# This function is written in a suboptimal way but we dl not use it here\n",
    "def Ric(grid, metric_inv, metric_der):\n",
    "    n = grid.shape[0]\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riem(grid, metric_inv, metric_der)[:, c, a, c, b]\n",
    "    return Ric\n",
    "    # takes 2.5 secs on 100 by 100 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar curvature tensor via Riemann and Ricci\n",
    "# R_ab = Riem^c_acb\n",
    "# R = g^ij * R_ij\n",
    "def Sc(grid, metric_inv, metric_der):\n",
    "    n = grid.shape[0]\n",
    "    Riemann = Riem(grid, metric_inv, metric_der)\n",
    "\n",
    "    Sc = torch.zeros(n)\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riemann[:, c, a, c, b]\n",
    "    #einsum!!\n",
    "    Sc = metric_inv*Ric\n",
    "    Sc = torch.sum(Sc,(1,2))\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curvature measuring functional\n",
    "    \n",
    "def Func(encoded_data):\n",
    "    \n",
    "    numsteps = 30 # grid of size numsteps x numsteps\n",
    "    grid = makegrid(encoded_data, numsteps)\n",
    "\n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    #computeing metric and its derivatives on the grid\n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    decoded_grid = decoder(latent)\n",
    "    \n",
    "    metric = g(grid, decoded_grid)\n",
    "    metric_der = dg_grid(grid, decoded_grid)\n",
    "    #with torch.no_grad():\n",
    "        #metric = g(grid).cpu()\n",
    "        #metric_der = dg_grid(grid).cpu()\n",
    "    metric_inv = torch.inverse(metric.cpu()) #this is the inverse of the metric on the grid\n",
    "\n",
    "    #Frobenius norm on the metric without border\n",
    "\n",
    "    Newfrob = metric.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "    Newfrob = Newfrob[2:-2,2:-2].transpose(0,1)\n",
    "\n",
    "    Scalar_curvature_grid = Sc(grid, metric_inv, metric_der)\n",
    "\n",
    "    Scalar_curv = Scalar_curvature_grid.view(numsteps,numsteps) #reshaping\n",
    "    Scalar_curv = Scalar_curv[2:-2,2:-2].transpose(0,1) #avoiding border effects\n",
    "\n",
    "    #F_simp = (abs(Scalar_curv)*hx*hy).sum() #integrating\n",
    "\n",
    "    metric_no_border = metric.reshape(numsteps, numsteps,2,2)[2:-2,2:-2]\n",
    "    det_metric_no_border = torch.det(metric_no_border.cpu())\n",
    "    det_sqrt = torch.sqrt(det_metric_no_border)\n",
    "\n",
    "    #F_new = (det_sqrt*torch.abs(Scalar_curv)*hx*hy).sum()\n",
    "    #F_new = (det_sqrt*Newfrob*hx*hy).sum()\n",
    "\n",
    "    F_new = (det_sqrt*torch.abs(Scalar_curv**2)*hx*hy).sum()\n",
    "\n",
    "    return F_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building my loss function\n",
    "def myloss(decoded_data, image_batch):\n",
    "    oldloss = torch.nn.MSELoss()\n",
    "    #curv_w = 0.0001 #initially 0.0001\n",
    "\n",
    "    image_batch = image_batch.to(device)\n",
    "    encoded_data = encoder(image_batch)\n",
    "\n",
    "    newloss = Func(encoded_data)\n",
    "\n",
    "    #myloss = oldloss(decoded_data, image_batch) + curv_w * newloss\n",
    "    myloss = oldloss(decoded_data, image_batch)\n",
    "    return myloss\n",
    "\n",
    "### Define the loss function\n",
    "loss_fn = myloss\n",
    "#loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b22359",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "mseloss = torch.nn.MSELoss()\n",
    "\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    mse_loss = []\n",
    "    \n",
    "    batch_idx = 0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "\n",
    "        #if batch_idx % 10 == 5:\n",
    "        #    Curvature_functional = Func(encoded_data)\n",
    "        #    loss = loss_fn(decoded_data, image_batch) + Curvature_functional\n",
    "        #else:\n",
    "        #    loss = loss_fn(decoded_data, image_batch)         \n",
    "        #loss = loss_fn(decoded_data, image_batch) + 0.1*F(encoded_data) #changed!!\n",
    "\n",
    "        #loss = loss_fn(decoded_data, image_batch) + 0.005*Func(encoded_data) #changed!!\n",
    "\n",
    "        #loss = loss_fn(decoded_data, image_batch) + Func(encoded_data) #changed!!\n",
    "\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "\n",
    "        only_mse = mseloss(decoded_data, image_batch)\n",
    "\n",
    "        new_loss = loss.data - only_mse.data\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        #print(batch_idx)\n",
    "\n",
    "        print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "        \n",
    "        train_loss.append(float(loss.detach().cpu().numpy()))\n",
    "        mse_loss.append(float(only_mse.detach().cpu().numpy()))\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    #return np.mean(train_loss), np.mean(mse_loss) \n",
    "    return train_loss, mse_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches per epoch\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_dataset[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         rec_img  = decoder(encoder(img))\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manifold plot\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "def make_manifold_plot(encoded_data, size):\n",
    "    mygrid = makegrid(encoded_data, size)\n",
    "    latent1 = mygrid\n",
    "    latent1 = latent1.to(device)\n",
    "    result = decoder(latent1).cpu().detach()\n",
    "    fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    show_image(torchvision.utils.make_grid(result[:100],10,5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "#diz_loss = {'train_loss':[],'val_loss':[]}\n",
    "diz_loss = {'train_loss':[],'mse_loss':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   #train_loss =train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "   #train_loss = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)[0]\n",
    "   #mse_loss = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)[1]\n",
    "   #train_loss, mse_loss = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "   train_info = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "   #val_loss = test_epoch(encoder,decoder,device,test_loader,loss_fn)\n",
    "\n",
    "   with torch.no_grad():\n",
    "    # calculate mean and std of latent code, generated takining in test images as inputs \n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    latent = encoder(images)\n",
    "    latent = latent.cpu()\n",
    "   #curv_func = Func(latent)\n",
    "   train_loss = np.mean(train_info[0])\n",
    "   curv_func = np.mean(train_info[0]) - np.mean(train_info[1]) # train_loss - mse_loss = curv_loss\n",
    "\n",
    "   #print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {} \\t curvature {}'.format(epoch + 1, num_epochs,train_loss,val_loss, curv_func))\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t Curvature {}'.format(epoch + 1, num_epochs,train_loss, curv_func))\n",
    "   diz_loss['train_loss'].append(train_info[0])\n",
    "   diz_loss['mse_loss'].append(train_info[1])\n",
    "   #diz_loss['val_loss'].append(val_loss)\n",
    "   plot_ae_outputs(encoder,decoder,n=10)\n",
    "   make_manifold_plot(latent, 10)\n",
    "diz_loss['train_loss'] = np.array(diz_loss['train_loss']).flatten()\n",
    "diz_loss['mse_loss'] = np.array(diz_loss['mse_loss']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20665126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses per batch\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_loss['train_loss'], label='Train_loss')\n",
    "plt.semilogy(diz_loss['train_loss'] - diz_loss['mse_loss'], label='Curv_loss')\n",
    "plt.title('Losses with weight 0.00001')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "#plt.title('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from latnt code and visualize them. It is not a latent space. Just some samples.\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # calculate mean and std of latent code, generated takining in test images as inputs \n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    latent = encoder(images)\n",
    "    latent = latent.cpu()\n",
    "\n",
    "    mean = latent.mean(dim=0)\n",
    "    print(mean)\n",
    "    std = (latent - mean).pow(2).mean(dim=0).sqrt()\n",
    "    print(std)\n",
    "\n",
    "    # sample latent vectors from the normal distribution\n",
    "    latent = torch.randn(128, d)*std + mean\n",
    "    #print(latent)\n",
    "    #print(latent.shape)\n",
    "\n",
    "    # reconstruct images from the random latent vectors\n",
    "    latent = latent.to(device)\n",
    "    img_recon = decoder(latent)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    show_image(torchvision.utils.make_grid(img_recon[:100],10,5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "PATH_enc = 'encoder_curw_w=0.0001_5epochs_30x30grid.pt'\n",
    "torch.save(encoder.state_dict(), PATH_enc)\n",
    "PATH_dec = 'decoder_curw_w=0.0001_5epochs_30x30grid.pt'\n",
    "torch.save(decoder.state_dict(), PATH_dec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84c91903",
   "metadata": {},
   "source": [
    "# Point plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b921ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf3f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples.label.astype(str), opacity=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
