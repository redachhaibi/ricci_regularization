{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! this is an old notebook!\n",
    "\n",
    "This notebook explores Scalar curvature computation with jacfwd - a PyTorch forward-propagation tool (See torch.func.jacfwd at https://pytorch.org/functorch/stable/generated/functorch.jacfwd.html).\n",
    "\n",
    "The AE consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation*}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi \\ .\n",
    "\\end{equation*}\n",
    "\n",
    "In detail this notebook consists of:\n",
    "\n",
    "0) Loading weights of the decoder $\\Psi$ (its architecture is set in this notebook) of a pre-trained convolutional AE.\n",
    "1) Auxillary tensors involving higher order derivatives are computed with jacfwd: metric $g$ and its derivatives, Riemann tensor $R^{i}_{jkl}$, Ricci tensor $R_{ij}$ and scalar curvature.\n",
    "2) The ground truth is checked on several examples (Einstein metrics): sphere and Lobachevskiy (Hyperbolic) plane. \n",
    "3) Computational time for scalar curvature computation is demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Imports and some functions for plotting (Skip reading this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "device = torch.device(\"cpu\")\n",
    "import torch\n",
    "import torch.func as TF\n",
    "from functorch import jacrev,jacfwd\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "decoder = Decoder(encoded_space_dim = 2,fc2_input_dim=128)\n",
    "\n",
    "# Send to device\n",
    "decoder.to(device) \n",
    "\n",
    "# Load the parameters of the trained decoder without curvature in Loss func\n",
    "PATH_dec = '../nn_weights/decoder_conv_autoenc.pt'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "\n",
    "# Switch to eval mode\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(numsteps, xshift = 0.0, yshift = 0.0):\n",
    "    \n",
    "    xs = torch.linspace(-1.5, 1.5, steps = numsteps) + xshift\n",
    "    ys = torch.linspace(-1.5, 1.5, steps = numsteps) + yshift\n",
    "    #uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "    # true grid starts from left bottom corner. x is the first to increase\n",
    "    tgrid = torch.cartesian_prod(ys, xs)\n",
    "    tgrid = tgrid.roll(1,1)\n",
    "    return tgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frob_norm_tensor_on_grid(plot_name,tensor_on_grid, numsteps = 100,xshift = 0.0, yshift = 0.0):\n",
    "    Frob_norm_on_grid = tensor_on_grid.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "    #Frob_norm_on_grid = metric_on_grid.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "    Frob_norm_on_grid = Frob_norm_on_grid[1:-1,1:-1].detach()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(Frob_norm_on_grid,origin=\"lower\")\n",
    "\n",
    "    cbar = ax.figure.colorbar(im)\n",
    "    \n",
    "    ax.set_xticks((Frob_norm_on_grid.shape[0]-1)*(np.linspace(0,1,num=11)),labels=(np.linspace(-1.5,1.5,num=11)+xshift).round(1))\n",
    "    ax.set_yticks((Frob_norm_on_grid.shape[1]-1)*(np.linspace(0,1,num=11)),labels=(np.linspace(-1.5,1.5,num=11)+yshift).round(1))\n",
    "    plt.xlabel( \"x coordinate\")\n",
    "    plt.ylabel( \"y coordinate\")\n",
    "    plt.axis('scaled')\n",
    "\n",
    "    ax.set_title(plot_name)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Tensors computed with higher order derivatives using jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_jacfwd(u, function = decoder, latent_space_dim=2):\n",
    "    u = u.reshape(-1,latent_space_dim)\n",
    "    jac = jacfwd(function)(u)\n",
    "    jac = jac.reshape(-1,latent_space_dim)\n",
    "    metric = torch.matmul(jac.T,jac)\n",
    "    return metric\n",
    "\n",
    "metric_jacfwd_vmap = TF.vmap(metric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable wrt which \n",
    "# the derivative is computed is the last index\n",
    "def metric_der_jacfwd (u, function = decoder):\n",
    "    metric = functools.partial(metric_jacfwd, function=function)\n",
    "    dg = jacfwd(metric)(u).squeeze()\n",
    "    # squeezing is needed to get rid of 1-dimentions \n",
    "    # occuring when using jacfwd\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Gamma^\\rho_{\\mu\\nu} = \\frac{1}{2} g^{\\rho\\sigma}\\left(\\partial_\\mu g_{\\sigma\\nu} + \\partial_\\nu g_{\\mu\\sigma} - \\partial_\\sigma g_{\\mu\\nu}\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ch_jacfwd (u, function = decoder):\n",
    "    g = metric_jacfwd(u,function)\n",
    "    g_inv = torch.inverse(g)\n",
    "    dg = metric_der_jacfwd(u,function)\n",
    "    Ch = 0.5*(torch.einsum('im,mkl->ikl',g_inv,dg)+\n",
    "              torch.einsum('im,mlk->ikl',g_inv,dg)-\n",
    "              torch.einsum('im,klm->ikl',g_inv,dg)\n",
    "              )\n",
    "    return Ch\n",
    "Ch_jacfwd_vmap = TF.vmap(Ch_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ch_der_jacfwd (u, function = decoder):\n",
    "    Ch = functools.partial(Ch_jacfwd, function=function)\n",
    "    dCh = jacfwd(Ch)(u).squeeze()\n",
    "    return dCh\n",
    "Ch_der_jacfwd_vmap = TF.vmap(Ch_der_jacfwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^{\\rho}_{\\sigma\\mu\\nu} = \\partial_{\\mu}\\Gamma^{\\rho}_{\\nu\\sigma} - \\partial_{\\nu}\\Gamma^{\\rho}_{\\mu\\sigma} + \\Gamma^{\\rho}_{\\mu\\lambda}\\Gamma^{\\lambda}_{\\nu\\sigma} - \\Gamma^{\\rho}_{\\nu\\lambda}\\Gamma^{\\lambda}_{\\mu\\sigma}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem_jacfwd(u, function = decoder):\n",
    "    Ch = Ch_jacfwd(u, function)\n",
    "    Ch_der = Ch_der_jacfwd(u, function)\n",
    "\n",
    "    Riem = torch.einsum(\"iljk->ijkl\",Ch_der) - torch.einsum(\"ikjl->ijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"ikp,plj->ijkl\", Ch, Ch) - torch.einsum(\"ilp,pkj->ijkl\", Ch, Ch)\n",
    "    return Riem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R_{\\mu\\nu} = R^{\\rho}_{\\mu\\rho\\nu}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ric_jacfwd(u, function = decoder):\n",
    "    Riemann = Riem_jacfwd(u, function)\n",
    "    Ric = torch.einsum(\"cacb->ab\",Riemann)\n",
    "    return Ric\n",
    "Ric_jacfwd_vmap = TF.vmap(Ric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "Ric_jacfwd_vmap(torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Ground truth check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric generating functions\n",
    "# u = (\\theta, \\phi)\n",
    "# ds^2 = (d\\theta)^2 + sin^2(\\theta)*(d\\phi)^2\n",
    "def my_fun_sphere(u):\n",
    "    u = u.flatten()\n",
    "    \n",
    "    x = torch.sin(u[0])*torch.cos(u[1])\n",
    "    y = torch.sin(u[0])*torch.sin(u[1])\n",
    "    z = torch.cos(u[0])\n",
    "\n",
    "    x = x.unsqueeze(0)\n",
    "    y = y.unsqueeze(0)\n",
    "    z = z.unsqueeze(0)\n",
    "    output = torch.cat((x, y, z),dim=-1)\n",
    "    output = torch.cat((output.unsqueeze(0),torch.zeros(781).unsqueeze(0)),dim=1)\n",
    "    output = output.flatten()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric tensor and ricci tensor ground truth\n",
    "# ds^2 = (d\\theta)^2 + sin^2(\\theta)*(d\\phi)^2\n",
    "def metric_sphere(u):\n",
    "    u = u.flatten()\n",
    "    #print(\"\\n\", u.dtype)\n",
    "    theta = u[0]\n",
    "    phi = u[1]\n",
    "    #metric_tensor = torch.diag(torch.tensor([1.0,0.0])) + torch.diag(torch.Tensor([0.0,1.0]))*(torch.sin(theta))**2\n",
    "    E_11 = torch.diag(torch.tensor([1.0,0.0],dtype=float))\n",
    "    E_22 = torch.diag(torch.tensor([0.0,1.0],dtype=float))\n",
    "    \n",
    "    metric_tensor = E_11 + E_22*(torch.sin(theta))**2\n",
    "    #print(\"\\n\", metric_tensor.dtype)\n",
    "    return metric_tensor \n",
    "metric_sphere_vmap = TF.vmap(metric_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(2,2,dtype=float)\n",
    "metric_jacfwd_example = metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere)\n",
    "Ricci_jacfwd_example = Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere)\n",
    "metric_exact_example = metric_sphere_vmap(test_batch)\n",
    "print(\"metric via jacfwd:\\n\", metric_jacfwd_example)\n",
    "print(\"Ricci via jacfwd:\\n\", Ricci_jacfwd_example)\n",
    "print(\"metric via exact formula:\\n\", metric_exact_example)\n",
    "print(\"Absolute error for metric:\\n\", metric_jacfwd_example - metric_exact_example)\n",
    "print(\"Absolute error for Ricci:\\n\", Ricci_jacfwd_example - metric_exact_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify metric \n",
    "# tensor computation for a 2 dimentional sphere of radius 1\n",
    "torch.manual_seed(10)\n",
    "\n",
    "#test_batch = torch.rand(1000,2)\n",
    "test_batch = torch.rand(1000,2,dtype=float)+torch.tensor([0.1,0.0])\n",
    "#test_batch.to(torch.float64)\n",
    "\n",
    "#test_batch = torch.rand(1000,2) @ torch.diag( torch.tensor( [torch.pi, 2*torch.pi] ) )\n",
    "# Capping\n",
    "#test_batch[:,0]   = 0.1 + 0.8*test_batch[:,0]\n",
    "test_metric_jacfwd_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "test_metric_exact_array = metric_sphere_vmap(test_batch)\n",
    "\n",
    "# here we check the error in exact metric computation and jacfwd\n",
    "absolute_error = (test_metric_jacfwd_array - test_metric_exact_array).norm(dim=(1,2))\n",
    "#relative_error = 100*(test_metric_jacfwd_array - test_metric_exact_array/test_metric_exact_array).norm(dim=(1,2))\n",
    "\n",
    "array_of_determinants = torch.det(test_metric_exact_array)\n",
    "\n",
    "print(\"array of metric determinants:\\n mean\", array_of_determinants.mean(),\n",
    "      \"\\n max\",array_of_determinants.max(),\n",
    "      \"\\n min\", array_of_determinants.min())\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)\n",
    "plt.title(\"Histogram of frobenius norm of absolute error for metric tensor for a sphere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = k*g,with k = n-1 for an \n",
    "# n-dimentional sphere S^n. Thus if n = 2, Ric = g\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = torch.rand(1000,2, dtype=torch.float64)+torch.tensor([0.1,0.0])\n",
    "\n",
    "#test_batch = torch.rand(1000,2) @ torch.diag( torch.tensor( [torch.pi, 2*torch.pi] ) )\n",
    "# Capping\n",
    "#test_batch[:,0]   = 0.1 + 0.8*test_batch[:,0]\n",
    "test_Ricci_jacfwd_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "test_metric_exact_array = metric_sphere_vmap(test_batch)\n",
    "\n",
    "# here we check the error in exact metric computation and jacfwd\n",
    "absolute_error = (test_Ricci_jacfwd_array - test_metric_exact_array).norm(dim=(1,2))\n",
    "\n",
    "array_of_determinants = torch.det(test_metric_exact_array)\n",
    "\n",
    "print(\"array of metric determinants:\\n mean\", array_of_determinants.mean(),\n",
    "      \"\\n max\",array_of_determinants.max(),\n",
    "      \"\\n min\", array_of_determinants.min())\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)\n",
    "plt.title(\"Histogram of frobenius norm of absolute error for Ricci tensor for a sphere\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lobachevsky plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial embedding (valid for y>c) of Lobachevsky plane to R^3 \n",
    "# (formally here it is R^784)\n",
    "# ds^2 = 1/y^2(dx^2 + dy^2)\n",
    "# http://www.antoinebourget.org/maths/2018/08/08/embedding-hyperbolic-plane.html\n",
    "def my_fun_lobachevsky(u, c = torch.tensor(0.01,dtype=torch.float64)):\n",
    "    #cnew=torch.tensor(0.01,dtype=torch.float64)\n",
    "    u = u.flatten()\n",
    "    x = u[0]\n",
    "    y = u[1]\n",
    "    #print(\" x and y shapes:\", x, cnew)\n",
    "    #print(\"{:.20f}\".format(c))\n",
    "    t = torch.acosh(y/c)\n",
    "    x0 = t - torch.tanh(t)\n",
    "    x1 = (1/torch.sinh(t))*torch.cos(x/c)\n",
    "    x2 = (1/torch.sinh(t))*torch.sin(x/c)\n",
    "    output = torch.cat((x0.unsqueeze(0),x1.unsqueeze(0),x2.unsqueeze(0)),dim=-1)\n",
    "    #output = torch.cat((output.unsqueeze(0),torch.zeros(781).unsqueeze(0)),dim=1)\n",
    "    output = output.flatten()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric tensor and ricci tensor ground truth\n",
    "# ds^2 = \\frac{dx^2 + dy^2}{y^2}\n",
    "def metric_lobachevsky(u):\n",
    "    u = u.flatten()\n",
    "\n",
    "    #x = u[0]\n",
    "    y = u[1]\n",
    "\n",
    "    E= torch.eye(2,dtype=torch.float64)\n",
    "    \n",
    "    metric_tensor = E*(1/y**2)\n",
    "    return metric_tensor\n",
    "metric_lobachevsky_vmap = TF.vmap(metric_lobachevsky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.set_printoptions(precision=16)\n",
    "\n",
    "\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(2,2,dtype=float)+torch.tensor([0.0,0.5],dtype=torch.float64)\n",
    "\n",
    "metric_jacfwd_example = metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky)\n",
    "Ricci_jacfwd_example = Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky)\n",
    "metric_exact_example = metric_lobachevsky_vmap(test_batch)\n",
    "\n",
    "\n",
    "print(\"metric via jacfwd:\\n\", metric_jacfwd_example)\n",
    "print(\"Ricci via jacfwd:\\n\", Ricci_jacfwd_example)\n",
    "print(\"metric via exact formula:\\n\", metric_exact_example)\n",
    "print(\"Absolute error for metric:\\n\", metric_jacfwd_example - metric_exact_example)\n",
    "print(\"Absolute error for Ricci:\\n\", Ricci_jacfwd_example + metric_exact_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify metric \n",
    "# tensor computation for hyperbolic plane\n",
    "torch.manual_seed(10)\n",
    "\n",
    "#test_batch = torch.rand(1000,2)\n",
    "test_batch = torch.rand(1000,2,dtype=float)+torch.tensor([0.0,1.0],dtype=torch.float64)\n",
    "\n",
    "#test_batch = torch.rand(1000,2) @ torch.diag( torch.tensor( [torch.pi, 2*torch.pi] ) )\n",
    "# Capping\n",
    "#test_batch[:,0]   = 0.1 + 0.8*test_batch[:,0]\n",
    "test_metric_jacfwd_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "test_metric_exact_array = metric_lobachevsky_vmap(test_batch)\n",
    "\n",
    "# here we check the error in exact metric computation and jacfwd\n",
    "absolute_error = (test_metric_jacfwd_array - test_metric_exact_array).norm(dim=(1,2))\n",
    "\n",
    "\n",
    "array_of_determinants = torch.det(test_metric_exact_array)\n",
    "array_of_frobenius_norm = torch.norm(test_metric_exact_array, dim=(1,2))\n",
    "\n",
    "print(\"array of metric determinants:\\n mean\", array_of_determinants.mean(),\n",
    "      \"\\n max\",array_of_determinants.max(),\n",
    "      \"\\n min\", array_of_determinants.min())\n",
    "\n",
    "print(\"array of metric frobenius norms:\\n mean\", array_of_frobenius_norm.mean(),\n",
    "      \"\\n max\",array_of_frobenius_norm.max(),\n",
    "      \"\\n min\", array_of_frobenius_norm.min())\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)\n",
    "plt.title(\"Histogram of frobenius norm of absolute error for metric tensor for the hyperbolic plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = -g for a 2-dimentional hyperbolic plane\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = torch.rand(1000,2, dtype=torch.float64)+torch.tensor([0.0,1.0],dtype=torch.float64)\n",
    "\n",
    "test_Ricci_jacfwd_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "test_metric_exact_array = metric_lobachevsky_vmap(test_batch)\n",
    "\n",
    "# here we check the error in exact metric computation and jacfwd\n",
    "absolute_error = (test_Ricci_jacfwd_array + test_metric_exact_array).norm(dim=(1,2))\n",
    "\n",
    "array_of_determinants = torch.det(test_metric_exact_array)\n",
    "array_of_frobenius_norm = torch.norm(test_metric_exact_array, dim=(1,2))\n",
    "\n",
    "print(\"array of metric determinants:\\n mean\", array_of_determinants.mean(),\n",
    "      \"\\n max\",array_of_determinants.max(),\n",
    "      \"\\n min\", array_of_determinants.min())\n",
    "\n",
    "print(\"array of metric frobenius norms:\\n mean\", array_of_frobenius_norm.mean(),\n",
    "      \"\\n max\",array_of_frobenius_norm.max(),\n",
    "      \"\\n min\", array_of_frobenius_norm.min())\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)\n",
    "plt.title(\"Histogram of frobenius norm of absolute error for Ricci tensor for the hyperbolic plane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Comparing metric and Ricci tensors for Einstein metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(3,2)\n",
    "print(\"metric:\\n\", metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere))\n",
    "print(\"Ricci tensor:\\n\", Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = k*g,with k = n-1 for an \n",
    "# n-dimentional sphere S^n. Thus if n = 2, Ric = g\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = torch.rand(1000,2, dtype=torch.float64)+0.1\n",
    "#@ torch.diag( torch.tensor( [torch.pi, 2*torch.pi] ) )\n",
    "# Capping\n",
    "#test_batch[:,0]   = 0.1 + 0.8*test_batch[:,0]\n",
    "test_metric_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "test_Ric_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "\n",
    "# here we check if g = Ric\n",
    "absolute_error = (test_metric_array - test_Ric_array).norm(dim=(1,2))\n",
    "relative_error = 100*absolute_error/(test_metric_array.norm(dim=(1,2)))\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "print( \"Relative error:\")\n",
    "print( relative_error.mean(), relative_error.max() )\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare frobenius norm heatmaps of the metric \n",
    "# and the Ricci tensor. For the sphere they should coincide\n",
    "numsteps = 100\n",
    "tgrid = make_grid(numsteps)\n",
    "Ric_on_grid = Ric_jacfwd_vmap(tgrid, function=my_fun_sphere)\n",
    "metric_on_grid = metric_jacfwd_vmap(tgrid, function=my_fun_sphere)\n",
    "\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Frobenius norm of the metric',\n",
    "                              tensor_on_grid= metric_on_grid, \n",
    "                              numsteps=numsteps)\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid= Ric_on_grid, \n",
    "                              numsteps=numsteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lobachevsky plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(3,2)\n",
    "print(\"metric:\\n\", metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky))\n",
    "print(\"Ricci tensor:\\n\", Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = k*g,with k = -1 \n",
    "# for the Lobachevsky plane. Thus if Ric = -g\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = 10*torch.rand(1000,2,dtype=torch.float64) + 0.5 \n",
    "# we use shift because y>0 for this model\n",
    "\n",
    "test_metric_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "test_Ric_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "\n",
    "# here we check if g = - Ric\n",
    "absolute_error = (test_metric_array + test_Ric_array).norm(dim=(1,2))\n",
    "relative_error = 100*absolute_error/(test_metric_array.norm(dim=(1,2)))\n",
    "\n",
    "print( \"Shapes:\")\n",
    "print( absolute_error.shape )\n",
    "print( \"Absolute error:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "print( \"Relative error:\")\n",
    "print( relative_error.mean(), relative_error.max() )\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(absolute_error,bins=10,density=False,stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare frobenius norm heatmaps of the metric \n",
    "# and the Ricci tensor. For the Lobachevsky plane they should coincide\n",
    "numsteps = 100\n",
    "tgrid = make_grid(numsteps, xshift=0.0, yshift=1.7)\n",
    "\n",
    "lobachevsky_metric_on_grid = metric_jacfwd_vmap(tgrid, function=my_fun_lobachevsky)\n",
    "lobachevsky_Ric_on_grid = Ric_jacfwd_vmap(tgrid, function=my_fun_lobachevsky)\n",
    "\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Lobachevsky plane: Frobenius norm of the metric',\n",
    "                              tensor_on_grid=lobachevsky_metric_on_grid,\n",
    "                            numsteps= numsteps, xshift=0.0, yshift=1.7)\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Lobachevsky plane: Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid=lobachevsky_Ric_on_grid,\n",
    "                            numsteps= numsteps, xshift=0.0, yshift=1.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. The Ricci tensor for the metric given by the pullback of the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes around 17 secs\n",
    "numsteps = 100\n",
    "grid = make_grid(numsteps)\n",
    "Decoder_Ric_on_grid = Ric_jacfwd_vmap(grid,function=decoder)\n",
    "draw_frob_norm_tensor_on_grid(plot_name='Latent space: Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid=Decoder_Ric_on_grid,\n",
    "                              numsteps=numsteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Newton method convergence etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5.0\n",
    "n = 1000000\n",
    "# Ground truth\n",
    "y = np.exp(x)\n",
    "print( y )\n",
    "# Approx\n",
    "z = (1+x/n)**n\n",
    "print( z )\n",
    "print( \"Error: \", y-z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth \n",
    "y = np.sqrt(x)\n",
    "print( \"Ground truth \")\n",
    "print( y )\n",
    "# Approx via Newton-Raphson\n",
    "z = x\n",
    "for i in range(7):\n",
    "    print( \"\" )\n",
    "    #print( \"Iteration \", i)\n",
    "    z = 0.5*( z + x/z )\n",
    "    print( z )\n",
    "    print( \"Error: \", y-z) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Understanding how precision works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.rand(10)\n",
    "h = 0.0001\n",
    "\n",
    "cos_fd = lambda x: (torch.sin(x+h)-torch.sin(x))/h\n",
    "\n",
    "cos_jacfwd = jacfwd(torch.sin)\n",
    "cos_jacfwd_vmap = TF.vmap(cos_jacfwd)\n",
    "\n",
    "result_jacfwd = cos_jacfwd_vmap(test_tensor)\n",
    "result_fd = cos_fd(test_tensor)\n",
    "result_exact = torch.cos(test_tensor)\n",
    "\n",
    "absolute_error = result_fd-result_exact\n",
    "\n",
    "relative_error = 100*absolute_error/result_exact\n",
    "\n",
    "print( \"Absolute error fd vs exact:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "print( \"Relative error fd vs exact:\")\n",
    "print( relative_error.mean(), relative_error.max() )\n",
    "\n",
    "\n",
    "absolute_error = result_jacfwd-result_exact\n",
    "\n",
    "relative_error = 100*absolute_error/result_exact\n",
    "\n",
    "print( \"Absolute error jacfwd vs exact:\")\n",
    "print( absolute_error.mean(), absolute_error.max() )\n",
    "print( \"Relative error jacfwd vs exact:\")\n",
    "print( relative_error.mean(), relative_error.max() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex = torch.tensor([1e-6])\n",
    "# float32 by default\n",
    "ex = torch.tensor([1e-6],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex*=0.1\n",
    "print(ex)\n",
    "print(\"{:.20f}\".format(float(ex)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Timing Scalar curvature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization as RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "times_to_repeat = 10\n",
    "grid_linear_size = 100\n",
    "time = timeit.timeit(stmt=\"RR.Sc_jacfwd_vmap(RR.make_grid(grid_linear_size),function=decoder)\",\n",
    "                                      number = times_to_repeat, globals=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"It takes\", time/times_to_repeat, \"seconds to compute\")\n",
    "print(\"Scalar curvature for a grid of linear size:\", grid_linear_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
