{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Imports and some functions for plotting (Skip reading this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "device = torch.device(\"cpu\")\n",
    "import torch\n",
    "import torch.func as TF\n",
    "from functorch import jacrev,jacfwd\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "decoder = Decoder(encoded_space_dim = 2,fc2_input_dim=128)\n",
    "\n",
    "# Send to device\n",
    "decoder.to(device) \n",
    "\n",
    "# Load the parameters of the trained decoder without curvature in Loss func\n",
    "PATH_dec = '../nn_weights/decoder_conv_autoenc.pt'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "\n",
    "# Switch to eval mode\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid(numsteps, xshift = 0.0, yshift = 0.0):\n",
    "    \n",
    "    xs = torch.linspace(-1.5, 1.5, steps = numsteps) + xshift\n",
    "    ys = torch.linspace(-1.5, 1.5, steps = numsteps) + yshift\n",
    "    #uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "    # true grid starts from left bottom corner. x is the first to increase\n",
    "    tgrid = torch.cartesian_prod(ys, xs)\n",
    "    tgrid = tgrid.roll(1,1)\n",
    "    return tgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frob_norm_tensor_on_grid(plot_name,tensor_on_grid, numsteps = 100,xshift = 0.0, yshift = 0.0):\n",
    "    Frob_norm_on_grid = tensor_on_grid.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "    #Frob_norm_on_grid = metric_on_grid.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "    Frob_norm_on_grid = Frob_norm_on_grid[1:-1,1:-1].detach()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(Frob_norm_on_grid,origin=\"lower\")\n",
    "\n",
    "    cbar = ax.figure.colorbar(im)\n",
    "    \n",
    "    ax.set_xticks((Frob_norm_on_grid.shape[0]-1)*(np.linspace(0,1,num=11)),labels=(np.linspace(-1.5,1.5,num=11)+xshift).round(1))\n",
    "    ax.set_yticks((Frob_norm_on_grid.shape[1]-1)*(np.linspace(0,1,num=11)),labels=(np.linspace(-1.5,1.5,num=11)+yshift).round(1))\n",
    "    plt.xlabel( \"x coordinate\")\n",
    "    plt.ylabel( \"y coordinate\")\n",
    "    plt.axis('scaled')\n",
    "\n",
    "    ax.set_title(plot_name)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Tensors computed with higher order derivatives using jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_jacfwd(u, function = decoder, latent_space_dim=2):\n",
    "    u = u.reshape(-1,latent_space_dim)\n",
    "    jac = jacfwd(function)(u)\n",
    "    jac = jac.reshape(-1,latent_space_dim)\n",
    "    metric = torch.matmul(jac.T,jac)\n",
    "    return metric\n",
    "\n",
    "metric_jacfwd_vmap = TF.vmap(metric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable wrt which \n",
    "# the derivative is computed is the last index\n",
    "def metric_der_jacfwd (u, function = decoder):\n",
    "    metric = functools.partial(metric_jacfwd, function=function)\n",
    "    dg = jacfwd(metric)(u).squeeze()\n",
    "    # squeezing is needed to get rid of 1-dimentions \n",
    "    # occuring when using jacfwd\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ch_jacfwd (u, function = decoder):\n",
    "    g = metric_jacfwd(u,function)\n",
    "    g_inv = torch.inverse(g)\n",
    "    dg = metric_der_jacfwd(u,function)\n",
    "    Ch = 0.5*(torch.einsum('im,mkl->ikl',g_inv,dg)+\n",
    "              torch.einsum('im,mlk->ikl',g_inv,dg)-\n",
    "              torch.einsum('im,klm->ikl',g_inv,dg)\n",
    "              )\n",
    "    return Ch\n",
    "Ch_jacfwd_vmap = TF.vmap(Ch_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ch_der_jacfwd (u, function = decoder):\n",
    "    Ch = functools.partial(Ch_jacfwd, function=function)\n",
    "    dCh = jacfwd(Ch)(u).squeeze()\n",
    "    return dCh\n",
    "Ch_der_jacfwd_vmap = TF.vmap(Ch_der_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem_jacfwd(u, function = decoder):\n",
    "    Ch = Ch_jacfwd(u, function)\n",
    "    Ch_der = Ch_der_jacfwd(u, function)\n",
    "\n",
    "    Riem = torch.einsum(\"iljk->ijkl\",Ch_der) - torch.einsum(\"ikjl->ijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"ikp,plj->ijkl\", Ch, Ch) - torch.einsum(\"ilp,pkj->ijkl\", Ch, Ch)\n",
    "    return Riem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ric_jacfwd(u, function = decoder):\n",
    "    Riemann = Riem_jacfwd(u, function)\n",
    "    Ric = torch.einsum(\"cacb->ab\",Riemann)\n",
    "    return Ric\n",
    "Ric_jacfwd_vmap = TF.vmap(Ric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo\n",
    "Ric_jacfwd_vmap(torch.rand(3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Ground truth check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fun_sphere(u):\n",
    "    u = u.flatten()\n",
    "    output = torch.cat((torch.sin(u[0])*torch.cos(u[1]).unsqueeze(0),torch.sin(u[0])*torch.sin(u[1]).unsqueeze(0),torch.cos(u[0]).unsqueeze(0)),dim=-1)\n",
    "    output = torch.cat((output.unsqueeze(0),torch.zeros(781).unsqueeze(0)),dim=1)\n",
    "    output = output.flatten()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(3,2)\n",
    "print(\"metric:\\n\", metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere))\n",
    "print(\"Ricci tensor:\\n\", Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_sphere))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = k*g,with k = n-1 for an \n",
    "# n-dimentional sphere S^n. Thus if n = 2, Ric = g\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = torch.rand(1000,2)\n",
    "test_metric_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "test_Ric_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_sphere)\n",
    "\n",
    "# here we check if g = Ric\n",
    "absolute_error = (test_metric_array - test_Ric_array).norm(dim=(1,2))\n",
    "relative_error = 100*absolute_error/(test_metric_array.norm(dim=(1,2)))\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(relative_error,bins=10,density=False,stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare frobenius norm heatmaps of the metric \n",
    "# and the Ricci tensor. For the sphere they should coincide\n",
    "numsteps = 100\n",
    "tgrid = make_grid(numsteps)\n",
    "Ric_on_grid = Ric_jacfwd_vmap(tgrid, function=my_fun_sphere)\n",
    "metric_on_grid = metric_jacfwd_vmap(tgrid, function=my_fun_sphere)\n",
    "\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Frobenius norm of the metric',\n",
    "                              tensor_on_grid= metric_on_grid, \n",
    "                              numsteps=numsteps)\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid= Ric_on_grid, \n",
    "                              numsteps=numsteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lobachevsky plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial embedding (for y>c) of Lobachevsky plane to R^3 \n",
    "# (formally here it is R^784)\n",
    "# ds^2 = 1/y^2(dx^2 + dy^2)\n",
    "# http://www.antoinebourget.org/maths/2018/08/08/embedding-hyperbolic-plane.html\n",
    "def my_fun_lobachevsky(u, c=0.01):\n",
    "    u = u.flatten()\n",
    "    x = u[0]\n",
    "    y = u[1]\n",
    "    t = torch.acosh(y/c)\n",
    "    x0 = t - torch.tanh(t)\n",
    "    x1 = (1/torch.sinh(t))*torch.cos(x/c)\n",
    "    x2 = (1/torch.sinh(t))*torch.sin(x/c)\n",
    "    output = torch.cat((x0.unsqueeze(0),x1.unsqueeze(0),x2.unsqueeze(0)),dim=-1)\n",
    "    output = torch.cat((output.unsqueeze(0),torch.zeros(781).unsqueeze(0)),dim=1)\n",
    "    output = output.flatten()\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motivating demo\n",
    "torch.manual_seed(10)\n",
    "test_batch = torch.rand(3,2)\n",
    "print(\"metric:\\n\", metric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky))\n",
    "print(\"Ricci tensor:\\n\", Ric_jacfwd_vmap(test_batch,\n",
    "                                      function=my_fun_lobachevsky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historgam of errors. This is done in order to verify Ricci \n",
    "# tensor computation. Ric = k*g,with k = -1 \n",
    "# for the Lobachevsky plane. Thus if Ric = -g\n",
    "torch.manual_seed(10)\n",
    "\n",
    "test_batch = torch.rand(1000,2) + 0.2 \n",
    "# we use shift because y>0 for this model\n",
    "\n",
    "test_metric_array = metric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "test_Ric_array = Ric_jacfwd_vmap(test_batch,\n",
    "                                       function=my_fun_lobachevsky)\n",
    "\n",
    "# here we check if g = - Ric\n",
    "absolute_error = (test_metric_array + test_Ric_array).norm(dim=(1,2))\n",
    "relative_error = 100*absolute_error/(test_metric_array.norm(dim=(1,2)))\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(relative_error,bins=10,density=False,stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare frobenius norm heatmaps of the metric \n",
    "# and the Ricci tensor. For the Lobachevsky plane they should coincide\n",
    "numsteps = 100\n",
    "tgrid = make_grid(numsteps, xshift=0.0, yshift=1.7)\n",
    "\n",
    "lobachevsky_metric_on_grid = metric_jacfwd_vmap(tgrid, function=my_fun_lobachevsky)\n",
    "lobachevsky_Ric_on_grid = Ric_jacfwd_vmap(tgrid, function=my_fun_lobachevsky)\n",
    "\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Lobachevsky plane: Frobenius norm of the metric',\n",
    "                              tensor_on_grid=lobachevsky_metric_on_grid,\n",
    "                            numsteps= numsteps, xshift=0.0, yshift=1.7)\n",
    "draw_frob_norm_tensor_on_grid(plot_name = 'Lobachevsky plane: Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid=lobachevsky_Ric_on_grid,\n",
    "                            numsteps= numsteps, xshift=0.0, yshift=1.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. The Ricci tensor for the metric given by the pullback of the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes around 17 secs\n",
    "numsteps = 100\n",
    "grid = make_grid(numsteps)\n",
    "Decoder_Ric_on_grid = Ric_jacfwd_vmap(grid,function=decoder)\n",
    "draw_frob_norm_tensor_on_grid(plot_name='Latent space: Frobenius norm of the Ricci tensor',\n",
    "                              tensor_on_grid=Decoder_Ric_on_grid,\n",
    "                              numsteps=numsteps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
