{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook builds the quasi-isomorphic embedding of a torus latent space in $\\mathbb{R}^3$ using a pyTorch optimizer.\n",
    "\n",
    "1) Weights of the AE and encoded latent space data are loaded\n",
    "2) A grid is constructed and geodesic distances between neigbor points are computed via Stochman\n",
    "3) Optimizer is tuned. Embedding is constructed via optimization.\n",
    "4) The embedding is plotted vith matplotlib and trimesh. The results are saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import stochman\n",
    "from stochman.manifold import EmbeddedManifold\n",
    "import torch.nn as nn\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "violent_saving = True\n",
    "\n",
    "load_distances = True\n",
    "\n",
    "#experiment_json = f'../experiments/MNIST_torus_AEexp34.json' # no curv_pen\n",
    "\n",
    "experiment_json = f'../experiments/MNIST01_torus_AEexp7.json'\n",
    "mydict = ricci_regularization.get_dataloaders_tuned_nn(Path_experiment_json = experiment_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_ae = mydict[\"tuned_neural_network\"]\n",
    "test_loader = mydict[\"test_loader\"]\n",
    "json_cofig = mydict[\"json_config\"]\n",
    "Path_pictures = json_cofig[\"Path_pictures\"]\n",
    "exp_number = json_cofig[\"experiment_number\"]\n",
    "curv_w = json_cofig[\"losses\"][\"curv_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 784\n",
    "k = json_cofig[\"dataset\"][\"parameters\"][\"k\"]\n",
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "feature_space_encoding_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( test_loader, position=0 ):\n",
    "#for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    feature_space_encoding_list.append(torus_ae.encoder_torus(data.view(-1,D)))\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "feature_space_encoding = torch.cat(feature_space_encoding_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1],c = color_array,cmap=ricci_regularization.discrete_cmap(k,\"jet\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the grid and its triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the grid of points \n",
    "num_points = 100\n",
    "\n",
    "x_left = -2#-torch.pi#-torch.pi #-2.0\n",
    "y_bottom = -2#-torch.pi#-torch.pi #-2.0\n",
    "\n",
    "x_size = -x_left*2#2*torch.pi # 4.\n",
    "\n",
    "y_size = -y_bottom*2#2*torch.pi #4. # max shift of geodesics \n",
    "\n",
    "x_right = x_left + x_size\n",
    "y_top = y_bottom + y_size\n",
    "\n",
    "starting_points = torch.cat([torch.tensor([x_left,y_bottom + k]) for k in torch.linspace(0,y_size,num_points) ]).reshape(num_points,2)\n",
    "end_points = torch.cat([torch.tensor([x_right,y_bottom + k]) for k in torch.linspace(0,y_size,num_points) ]).reshape(num_points,2)\n",
    "\n",
    "starting_points_vertical = torch.cat([torch.tensor([x_left +k, y_bottom]) for k in torch.linspace(0,y_size,num_points) ]).reshape(num_points,2)\n",
    "end_points_vertical = torch.cat([torch.tensor([x_left + k, y_top]) for k in torch.linspace(0,y_size,num_points) ]).reshape(num_points,2)\n",
    "\n",
    "horizontal_step = torch.tensor([x_size/(num_points-1),0])\n",
    "grid = torch.cat([(starting_points + k * horizontal_step) for k in range(num_points)])\n",
    "grid = grid.reshape(num_points,num_points,2)\n",
    "\n",
    "# Triangulate parameter space to determine the triangles using the starting flat grid\n",
    "u = np.linspace(x_left, x_right , endpoint=True, num=num_points)\n",
    "v = np.linspace(y_bottom, y_top , endpoint=True, num=num_points)\n",
    "u, v = np.meshgrid(u, v)\n",
    "u, v = u.flatten(), v.flatten()\n",
    "\n",
    "# Triangulate parameter space to determine the triangles\n",
    "tri = mtri.Triangulation(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodesic distances computation via Stochman (or loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geodesics are computed minimizing \"energy\" in the embedding of the manifold,\n",
    "# So no need to compute the Pullback metric. and thus the algorithm is fast\n",
    "class Autoencoder(EmbeddedManifold):\n",
    "    def embed(self, c, jacobian = False):\n",
    "        return torus_ae.decoder_torus(c)\n",
    "#selected_labels = json_cofig[\"dataset\"][\"selected_labels\"]\n",
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_distances == False:\n",
    "    #horizontal geodesics left to right\n",
    "    c,success = model.connecting_geodesic(grid[:-1,:,:].reshape(-1,2),grid[1:,:,:].reshape(-1,2))\n",
    "    c.plot()\n",
    "    plt.scatter(grid[:,:,0], grid[:,:,1],c=\"blue\")\n",
    "    #plt.scatter(all_end_points_horizontal[-num_points:,0],all_end_points_horizontal[-num_points:,1],c=\"blue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_distances == False:\n",
    "    # vertical geodesics\n",
    "    c_vert,success = model.connecting_geodesic(grid[:,:-1,:].reshape(-1,2),grid[:,1:,:].reshape(-1,2))\n",
    "    c_vert.plot()\n",
    "    plt.scatter(grid[:,:,0], grid[:,:,1],c=\"blue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_distances == False:\n",
    "    c_vert.plot()\n",
    "    c.plot()\n",
    "    plt.scatter(grid[:,:,0], grid[:,:,1],c=\"blue\")\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_distances == True:\n",
    "    # loading geod lengths\n",
    "    horizontal_lengths = torch.load(Path_pictures+'/horizontal_lengths.pt')\n",
    "    vertical_lengths = torch.load(Path_pictures+'/vertical_lengths.pt')\n",
    "else:\n",
    "    t = torch.linspace(0,1,20)\n",
    "    horizontal_lengths = model.curve_length(c(t)).detach()\n",
    "    vertical_lengths = model.curve_length(c_vert(t)).detach()\n",
    "    torch.save(horizontal_lengths,Path_pictures+'/horizontal_lengths.pt')\n",
    "    torch.save(vertical_lengths,Path_pictures+'/vertical_lengths.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial embedding rect shape\n",
    "with torch.no_grad():\n",
    "    horizontal_lengths_reshaped = horizontal_lengths.reshape(num_points-1,num_points)\n",
    "    vertical_lengths_reshaped = vertical_lengths.reshape(num_points,num_points-1)\n",
    "    minimal_horizontal_length = horizontal_lengths_reshaped.sum(dim=0).min()\n",
    "    minimal_vertical_length = vertical_lengths_reshaped.sum(dim=1).min()\n",
    "edge = torch.min(minimal_horizontal_length,minimal_vertical_length)\n",
    "print(\"edge length:\", edge.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the initial grid embedding\n",
    "with torch.no_grad():\n",
    "    stretched_grid = grid*edge/x_size\n",
    "#setteing small vertical perturbation\n",
    "torch.manual_seed(666)\n",
    "eps = 1e-2*edge/num_points\n",
    "z_perturbation = eps * torch.randn(num_points,num_points,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified optimization avoiding nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "def plot_triang(embedded_grid,additional_comment='',savefig=False, plot_number=0):\n",
    "    # triple\n",
    "    x = embedded_grid[:,:,0].flatten().detach()\n",
    "    y = embedded_grid[:,:,1].flatten().detach()\n",
    "    z = embedded_grid[:,:,2].flatten().detach()\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10),dpi=300)\n",
    "    # Plot the surface.  The triangles in parameter space determine which x, y, z\n",
    "    # points are connected by an edge.\n",
    "\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "    ax.set_title(f\"3d embedding of a grid on torus with $\\lambda_{{\\mathrm{{curv}}}} = ${curv_w}.\"+\n",
    "                    additional_comment)\n",
    "    \n",
    "    p = ax.plot_trisurf(x, y, z, triangles=tri.triangles, cmap=cm.Spectral,vmax=z.max(),vmin=z.min())\n",
    "    ax.set_zlim(-0.5, 0.5)\n",
    "    ax.view_init(0, 30)\n",
    "\n",
    "    cbar = fig.colorbar(p,shrink = 0.1)\n",
    "    cbar.set_label(\"Height\")\n",
    "    cbar.set_ticks(ticks=[z.min(), 0., z.max()])\n",
    "    cbar.set_ticklabels(ticklabels=[f'{z.min():.3f}','0', f'{z.max():.3f}'])\n",
    "\n",
    "    if savefig == True:\n",
    "        plt.savefig(Path_pictures+f\"/3dembedding_optimization_history/plot{plot_number}.pdf\",format=\"pdf\")\n",
    "\n",
    "    plt.show()\n",
    "    return tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_simple(epoch, params, embedded_grid, horizontal_lengths_reshaped, vertical_lengths_reshaped, num_iter=1, \n",
    "                         mode=\"diagnostic\", loss_history=None, learning_rate=1e+1):\n",
    "    if loss_history is None:\n",
    "        loss_history = []  # List to store loss values\n",
    "\n",
    "    # Use an optimizer (e.g., Adam)\n",
    "    optimizer = torch.optim.SGD(params, lr=learning_rate)\n",
    "\n",
    "    for iter_num in range(num_iter):\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "        # Compute the embedded grid once to avoid redundant computations\n",
    "        embedded = embedded_grid\n",
    "\n",
    "        # Calculate horizontal and vertical distances\n",
    "        horizontal_grid_distances = (embedded[1:, :, :] - embedded[:-1, :, :]).norm(dim=-1)\n",
    "        vertical_grid_distances = (embedded[:, 1:, :] - embedded[:, :-1, :]).norm(dim=-1)\n",
    "\n",
    "        # Compute the losses\n",
    "        loss_horizontal = (horizontal_lengths_reshaped - horizontal_grid_distances).square().mean()\n",
    "        loss_vertical = (vertical_lengths_reshaped - vertical_grid_distances).square().mean()\n",
    "\n",
    "        # Sum the losses\n",
    "        loss = 1e2 * (loss_horizontal + loss_vertical)\n",
    "\n",
    "        # Backpropagation: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the loss value\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        \"\"\"\n",
    "        # Print diagnostics if needed\n",
    "        if mode == \"diagnostic\":\n",
    "            print(f\"Iteration #{iter_num + 1}, loss: {loss.item():.3f}\")\n",
    "        \"\"\"\n",
    "\n",
    "    # Plot the loss values if in diagnostic mode\n",
    "    if mode == \"diagnostic\":\n",
    "        plot_triang(embedded_grid, plot_number=epoch+1,savefig=True,\n",
    "                              additional_comment=f'\\n After {len(loss_history)} iterations.')\n",
    "\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(loss_history, label='Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate optimization\n",
    "embedded_grid = torch.cat((stretched_grid, z_perturbation),dim=2).requires_grad_()\n",
    "\n",
    "# Define parameters (for example, weights to optimize)\n",
    "params = [embedded_grid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5 \n",
    "loss_history = []\n",
    "#embedded_grid.plot_triang()\n",
    "for epoch in range(num_epochs):\n",
    "    # Run the training loop\n",
    "    loss_history = training_loop_simple(epoch, params, embedded_grid, horizontal_lengths_reshaped, \n",
    "                         vertical_lengths_reshaped,loss_history=loss_history, \n",
    "                         num_iter=100, mode=\"diagnostic\",learning_rate=1e0)\n",
    "    #embedded_grid.plot_triang(plot_number=epoch+1,savefig=True,\n",
    "    #                          additional_comment=f'\\n After {len(loss_history)} iterations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(loss_history, label='Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "if violent_saving == True:\n",
    "    plt.savefig(Path_pictures+\"/3dembedding_optimization_history/loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_grid = embedded_grid.detach()\n",
    "# grid saving\n",
    "if violent_saving == True:\n",
    "    torch.save(optimized_grid,Path_pictures+\"/embedded_grid.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with the embedded grid with trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "# Create the trimesh object directly from vertices and faces\n",
    "mesh = trimesh.Trimesh(vertices=optimized_grid.reshape(-1,3), faces=tri.triangles)\n",
    "\n",
    "# Extract z-coordinates of the vertices\n",
    "z_coords = mesh.vertices[:, 2]\n",
    "\n",
    "# Normalize the z-coordinates to the range [0, 1]\n",
    "z_min = z_coords.min()\n",
    "z_max = z_coords.max()\n",
    "normalized_z = (z_coords - z_min) / (z_max - z_min)\n",
    "\n",
    "# Get a colormap from matplotlib\n",
    "colormap = matplotlib.colormaps.get_cmap(\"jet\")\n",
    "#colormap = cm.get_cmap('rainbow')\n",
    "\n",
    "# Map the normalized z-coordinates to colors using the colormap\n",
    "colors = colormap(normalized_z)\n",
    "\n",
    "# Convert colors to 0-255 range and RGBA format\n",
    "vertex_colors = (colors[:, :4] * 255).astype(np.uint8)\n",
    "\n",
    "# Assign these colors to the mesh's vertices\n",
    "mesh.visual.vertex_colors = vertex_colors\n",
    "\n",
    "# Create a scene with the mesh\n",
    "scene = trimesh.Scene(mesh)\n",
    "\n",
    "# Define the initial camera transformation matrix\n",
    "# Here, we are setting the camera to look at the mesh from a specific angle\n",
    "# and zoom out by translating the camera along the y-axis\n",
    "zoom_out_factor = 12.0  # Increase this value to zoom out more\n",
    "camera_transform = trimesh.transformations.translation_matrix([-0.2, -zoom_out_factor, -5.5])\n",
    "\n",
    "\n",
    "# Set the camera transform in the scene\n",
    "scene.camera_transform = camera_transform\n",
    "\n",
    "# Display the mesh in a viewer window with the specified initial observation angle\n",
    "scene.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
