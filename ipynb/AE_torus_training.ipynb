{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torus AE training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the training of the autoencoder (AE). \n",
    "\n",
    "The AE consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is topologically a $d-$ dimensional torus $\\mathcal{T}^d$, i.e it can be considered as a periodic box $[-\\pi, \\pi]^d$. We define a Riemannian metric on the latent space  as the pull-back of the Euclidean metric in the output space $\\mathbb{R}^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi \\ .\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "One can switch between regimes: \n",
    "\"yaml_config[\"training_mode\"][\"diagnostic_mode\"]\", \"compute_curvature_mode\", \"yaml_config[\"training_mode\"][\"OOD_regime\"]\".\n",
    "\n",
    "If \"yaml_config[\"training_mode\"][\"diagnostic_mode\"]\"==True, following losses are plotted: MSE, $\\mathcal{L}_\\mathrm{unif}$, $\\mathcal{L}_\\mathrm{curv}$, $\\det(g)$, $\\|g_{reg}^{-1}\\|_F$, $\\|\\nabla \\Psi \\|^2_F$, $\\|\\nabla \\Phi \\|^2_F$, where:\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}_\\mathrm{curv} := \\int_M R^2 \\mu \\ ,\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}_\\mathrm{unif} := \\sum\\limits_{k=1}^{m} |\\int_M z^k  \\mu_N (dz) |^2 \\ ,\n",
    "\\end{equation*}\n",
    "where $R$ states for scalar curvature (see https://en.wikipedia.org/wiki/Scalar_curvature), $\\mu_N = \\Phi\\# ( \\frac{1}{N}\\sum\\limits_{j=1}^{N} \\delta_{X_i} ) $ is the push-forward of the natural measure induced by the dataset by the encoder $\\Phi$, thus $\\mu_N$ is a measure on $\\mathcal{T}^d$,  $ \\alpha_k = \\frac{1}{N} \\sum_{j=1}^{N} z_j^k$ is the empirical estimator of the $k$ -th moment of the data distribution in the latent space.\n",
    "\n",
    "If $\\xi \\sim \\mathcal{U}[-\\pi, \\pi]$ and $z = e^{i \\xi}$ than all the moments of $z$ are zero, namely if $\\mathcal{L}_\\mathrm{unif} \\to 0$ as $m \\to \\infty$, one obtains weak convergence of the data distribution in the latent space to the uniform distribution.\n",
    "\n",
    "Also $g_{reg} = g + \\varepsilon \\cdot I$ is the regularized matrix of metric for stability of inverse matrix computation, $\\|\\|_F$ is the Frobenius norm of the matrix.\n",
    "\n",
    "The notebook consists of\n",
    "\n",
    "1) Imports. Choosing hyperparameters for dataset uploading, learning and plotting such as learning rate, batch size, weights of MSE loss, curvature loss, etc. Automatic loading of train and test dataloaders. Choice among data sets \"Synthetic\", \"Swissroll\", \"MNIST\", \"MNIST01\" (any selected labels from MNIST). \n",
    "2) Architecture and device. Architecture types: Fully connected (TorusAE), Convolutional (TorusConvAE). Device: cuda/cpu. \n",
    "3) Training.\n",
    "4) Report of training. Printing of graphs of losses, saves of a json file with training params.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import os\n",
    "import ricci_regularization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters loading from YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the YAML configuration file\n",
    "with open('init_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Print the loaded YAML configuration\n",
    "print(\"YAML Configuration loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the experiment_name\n",
    "experiment_name = yaml_config[\"dataset\"][\"name\"] + \"_torus_AE\"\n",
    "print(f\"Experiment Name: {experiment_name}\")  # Print the constructed experiment name\n",
    "\n",
    "# Paths for saving  pictures\n",
    "Path_pictures = f\"../experiments/{experiment_name}/experiment\" + str(yaml_config[\"experiment\"][\"experiment_number\"])\n",
    "print(f\"Path for Pictures: {Path_pictures}\")  # Print the path for pictures\n",
    "\n",
    "# Check and create directories based on configuration\n",
    "if yaml_config[\"experiment\"][\"violent_saving\"]:  # Check if violent saving is enabled\n",
    "    print(\"Plots will be saved\")\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        if not os.path.exists(f\"../experiments/{experiment_name}/\"):  # Check if the experiment directory does not exist\n",
    "            os.mkdir(f\"../experiments/{experiment_name}/\")  # Create the experiment directory if not yet created\n",
    "            print(f\"Created directory: ../experiments/{experiment_name}/\")  # Print directory creation feedback\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "else:\n",
    "    print(\"Plots will not be saved\")\n",
    "Path_weights = \"../nn_weights/\"  # Path for saving neural network weights\n",
    "print(f\"Path for Weights: {Path_weights}\")  # Print the path for neural network weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOD sampling parameters\n",
    "# This parameters mean nothing if yaml_config[\"training_mode\"][\"OOD_regime\"] == False\n",
    "\n",
    "T_ood = 20 # 100 # period of OOD penalization\n",
    "n_ood = 5 # number of OOD samples per point\n",
    "sigma_ood = 2e-1 # sigma of OOD Gaussian samples: 2e-1 swissroll\n",
    "N_extr = 16 # 32 batch size of extremal curvature points\n",
    "r_ood = 1e-3 # 1e-2 decay factor\n",
    "OOD_w = yaml_config[\"loss_settings\"][\"lambda_curv\"] # weight on curvature in OOD sampling\n",
    "start_ood = 0 # OOD starting batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for data loader reproducibility\n",
    "torch.manual_seed(yaml_config[\"data_loader_settings\"][\"random_seed\"])\n",
    "print(f\"Set random seed to: {yaml_config['data_loader_settings']['random_seed']}\")\n",
    "\n",
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "\n",
    "# Calculate number of batches per epoch\n",
    "batches_per_epoch = len(train_loader)\n",
    "print(f\"Number of batches per epoch: {batches_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(yaml_config[\"data_loader_settings\"][\"random_seed\"])\n",
    "print(f\"Set random seed to: {yaml_config['data_loader_settings']['random_seed']}\")\n",
    "\n",
    "# Selecting the architecture type based on YAML configuration\n",
    "if yaml_config[\"architecture\"][\"type\"] == \"TorusConvAE\":\n",
    "    torus_ae = ricci_regularization.Architectures.TorusConvAE(\n",
    "        x_dim=yaml_config[\"architecture\"][\"output_dim\"],\n",
    "        h_dim1=512,\n",
    "        h_dim2=256,\n",
    "        z_dim=yaml_config[\"architecture\"][\"latent_dim\"],\n",
    "        pixels=28\n",
    "    )\n",
    "    print(\"Selected architecture: TorusConvAE\")\n",
    "else:\n",
    "    torus_ae = ricci_regularization.Architectures.TorusAE(\n",
    "        x_dim=yaml_config[\"architecture\"][\"output_dim\"],\n",
    "        h_dim1=512,\n",
    "        h_dim2=256,\n",
    "        z_dim=yaml_config[\"architecture\"][\"latent_dim\"]\n",
    "    )\n",
    "    print(\"Selected architecture: TorusAE\")\n",
    "\n",
    "# Check GPU availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available! Training will use GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is NOT available! Using CPU.\")\n",
    "\n",
    "# Move the AE model to the selected device\n",
    "torus_ae.to(device)\n",
    "print(f\"Moved model to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yaml_config[\"experiment\"][\"weights_loaded\"] == True:\n",
    "    PATH_weights_loaded = f'../nn_weights/{yaml_config[\"dataset\"][\"name\"]}_exp{yaml_config[\"experiment\"][\"experiment_number\"]-1}.pt'\n",
    "    torus_ae.load_state_dict(torch.load(PATH_weights_loaded))\n",
    "    torus_ae.eval()\n",
    "    print(f\"Weights loaded from {PATH_weights_loaded}\")\n",
    "else:\n",
    "    print(\"No weights loaded as 'weights_loaded' is set to False in the configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(torus_ae.parameters(),\n",
    "        lr=yaml_config[\"optimizer_settings\"][\"lr\"],\n",
    "        weight_decay=yaml_config[\"optimizer_settings\"][\"weight_decay\"])\n",
    "print(f\"Optimizer configured with learning rate {yaml_config['optimizer_settings']['lr']} and weight decay {yaml_config['optimizer_settings']['weight_decay']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curv_func(encoded_data, function=torus_ae.decoder_torus):\n",
    "    metric_on_data = ricci_regularization.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=function)\n",
    "    det_on_data = torch.det(metric_on_data)\n",
    "    Sc_on_data = ricci_regularization.Sc_jacfwd_vmap(encoded_data,\n",
    "                                           function=function)\n",
    "    N = metric_on_data.shape[0]\n",
    "    Integral_of_Sc = (1/N)*(torch.sqrt(det_on_data)*torch.square(Sc_on_data)).sum()\n",
    "    #Integral_of_Sc = (1/N)*(torch.sqrt(det_on_data)*(Sc_on_data**4)).sum()\n",
    "    return Integral_of_Sc\n",
    "\n",
    "print(\"curv_func: Calculated integral of scalar curvature\")\n",
    "\n",
    "# Loss = MSE + uniform_loss + curv_loss\n",
    "def loss_function(recon_data, data, z, decoder):\n",
    "    MSE = F.mse_loss(recon_data, data.view(-1, yaml_config[\"dataset\"][\"D\"]), reduction='mean')\n",
    "    z_sin = z[:, 0:yaml_config[\"architecture\"][\"latent_dim\"]]\n",
    "    z_cos = z[:, yaml_config[\"architecture\"][\"latent_dim\"]:2*yaml_config[\"architecture\"][\"latent_dim\"]]\n",
    "    mode1 = torch.mean( z, dim = 0)\n",
    "    mode1 = torch.sum( mode1*mode1 )\n",
    "    mode2_1 = torch.mean( 2*z_cos*z_cos-1, dim = 0)\n",
    "    mode2_1 = torch.sum( mode2_1*mode2_1)\n",
    "    mode2_2 = torch.mean( 2*z_sin*z_cos, dim = 0)\n",
    "    mode2_2 = torch.sum( mode2_2*mode2_2 )\n",
    "    mode2 = mode2_1 + mode2_2\n",
    "    unif_loss = mode1 + mode2\n",
    "    if yaml_config[\"loss_settings\"][\"num_moments\"] > 2:\n",
    "        mode3_1 = torch.mean( 4*z_cos**3-3*z_cos, dim = 0)\n",
    "        mode3_1 = torch.sum( mode3_1*mode3_1)\n",
    "        mode3_2 = torch.mean( z_sin*(8*z_cos**3-4*z_cos), dim = 0)\n",
    "        mode3_2 = torch.sum( mode3_2*mode3_2 )\n",
    "        mode3 = mode3_1 + mode3_2\n",
    "        unif_loss += mode3\n",
    "    if yaml_config[\"loss_settings\"][\"num_moments\"] > 3:\n",
    "        mode4_1 = torch.mean( 8*z_cos**4-8*z_cos**2+1, dim = 0)\n",
    "        mode4_1 = torch.sum( mode4_1*mode4_1)\n",
    "        mode4_2 = torch.mean( z_sin*(16*z_cos**4-12*z_cos**2+1), dim = 0)\n",
    "        mode4_2 = torch.sum( mode4_2*mode4_2 )\n",
    "        mode4 = mode4_1 + mode4_2\n",
    "        unif_loss += mode4\n",
    "    dict_losses = {\n",
    "        \"MSE\": MSE,\n",
    "        \"uniform_loss\": unif_loss,\n",
    "    }\n",
    "    \n",
    "    if yaml_config[\"training_mode\"][\"compute_curvature\"] == True:\n",
    "        encoded_points_no_grad = torus_ae.encoder2lifting(data.view(-1, yaml_config[\"dataset\"][\"D\"])).detach()\n",
    "        metric_on_data = ricci_regularization.metric_jacfwd_vmap(encoded_points_no_grad,\n",
    "                                           function=decoder)\n",
    "        det_on_data = torch.det(metric_on_data)\n",
    "        Sc_on_data = ricci_regularization.Sc_jacfwd_vmap(encoded_points_no_grad,\n",
    "                                           function=decoder,eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "        \n",
    "        if yaml_config[\"loss_settings\"][\"curvature_penalization_mode\"] == \"mean\":\n",
    "            curv_loss = (torch.sqrt(det_on_data)*torch.square(Sc_on_data)).mean()\n",
    "        elif yaml_config[\"loss_settings\"][\"curvature_penalization_mode\"] == \"max\":\n",
    "            curv_outlyers = torch.nn.ReLU()(torch.sqrt(det_on_data)*torch.square(Sc_on_data) - yaml_config[\"loss_settings\"][\"delta_curv\"])\n",
    "            curv_loss = (curv_outlyers).max()\n",
    "        \n",
    "        dict_losses[\"curvature_loss\"] = curv_loss\n",
    "        if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "            curv_squared_mean = (torch.square(Sc_on_data)).mean()\n",
    "            curv_squared_max = (torch.square(Sc_on_data)).max()\n",
    "            dict_losses[\"curv_squared_mean\"] = curv_squared_mean\n",
    "            dict_losses[\"curv_squared_max\"] = curv_squared_max\n",
    "    if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "        if yaml_config[\"training_mode\"][\"compute_curvature\"] == False:\n",
    "            encoded_points_no_grad = torus_ae.encoder2lifting(data.view(-1, yaml_config[\"dataset\"][\"D\"])).detach()\n",
    "            metric_on_data = ricci_regularization.metric_jacfwd_vmap(encoded_points_no_grad,function=decoder)\n",
    "            det_on_data = torch.det(metric_on_data)    \n",
    "        g_inv_train_batch = torch.linalg.inv(metric_on_data + yaml_config[\"loss_settings\"][\"eps\"]*torch.eye(yaml_config[\"architecture\"][\"latent_dim\"]).to(device))\n",
    "        g_inv_norm_train_batch = torch.linalg.matrix_norm(g_inv_train_batch)\n",
    "        g_inv_norm_mean = torch.mean(g_inv_norm_train_batch)\n",
    "        g_inv_norm_max = torch.max(g_inv_norm_train_batch)\n",
    "        g_det_mean = det_on_data.mean()\n",
    "        g_det_max = det_on_data.max()\n",
    "        g_det_min = det_on_data.min()\n",
    "        decoder_jac_norm = torch.func.vmap(torch.trace)(metric_on_data)\n",
    "        decoder_jac_norm_mean = decoder_jac_norm.mean()\n",
    "        decoder_jac_norm_max = decoder_jac_norm.max()\n",
    "        dict_losses[\"g_inv_norm_mean\"] = g_inv_norm_mean\n",
    "        dict_losses[\"g_inv_norm_max\"] = g_inv_norm_max\n",
    "        dict_losses[\"g_det_mean\"] = g_det_mean\n",
    "        dict_losses[\"g_det_max\"] = g_det_max\n",
    "        dict_losses[\"g_det_min\"] = g_det_min\n",
    "        dict_losses[\"decoder_jac_norm_mean\"] = decoder_jac_norm_mean\n",
    "        dict_losses[\"decoder_jac_norm_max\"] = decoder_jac_norm_max\n",
    "        outlyers_decoder_norm = torch.nn.ReLU()(decoder_jac_norm - yaml_config[\"loss_settings\"][\"delta_decoder\"])\n",
    "        dict_losses[\"decoder_contractive_loss\"] = (outlyers_decoder_norm).max()\n",
    "        metric_array_encoder = ricci_regularization.metric_jacrev_vmap(data.view(-1, yaml_config[\"dataset\"][\"D\"]),\n",
    "                function=torus_ae.encoder_torus,\n",
    "                latent_space_dim=yaml_config[\"dataset\"][\"D\"]) # D here is not the latent space dimension (naming is counter-intuitive)!\n",
    "        encoder_jac_norm = torch.func.vmap(torch.trace)(metric_array_encoder)\n",
    "        encoder_jac_norm_mean = encoder_jac_norm.mean()\n",
    "        encoder_jac_norm_max = encoder_jac_norm.max()\n",
    "        dict_losses[\"encoder_jac_norm_mean\"] = encoder_jac_norm_mean\n",
    "        dict_losses[\"encoder_jac_norm_max\"] = encoder_jac_norm_max\n",
    "        outlyers_encoder_norm = torch.nn.ReLU()(encoder_jac_norm - yaml_config[\"loss_settings\"][\"delta_encoder\"])\n",
    "        dict_losses[\"encoder_contractive_loss\"] = (outlyers_encoder_norm).max()\n",
    "    return dict_losses\n",
    "\n",
    "print(\"loss_function: Calculated MSE, uniform_loss, and optionally curvature_loss and diagnostic metrics\")\n",
    "\n",
    "# OOD initialization\n",
    "extreme_curv_value_tensor = None\n",
    "extreme_curv_points_tensor = None\n",
    "if yaml_config[\"training_mode\"][\"OOD_regime\"] == True:\n",
    "    first_batch,_ = next(iter(train_loader))\n",
    "    first_batch = first_batch.to(device)\n",
    "    extreme_curv_points_tensor = torus_ae.encoder2lifting(first_batch.view(-1,yaml_config[\"dataset\"][\"D\"])[:N_extr]).detach()\n",
    "    extreme_curv_points_tensor.to(device)\n",
    "    extreme_curv_value_tensor = ricci_regularization.Sc_jacfwd_vmap(extreme_curv_points_tensor, \n",
    "            function=torus_ae.decoder_torus,eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "\n",
    "print(\"OOD initialization: Initialized OOD regime with extreme curvature points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch=1,batch_idx = 0,dict_loss_arrays={},\n",
    "          extreme_curv_points_tensor = extreme_curv_points_tensor, \n",
    "          extreme_curv_value_tensor = extreme_curv_value_tensor):\n",
    "    if batch_idx == 0:\n",
    "        dict_loss_arrays = {}\n",
    "    torus_ae.train()\n",
    "    print(\"Epoch %d\"%epoch)\n",
    "    t = tqdm( train_loader, desc=\"Train\", position=0 )\n",
    "    \n",
    "    for (data, labels) in t:\n",
    "        #data = data.cuda()\n",
    "        #data = data.cpu()\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        \"\"\"\n",
    "        if yaml_config[\"architecture\"][\"type\"] == \"TorusConvAE\":\n",
    "            recon_batch, z = decoder(encoder(data)) , encoder(data)\n",
    "        else:\n",
    "            recon_batch, z = torus_ae(data)\n",
    "        \"\"\"\n",
    "        recon_batch, z = torus_ae(data)\n",
    "        #mse_loss, uniform_loss, curvature_loss, g_inv_loss, curvature_squared = loss_function(recon_batch, data, z,decoder=torus_ae.decoder_torus)\n",
    "        \n",
    "        dict_losses = loss_function(recon_batch, data, z,\n",
    "                                    decoder=torus_ae.decoder_torus)\n",
    "        mse_loss = dict_losses[\"MSE\"]\n",
    "        uniform_loss = dict_losses[\"uniform_loss\"]\n",
    "        loss = yaml_config[\"loss_settings\"][\"lambda_recon\"]*mse_loss + yaml_config[\"loss_settings\"][\"lambda_unif\"]*uniform_loss \n",
    "\n",
    "        #relu_function = torch.nn.ReLU()\n",
    "        #decoder_penalty = relu_function( dict_losses[f\"decoder_jac_norm_{djnpm}\"]- yaml_config[\"loss_settings\"][\"delta_decoder\"])\n",
    "        #encoder_penalty = relu_function( dict_losses[f\"encoder_jac_norm_{ejnpm}\"]- yaml_config[\"loss_settings\"][\"delta_encoder\"])\n",
    "        if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "            encoder_contractive_loss = dict_losses[\"encoder_contractive_loss\"]\n",
    "            decoder_contractive_loss = dict_losses[\"decoder_contractive_loss\"]\n",
    "            loss = loss + + yaml_config[\"loss_settings\"][\"lambda_contractive_decoder\"]*decoder_contractive_loss + yaml_config[\"loss_settings\"][\"lambda_contractive_encoder\"]*encoder_contractive_loss#yaml_config[\"loss_settings\"][\"lambda_contractive_encoder\"]*encoder_penalty\n",
    "\n",
    "\n",
    "        \n",
    "        if (yaml_config[\"training_mode\"][\"compute_curvature\"] == True): \n",
    "            curvature_loss = dict_losses[\"curvature_loss\"]\n",
    "            loss = loss + yaml_config[\"loss_settings\"][\"lambda_curv\"]*curvature_loss\n",
    "        else:\n",
    "            curvature_loss_mean_per_epoch = \"nan\"\n",
    "        \n",
    "        # OOD regime (optional)\n",
    "        if yaml_config[\"training_mode\"][\"OOD_regime\"] == True:\n",
    "            extreme_curv_points_tensor, extreme_curv_value_tensor = ricci_regularization.find_extreme_curvature_points(data_batch=data,\n",
    "                                extreme_curv_points_tensor=extreme_curv_points_tensor,\n",
    "                                extreme_curv_value_tensor=extreme_curv_value_tensor,batch_idx=batch_idx,\n",
    "                                encoder=torus_ae.encoder2lifting,decoder=torus_ae.decoder_torus,r_ood=r_ood,\n",
    "                                N_extr=N_extr,output_dim=yaml_config[\"dataset\"][\"D\"])\n",
    "            \n",
    "            if (batch_idx % T_ood == 0) & (batch_idx >= start_ood):\n",
    "                OOD_curvature_loss = ricci_regularization.OODTools.curv_loss_on_OOD_samples(extreme_curv_points_tensor=extreme_curv_points_tensor,\n",
    "                                                                                            decoder=torus_ae.decoder_torus,\n",
    "                                                                                            sigma_ood=sigma_ood,n_ood=n_ood,N_extr=N_extr,\n",
    "                                                                                            latent_space_dim=yaml_config[\"architecture\"][\"latent_dim\"])\n",
    "                if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "                    print(\"Curvature functional at OOD points\", OOD_curvature_loss)\n",
    "                loss = OOD_w * OOD_curvature_loss\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #appending losses per batch to loss arrays\n",
    "        if batch_idx == 0:\n",
    "            #dict_loss_arrays[\"decoder_penalty\"] = []\n",
    "            #dict_loss_arrays[\"encoder_penalty\"] = []\n",
    "            for key in dict_losses.keys():\n",
    "                dict_loss_arrays[key] = []\n",
    "        #dict_loss_arrays[\"decoder_penalty\"].append(decoder_penalty.item())\n",
    "        #dict_loss_arrays[\"encoder_penalty\"].append(decoder_penalty.item())\n",
    "        for key in dict_losses.keys():\n",
    "            dict_loss_arrays[key].append(dict_losses[key].item())\n",
    "        \n",
    "        # Progress bar\n",
    "        batch_idx += 1\n",
    "        MSE_mean_per_epoch = np.array(dict_loss_arrays[\"MSE\"])[-batches_per_epoch:].mean()\n",
    "        uniform_loss_mean_per_epoch = np.array(dict_loss_arrays[\"uniform_loss\"])[-batches_per_epoch:].mean()    \n",
    "        if yaml_config[\"training_mode\"][\"compute_curvature\"] == True:\n",
    "            curvature_loss_mean_per_epoch = np.array(dict_loss_arrays[\"curvature_loss\"])[-batches_per_epoch:].mean()\n",
    "        else:\n",
    "            curvature_loss_mean_per_epoch = \"nan\"\n",
    "        #decoder_penalty_mean_per_epoch = np.array(dict_loss_arrays[\"decoder_contractive_loss\"])[-batches_per_epoch:].mean()\n",
    "        \n",
    "        # Losses to be printed online in yaml_config[\"training_mode\"][\"diagnostic_mode\"]\n",
    "        if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "            encoder_contractive_loss_mean_per_epoch = np.array(dict_loss_arrays[\"encoder_contractive_loss\"])[-batches_per_epoch:].mean()\n",
    "            t.set_description_str(desc=f\"MSE:{MSE_mean_per_epoch}, Uniform:{uniform_loss_mean_per_epoch}, Encoder_penalty:{encoder_contractive_loss_mean_per_epoch}, Curvature:{curvature_loss_mean_per_epoch}.\\n\")\n",
    "        \n",
    "        # Losses to be printed online in yaml_config[\"training_mode\"][\"compute_curvature\"] mode\n",
    "        if yaml_config[\"training_mode\"][\"compute_curvature\"] == True:\n",
    "            t.set_description_str(desc=f\"MSE:{MSE_mean_per_epoch}, Uniform:{uniform_loss_mean_per_epoch}, Curvature:{curvature_loss_mean_per_epoch}.\\n\")\n",
    "        else:\n",
    "            t.set_description_str(desc=f\"MSE:{MSE_mean_per_epoch}, Uniform:{uniform_loss_mean_per_epoch}\")\n",
    "        #if batch_idx > num_batches: # if one wants to stop after certain number of batches\n",
    "        #    break\n",
    "    #end for\n",
    "    return batch_idx, dict_loss_arrays\n",
    "\n",
    "def test(mse_loss_array=[], uniform_loss_array=[], curvature_loss_array = [],g_inv_loss_array=[],curvature_squared_array=[]):\n",
    "    torus_ae.eval()\n",
    "    with torch.no_grad():\n",
    "        t = tqdm( test_loader, desc=\"Test\", position=1 )\n",
    "        for data, _ in t:\n",
    "            data = data.cpu()\n",
    "            recon_batch, z = torus_ae(data)\n",
    "            dict_losses = loss_function(recon_batch, data, z,decoder=torus_ae.decoder_torus)\n",
    "            if yaml_config[\"training_mode\"][\"compute_curvature\"] == True:\n",
    "                curvature_loss = dict_losses[\"curvature_loss\"]\n",
    "            else:\n",
    "                curvature_loss = torch.zeros(1)\n",
    "        \n",
    "            mse_loss_array.append( dict_losses[\"MSE\"].item() ) \n",
    "            uniform_loss_array.append( dict_losses[\"uniform_loss\"].item() )\n",
    "            curvature_loss_array.append(curvature_loss.item())\n",
    "    print(f\"Test losses. \\nMSE:{np.array(mse_loss_array).mean()}, Uniform:{np.array(uniform_loss_array).mean()}, Curvature:{np.array(curvature_loss_array).mean()}.\\n\")\n",
    "    return mse_loss_array, uniform_loss_array, curvature_loss_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx=0\n",
    "dict_loss_arrays = {}\n",
    "\n",
    "# Launch\n",
    "for epoch in range(1, yaml_config[\"optimizer_settings\"][\"num_epochs\"] + 1):\n",
    "  torus_ae.to(device)\n",
    "  batch_idx, dict_loss_arrays = train(epoch=epoch,batch_idx=batch_idx,dict_loss_arrays=dict_loss_arrays)\n",
    "  if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True :\n",
    "    dict2print = ricci_regularization.PlottingTools.translate_dict(dict2print=dict_loss_arrays, \n",
    "                include_curvature_plots=yaml_config[\"training_mode\"][\"compute_curvature\"],\n",
    "                eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "    ricci_regularization.PlottingTools.plotsmart(dict2print)\n",
    "  #else:\n",
    "  #  ricci_regularization.PlottingTools.plotfromdict(dict_of_losses=dict_loss_arrays)\n",
    "      \n",
    "  \n",
    "    \n",
    "  if (yaml_config[\"dataset\"][\"name\"] in [\"MNIST\",\"MNIST01\"]): #& (yaml_config[\"architecture\"][\"type\"] == \"TorusAE\"):\n",
    "    ricci_regularization.PlottingTools.plot_ae_outputs_selected(test_dataset=test_dataset,\n",
    "                                                       encoder=torus_ae.cpu().encoder2lifting,\n",
    "                                                       decoder=torus_ae.cpu().decoder_torus,\n",
    "                                                       selected_labels=yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "  #test() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test losses, $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_squared_losses(data_loader=test_loader):\n",
    "    len_test_loader = len(test_loader)\n",
    "    mse_loss = 0\n",
    "    curv_loss = 0\n",
    "    unif_loss = 0\n",
    "    input_dataset_list = []\n",
    "    torus_ae.to(device)\n",
    "    for (data, labels) in test_loader:\n",
    "        data = data.to(device)\n",
    "        input_dataset_list.append(data.cpu())\n",
    "        input = data\n",
    "        recon = torus_ae(data)[0]\n",
    "        z = torus_ae(data)[1]\n",
    "        enc = torus_ae.encoder2lifting(data.view(-1,yaml_config[\"dataset\"][\"D\"]))\n",
    "        dict_losses = loss_function(recon, input, z,\n",
    "                                    decoder=torus_ae.decoder_torus)\n",
    "        mse_loss += dict_losses[\"MSE\"].cpu().detach()/len_test_loader\n",
    "        unif_loss += dict_losses[\"uniform_loss\"].cpu().detach()/len_test_loader\n",
    "        curv_loss += dict_losses[\"curvature_loss\"].cpu().detach()/len_test_loader\n",
    "    input_dataset_tensor = torch.cat(input_dataset_list).view(-1,yaml_config[\"dataset\"][\"D\"])\n",
    "    var = torch.var(input_dataset_tensor.flatten())\n",
    "    R_squared = 1 - mse_loss/var\n",
    "    return mse_loss, unif_loss, curv_loss, R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_unif, test_curv, test_R_squared = compute_R_squared_losses(test_loader)\n",
    "#train_mse, train_unif, train_curv, train_R_squared, train_decoder_penalty = compute_R_squared_losses(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Train losses:\\nmse:{train_mse}, unif_loss:{train_unif}, decoder_penalty:{train_decoder_penalty}, curv_loss:{train_curv}\")\n",
    "#print(f\"R_squared: {train_R_squared.item():.4f}\")\n",
    "#print(f\"Test losses:\\nmse:{test_mse}\")\n",
    "print(f\"Test losses:\\nmse:{test_mse}, unif_loss:{test_unif}, curv_loss:{test_curv}\")\n",
    "print(f\"R_squared: {test_R_squared.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "from torcheval.metrics import R2Score\n",
    "R_squared = R2Score()#(multioutput=\"raw_values\")\n",
    "input = input_dataset_tensor.flatten()\n",
    "target = recon_dataset_tensor.flatten()\n",
    "R_squared.update(input, target)\n",
    "R_squared.compute()#.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yaml_config[\"experiment\"][\"weights_saved\"] == True:\n",
    "    PATH_ae = f'../nn_weights/{yaml_config[\"dataset\"][\"name\"]}_exp{yaml_config[\"experiment\"][\"experiment_number\"]}.pt'\n",
    "    torch.save(torus_ae.state_dict(), PATH_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss ploting\n",
    "if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "    #fig,axes = ricci_regularization.PlottingTools.plotsmart(dict2print)\n",
    "    fig,axes = ricci_regularization.PlottingTools.PlotSmartConvolve(dict2print)\n",
    "else:\n",
    "    fig,axes = ricci_regularization.PlottingTools.plotfromdict(dict_loss_arrays)\n",
    "if yaml_config[\"experiment\"][\"violent_saving\"] == True:\n",
    "    fig.savefig(f\"{Path_pictures}/losses_exp\"+str(yaml_config[\"experiment\"][\"experiment_number\"])+\".pdf\",bbox_inches='tight',format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig,axes = ricci_regularization.PlottingTools.plot9losses(mse_loss_array,curvature_loss_array,g_inv_meanperbatch_array)\n",
    "if yaml_config[\"experiment\"][\"violent_saving\"] == True:\n",
    "    fig.savefig(f\"{Path_pictures}/9losses_exp{yaml_config[\"experiment\"][\"experiment_number\"]}.pdf\",bbox_inches='tight',format=\"pdf\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspiration for torus_ae.encoder2lifting\n",
    "\"\"\"\n",
    "def circle2anglevectorized(zLatentTensor,d = yaml_config[\"architecture\"][\"latent_dim\"]):\n",
    "    cosphi = zLatentTensor[:, 0:yaml_config[\"architecture\"][\"latent_dim\"]]\n",
    "    sinphi = zLatentTensor[:, yaml_config[\"architecture\"][\"latent_dim\"]:2*yaml_config[\"architecture\"][\"latent_dim\"]]\n",
    "    phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "    return phi\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "#for (data, labels) in train_loader:\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    #zlist.append(torus_ae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,yaml_config[\"dataset\"][\"D\"])))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()/math.pi\n",
    "color_array = torch.cat(colorlist).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "if yaml_config[\"dataset\"][\"name\"] == \"Swissroll\":\n",
    "    my_cmap = \"jet\"\n",
    "else:\n",
    "    my_cmap = ricci_regularization.PlottingTools.discrete_cmap(yaml_config[\"dataset\"][\"k\"], 'jet')\n",
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array-1, marker='o', edgecolor='none', cmap=my_cmap)\n",
    "\n",
    "if yaml_config[\"dataset\"][\"name\"] in [\"Synthetic\",\"MNIST\",\"MNIST01\"]:\n",
    "    plt.colorbar(ticks=range(yaml_config[\"dataset\"][\"k\"]),orientation=\"vertical\")\n",
    "plt.grid(True)\n",
    "if yaml_config[\"experiment\"][\"violent_saving\"] == True:\n",
    "    plt.savefig(f\"{Path_pictures}/latent_space_exp\"+str(yaml_config[\"experiment\"][\"experiment_number\"])+\".pdf\",bbox_inches='tight',format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_config = {\n",
    "    \"experiment_name\": experiment_name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving json report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_config = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"experiment_number\": yaml_config[\"experiment\"][\"experiment_number\"],\n",
    "    \"dataset\": {\n",
    "        \"name\": yaml_config[\"dataset\"][\"name\"],\n",
    "        \"parameters\": {\n",
    "            \"k\": yaml_config[\"dataset\"].get(\"k\", None),\n",
    "            \"n\": yaml_config[\"dataset\"].get(\"n\", None),\n",
    "            \"D\": yaml_config[\"dataset\"].get(\"D\", None),\n",
    "            \"d\": yaml_config[\"dataset\"].get(\"d\", None),\n",
    "            \"shift_class\": yaml_config[\"dataset\"].get(\"shift_class\", None),\n",
    "            \"intercl_var\": yaml_config[\"dataset\"].get(\"intercl_var\", None),\n",
    "            \"var_class\": yaml_config[\"dataset\"].get(\"var_class\", None),\n",
    "            \"sr_noise\": yaml_config[\"dataset\"].get(\"sr_noise\", None)\n",
    "        },\n",
    "        \"selected_labels\": yaml_config[\"dataset\"].get(\"selected_labels\", None)\n",
    "    },\n",
    "    \"architecture\": {\n",
    "        \"name\": yaml_config[\"architecture\"][\"type\"], \n",
    "        \"input_dim\": yaml_config[\"architecture\"][\"output_dim\"],\n",
    "        \"latent_dim\": yaml_config[\"architecture\"][\"latent_dim\"]\n",
    "    },\n",
    "    \"optimization_parameters\": {\n",
    "        \"learning_rate\": yaml_config[\"optimizer_settings\"][\"lr\"],\n",
    "        \"batch_size\": yaml_config[\"data_loader_settings\"][\"batch_size\"],\n",
    "        \"split_ratio\": yaml_config[\"data_loader_settings\"][\"split_ratio\"],\n",
    "        \"num_epochs\": yaml_config[\"optimizer_settings\"][\"num_epochs\"],\n",
    "        \"weight_decay\": yaml_config[\"optimizer_settings\"][\"weight_decay\"],\n",
    "        \"random_shuffling\": yaml_config[\"data_loader_settings\"][\"random_shuffling\"],\n",
    "        \"random_seed\": yaml_config[\"data_loader_settings\"][\"random_seed\"]\n",
    "    },\n",
    "    \"losses\": {\n",
    "        \"lambda_recon\": yaml_config[\"loss_settings\"][\"lambda_recon\"],\n",
    "        \"lambda_unif\": yaml_config[\"loss_settings\"][\"lambda_unif\"],\n",
    "        \"Number of moments used\": yaml_config[\"loss_settings\"][\"num_moments\"],\n",
    "        \"lambda_curv\": yaml_config[\"loss_settings\"][\"lambda_curv\"],\n",
    "        \"delta_curv\": yaml_config[\"loss_settings\"][\"delta_curv\"],\n",
    "        \"curvature_penalization_mode\": yaml_config[\"loss_settings\"][\"curvature_penalization_mode\"],\n",
    "        \"g_inv regularization eps\": yaml_config[\"loss_settings\"][\"eps\"],\n",
    "        \"lambda_contractive_encoder\": yaml_config[\"loss_settings\"][\"lambda_contractive_encoder\"],\n",
    "        \"delta_encoder\": yaml_config[\"loss_settings\"][\"delta_encoder\"],\n",
    "        \"lambda_contractive_decoder\": yaml_config[\"loss_settings\"][\"lambda_contractive_decoder\"],\n",
    "        \"delta_decoder\": yaml_config[\"loss_settings\"][\"delta_decoder\"],\n",
    "        \"diagnostic_mode\": yaml_config[\"training_mode\"][\"diagnostic_mode\"],\n",
    "        \"compute_curvature\": yaml_config[\"training_mode\"][\"compute_curvature\"]\n",
    "    },\n",
    "    \"OOD_parameters\": {\n",
    "        \"OOD_regime\": yaml_config[\"training_mode\"][\"OOD_regime\"],\n",
    "        \"start_ood\": yaml_config[\"OOD_settings\"][\"start_ood\"],\n",
    "        \"T_ood\": yaml_config[\"OOD_settings\"][\"T_ood\"],\n",
    "        \"n_ood\": yaml_config[\"OOD_settings\"][\"n_ood\"],\n",
    "        \"sigma_ood\": yaml_config[\"OOD_settings\"][\"sigma_ood\"],\n",
    "        \"N_extr\": yaml_config[\"OOD_settings\"][\"N_extr\"],\n",
    "        \"r_ood\": yaml_config[\"OOD_settings\"][\"r_ood\"],\n",
    "        \"OOD_w\": yaml_config[\"OOD_settings\"][\"OOD_w\"]\n",
    "    },\n",
    "    \"Path_pictures\": f\"../experiments/{experiment_name}/experiment\"+str(yaml_config['experiment']['experiment_number']),\n",
    "    \"Path_weights\": \"../nn_weights/\",\n",
    "    \"Path_experiments\": \"../experiments/\"\n",
    "}\n",
    "if yaml_config[\"experiment\"][\"weights_saved\"] == True:\n",
    "    json_config[\"weights_saved_at\"] = PATH_ae\n",
    "if yaml_config[\"experiment\"][\"weights_loaded\"] == True:\n",
    "    json_config[\"weights_loaded_from\"] = PATH_weights_loaded\n",
    "# Save dictionary to JSON file\n",
    "with open(f\"../experiments/{experiment_name}exp\"+str(yaml_config[\"experiment\"][\"experiment_number\"])+\".json\", 'w') as json_file:\n",
    "    json.dump(json_config, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_results = {\n",
    "    \"training_results_on_test_data\": {\n",
    "        \"R^2\": test_R_squared,\n",
    "        \"mse_loss\": test_mse,  \n",
    "        \"unif_loss\": test_unif, \n",
    "        \"curv_loss\": test_curv  \n",
    "    }\n",
    "}\n",
    "if yaml_config[\"experiment\"][\"violent_saving\"] == True:\n",
    "    with open(f\"{Path_pictures}/exp\"+str(yaml_config[\"experiment\"][\"experiment_number\"])+\".json\", 'w') as json_file:\n",
    "        json.dump(json_results, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
