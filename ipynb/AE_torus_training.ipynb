{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torus AE training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the training of the autoencoder (AE). \n",
    "\n",
    "The AE consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is topologically a $d-$ dimensional torus $\\mathcal{T}^d$, i.e it can be considered as a periodic box $[-\\pi, \\pi]^d$. We define a Riemannian metric on the latent space  as the pull-back of the Euclidean metric in the output space $\\mathbb{R}^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi \\ .\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "One can switch on/off following training modes: \n",
    "\n",
    "- \"compute_curvature\"\n",
    "- \"diagnostic_mode\"\n",
    "- \"OOD_regime\"\n",
    "\n",
    "If \"compute_curvature\"==True, curvature functional is computed and latent space is regularized. One might want to turn it off for faster training for initial tuning of the parameters.\n",
    "\n",
    "If \"diagnostic_mode\"==True, following losses are plotted: MSE, $\\mathcal{L}_\\mathrm{unif}$, $\\mathcal{L}_\\mathrm{curv}$, $\\det(g)$, $\\|g_{reg}^{-1}\\|_F$, $\\|\\nabla \\Psi \\|^2_F$, $\\|\\nabla \\Phi \\|^2_F$, where:\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}_\\mathrm{curv} := \\int_M R^2 \\mu \\ ,\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}_\\mathrm{unif} := \\sum\\limits_{k=1}^{m} |\\int_M z^k  \\mu_N (dz) |^2 \\ ,\n",
    "\\end{equation*}\n",
    "where $R$ states for scalar curvature (see https://en.wikipedia.org/wiki/Scalar_curvature), $\\mu_N = \\Phi\\# ( \\frac{1}{N}\\sum\\limits_{j=1}^{N} \\delta_{X_i} ) $ is the push-forward of the natural measure induced by the dataset by the encoder $\\Phi$, thus $\\mu_N$ is a measure on $\\mathcal{T}^d$,  $ \\alpha_k = \\frac{1}{N} \\sum_{j=1}^{N} z_j^k$ is the empirical estimator of the $k$ -th moment of the data distribution in the latent space.\n",
    "\n",
    "If $\\xi \\sim \\mathcal{U}[-\\pi, \\pi]$ and $z = e^{i \\xi}$ than all the moments of $z$ are zero, namely if $\\mathcal{L}_\\mathrm{unif} \\to 0$ as $m \\to \\infty$, one obtains weak convergence of the data distribution in the latent space to the uniform distribution.\n",
    "\n",
    "Also $g_{reg} = g + \\varepsilon \\cdot I$ is the regularized matrix of metric for stability of inverse matrix computation, $\\|\\|_F$ is the Frobenius norm of the matrix.\n",
    "\n",
    "If \"OOD_regime\"==True, than OOD sampling is performed to refine the curvature regularization results.\n",
    "\n",
    "The notebook consists of\n",
    "\n",
    "1) Imports. Choosing hyperparameters for dataset uploading, learning and plotting such as learning rate, batch size, weights of MSE loss, curvature loss, etc. Automatic loading of train and test dataloaders. Choice among data sets \"Synthetic\", \"Swissroll\", \"MNIST\", \"MNIST01\" (any selected labels from MNIST). \n",
    "2) Architecture and device. Architecture types: Fully connected (TorusAE), Convolutional (TorusConvAE). Device: cuda/cpu. \n",
    "3) Training.\n",
    "4) Report of training. Printing of graphs of losses, saves of a json file with training params.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import ricci_regularization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters loading from YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the YAML configuration file\n",
    "with open('../experiments/Swissroll_exp1_config.yaml', 'r') as yaml_file: \n",
    "#with open('../experiments/MNIST01_exp9_config.yaml', 'r') as yaml_file:\n",
    "#with open('../experiments/MNIST_without_curvature_regularization_config.yaml','r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Print the loaded YAML configuration\n",
    "print(\"YAML Configuration loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the experiment_name\n",
    "print(\"Experiment Name:\", yaml_config[\"experiment\"][\"name\"])  # Print the constructed experiment name\n",
    "\n",
    "# Paths for saving  pictures\n",
    "Path_pictures = f\"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "print(f\"Path for experiment results: {Path_pictures}\")  # Print the path for pictures\n",
    "\n",
    "# Check and create directories based on configuration\n",
    "if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "    os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "    print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "else:\n",
    "    print(f\"Directiry already exists: {Path_pictures}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for data loader reproducibility\n",
    "torch.manual_seed(yaml_config[\"data_loader_settings\"][\"random_seed\"])\n",
    "print(f\"Set random seed to: {yaml_config['data_loader_settings']['random_seed']}\")\n",
    "\n",
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "\n",
    "# Calculate number of batches per epoch\n",
    "batches_per_epoch = len(train_loader)\n",
    "print(f\"Number of batches per epoch: {batches_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Architecture and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(yaml_config[\"data_loader_settings\"][\"random_seed\"])\n",
    "print(f\"Set random seed to: {yaml_config['data_loader_settings']['random_seed']}\")\n",
    "\n",
    "# Selecting the architecture type based on YAML configuration\n",
    "if yaml_config[\"architecture\"][\"type\"] == \"TorusConvAE\":\n",
    "    torus_ae = ricci_regularization.Architectures.TorusConvAE(\n",
    "        x_dim=yaml_config[\"architecture\"][\"output_dim\"],\n",
    "        h_dim1=512,\n",
    "        h_dim2=256,\n",
    "        z_dim=yaml_config[\"architecture\"][\"latent_dim\"],\n",
    "        pixels=28\n",
    "    )\n",
    "    print(\"Selected architecture: TorusConvAE\")\n",
    "else:\n",
    "    torus_ae = ricci_regularization.Architectures.TorusAE(\n",
    "        x_dim=yaml_config[\"architecture\"][\"output_dim\"],\n",
    "        h_dim1=512,\n",
    "        h_dim2=256,\n",
    "        z_dim=yaml_config[\"architecture\"][\"latent_dim\"]\n",
    "    )\n",
    "    print(\"Selected architecture: TorusAE\")\n",
    "\n",
    "# Check GPU availability and set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available! Training will use GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is NOT available! Using CPU.\")\n",
    "\n",
    "# Move the AE model to the selected device\n",
    "torus_ae.to(device)\n",
    "print(f\"Moved model to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yaml_config[\"experiment\"][\"weights_loaded_from\"] != False:\n",
    "    PATH_weights_loaded = yaml_config[\"experiment\"][\"weights_loaded_from\"]\n",
    "    torus_ae.load_state_dict(torch.load(PATH_weights_loaded))\n",
    "    torus_ae.eval()\n",
    "    print(f\"Weights loaded from {PATH_weights_loaded}\")\n",
    "else:\n",
    "    print(\"No pretrained weights loaded as per the config.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(torus_ae.parameters(),\n",
    "        lr=yaml_config[\"optimizer_settings\"][\"lr\"],\n",
    "        weight_decay=yaml_config[\"optimizer_settings\"][\"weight_decay\"])\n",
    "print(f\"Optimizer configured with learning rate {yaml_config['optimizer_settings']['lr']} and weight decay {yaml_config['optimizer_settings']['weight_decay']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss = MSE + uniform_loss + curv_loss + contractive_loss\n",
    "def loss_function(recon_data, data, z, decoder, compute_curvature = yaml_config[\"training_mode\"][\"compute_curvature\"]):\n",
    "    MSE = torch.nn.functional.mse_loss(recon_data, data.view(-1, yaml_config[\"architecture\"][\"input_dim\"]), reduction='mean')\n",
    "    unif_loss = ricci_regularization.LossComputation.uniform_loss( z,\n",
    "        latent_dim = yaml_config[\"architecture\"][\"latent_dim\"],\n",
    "        num_moments = yaml_config[\"loss_settings\"][\"num_moments\"])\n",
    "    \n",
    "    dict_losses = {\n",
    "        \"MSE\": MSE,\n",
    "        \"Uniform\": unif_loss,\n",
    "    }\n",
    "    compute_contractive_loss = yaml_config[\"training_mode\"][\"compute_contractive_loss\"]\n",
    "    if compute_contractive_loss == True:\n",
    "        dict_losses[\"Contractive\"] = torch.nn.ReLU()( ricci_regularization.Jacobian_norm_jacrev_vmap( \n",
    "                data, function = torus_ae.encoder_torus, \n",
    "                input_dim = yaml_config[\"architecture\"][\"input_dim\"] ) - yaml_config[\"loss_settings\"][\"delta_encoder\"]).max()\n",
    "    \n",
    "    if compute_curvature == True:\n",
    "        encoded_points_no_grad = torus_ae.encoder2lifting(data.view(-1, \n",
    "                    yaml_config[\"architecture\"][\"input_dim\"])).detach()\n",
    "        \n",
    "        metric_on_data = ricci_regularization.metric_jacfwd_vmap(encoded_points_no_grad,\n",
    "                                           function=decoder)\n",
    "        det_on_data = torch.det(metric_on_data)\n",
    "        Sc_on_data = ricci_regularization.Sc_jacfwd_vmap(encoded_points_no_grad,\n",
    "                                           function=decoder,eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "        \n",
    "        # switching between max and mean modes of curvature computation\n",
    "        dict_losses[\"Curvature\"] = (torch.sqrt(det_on_data)*torch.square(Sc_on_data)).mean()\n",
    "        if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "            dict_losses[\"curv_squared_mean\"] = (torch.square(Sc_on_data)).mean()\n",
    "            dict_losses[\"curv_squared_max\"] = (torch.square(Sc_on_data)).max()\n",
    "    \n",
    "    if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "        if compute_curvature == False:\n",
    "            encoded_points_no_grad = torus_ae.encoder2lifting(data.view(-1, yaml_config[\"architecture\"][\"input_dim\"])).detach()\n",
    "            metric_on_data = ricci_regularization.metric_jacfwd_vmap(encoded_points_no_grad,function=decoder)\n",
    "            det_on_data = torch.det(metric_on_data)    \n",
    "        g_inv_train_batch = torch.linalg.inv(metric_on_data + yaml_config[\"loss_settings\"][\"eps\"]*torch.eye(yaml_config[\"architecture\"][\"latent_dim\"]).to(device))\n",
    "        g_inv_norm_train_batch = torch.linalg.matrix_norm(g_inv_train_batch)\n",
    "        dict_losses[\"g_inv_norm_mean\"] = torch.mean(g_inv_norm_train_batch)\n",
    "        dict_losses[\"g_inv_norm_max\"] = torch.max(g_inv_norm_train_batch)\n",
    "        dict_losses[\"g_det_mean\"] = det_on_data.mean()\n",
    "        dict_losses[\"g_det_max\"] = det_on_data.max()\n",
    "        dict_losses[\"g_det_min\"] = det_on_data.min()\n",
    "        decoder_jac_norm = torch.func.vmap(torch.trace)(metric_on_data)\n",
    "        dict_losses[\"decoder_jac_norm_mean\"] = decoder_jac_norm.mean()\n",
    "        dict_losses[\"decoder_jac_norm_max\"] = decoder_jac_norm.max()\n",
    "        dict_losses[\"decoder_contractive_loss\"] = (torch.nn.ReLU()(decoder_jac_norm)).max()\n",
    "        metric_array_encoder = ricci_regularization.metric_jacrev_vmap(\n",
    "            data.view(-1, yaml_config[\"architecture\"][\"input_dim\"]),\n",
    "            function=torus_ae.encoder_torus,\n",
    "            latent_space_dim=yaml_config[\"architecture\"][\"input_dim\"]) # D here is not the latent space dimension (naming is counter-intuitive)!\n",
    "        encoder_jac_norm = torch.func.vmap(torch.trace)(metric_array_encoder)\n",
    "        encoder_jac_norm_mean = encoder_jac_norm.mean()\n",
    "        encoder_jac_norm_max = encoder_jac_norm.max()\n",
    "        dict_losses[\"encoder_jac_norm_mean\"] = encoder_jac_norm_mean\n",
    "        dict_losses[\"encoder_jac_norm_max\"] = encoder_jac_norm_max\n",
    "    return dict_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( epoch=1, batch_idx = 0, dict_loss_arrays={}):\n",
    "    #  creating a dict for losses shown in progress bar\n",
    "    dict_loss2print = {}\n",
    "    if batch_idx == 0:\n",
    "        dict_loss_arrays = {}\n",
    "    torus_ae.train()\n",
    "    print(\"Epoch %d\"%epoch)\n",
    "    t = tqdm( train_loader, desc=\"Train\", position=0 )\n",
    "\n",
    "    # OOD points initialization\n",
    "    if yaml_config[\"training_mode\"][\"OOD_regime\"] == True:\n",
    "        first_batch,_ = next(iter(train_loader))\n",
    "        first_batch = first_batch.to(device)\n",
    "        extreme_curv_points_tensor = torus_ae.encoder2lifting(first_batch.view(-1,yaml_config[\"architecture\"][\"input_dim\"])[:yaml_config[\"OOD_settings\"][\"N_extr\"]]).detach()\n",
    "        extreme_curv_points_tensor.to(device)\n",
    "        extreme_curv_value_tensor = ricci_regularization.Sc_jacfwd_vmap(extreme_curv_points_tensor, \n",
    "                function=torus_ae.decoder_torus,eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "    \n",
    "    for (data, labels) in t:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        recon_batch, z = torus_ae(data)\n",
    "\n",
    "        # Computing necessary losses on the current batch\n",
    "        dict_losses = loss_function(recon_batch, data, z,\n",
    "                                    decoder=torus_ae.decoder_torus)\n",
    "        # appending current losses to loss history\n",
    "        for key in dict_losses.keys():\n",
    "            if batch_idx == 0:\n",
    "                dict_loss_arrays[key] = []\n",
    "            # losses to keep in memory:\n",
    "            dict_loss_arrays[key].append(dict_losses[key].item())\n",
    "            # losses to show on progress bar: \n",
    "            dict_loss2print[key] = f\"{dict_losses[key].item():.4f}\"\n",
    "            # moving average (per epoch)\n",
    "            #dict_loss2print[key] = f\"{np.array(dict_loss_arrays[key])[-batches_per_epoch:].mean():.4f}\"\n",
    "        # end for \n",
    "        loss = yaml_config[\"loss_settings\"][\"lambda_recon\"] * dict_losses[\"MSE\"] \n",
    "        loss += yaml_config[\"loss_settings\"][\"lambda_unif\"] * dict_losses[\"Uniform\"] \n",
    "\n",
    "        if yaml_config[\"training_mode\"][\"compute_contractive_loss\"] == True:\n",
    "            # adding the contractive loss on the currenct batch to the loss function\n",
    "            loss += yaml_config[\"loss_settings\"][\"lambda_contractive_encoder\"] * dict_losses[\"Contractive\"]\n",
    "            \n",
    "        if (yaml_config[\"training_mode\"][\"compute_curvature\"] == True): \n",
    "            # adding the curvature loss on the currenct batch to the loss function\n",
    "            loss += yaml_config[\"loss_settings\"][\"lambda_curv\"] * dict_losses[\"Curvature\"]\n",
    "            \n",
    "        # OOD regime (optional)\n",
    "        if yaml_config[\"training_mode\"][\"OOD_regime\"] == True:\n",
    "            OOD_params_dict = yaml_config[\"OOD_settings\"]\n",
    "            extreme_curv_points_tensor, extreme_curv_value_tensor = ricci_regularization.find_extreme_curvature_points(\n",
    "                data_batch = data,\n",
    "                extreme_curv_points_tensor = extreme_curv_points_tensor,\n",
    "                extreme_curv_value_tensor = extreme_curv_value_tensor,\n",
    "                batch_idx = batch_idx,\n",
    "                encoder=torus_ae.encoder2lifting,decoder = torus_ae.decoder_torus,\n",
    "                OOD_params_dict = yaml_config[\"OOD_settings\"],\n",
    "                output_dim=yaml_config[\"architecture\"][\"input_dim\"])\n",
    "            \n",
    "            if (batch_idx % OOD_params_dict[\"T_ood\"] == 0) & (batch_idx >= yaml_config[\"OOD_settings\"][\"start_ood\"]):\n",
    "                OOD_curvature_loss = ricci_regularization.OODTools.curv_loss_on_OOD_samples(\n",
    "                    extreme_curv_points_tensor = extreme_curv_points_tensor,\n",
    "                    decoder = torus_ae.decoder_torus,\n",
    "                    OOD_params_dict = yaml_config[\"OOD_settings\"],\n",
    "                    latent_space_dim = yaml_config[\"architecture\"][\"latent_dim\"] )\n",
    "                if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "                    print(\"Curvature functional at OOD points\", OOD_curvature_loss)\n",
    "                loss = yaml_config[\"OOD_settings\"][\"OOD_w\"] * OOD_curvature_loss\n",
    "            #end if\n",
    "        #end if\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Progress bar plotting\n",
    "        t.set_postfix(dict_loss2print)\n",
    "        # Switching batch index\n",
    "        batch_idx += 1\n",
    "    #end for\n",
    "    return batch_idx, dict_loss_arrays\n",
    "\n",
    "def test(dict_loss_arrays = {}, batch_idx = 0):\n",
    "    dict_loss2print = {}\n",
    "    torus_ae.to(device)\n",
    "    t = tqdm( test_loader, desc=\"Test\", position=1 )\n",
    "    for data, _ in t:\n",
    "        data = data.to(device)\n",
    "        recon_batch, z = torus_ae(data)\n",
    "        dict_losses = loss_function(recon_batch, data, z,decoder=torus_ae.decoder_torus)\n",
    "        # appending current losses to loss history    \n",
    "        for key in dict_losses.keys():\n",
    "            if batch_idx == 0:\n",
    "                dict_loss_arrays[key] = []\n",
    "            dict_loss_arrays[key].append(dict_losses[key].item())\n",
    "            # mean losses to print\n",
    "            dict_loss2print[key] = f\"{dict_losses[key]:.4f}\"\n",
    "#            dict_loss2print[key] = f\"{np.array(dict_loss_arrays[key]).mean():.4f}\"\n",
    "        t.set_postfix(dict_loss2print)\n",
    "        # switch batch index\n",
    "        batch_idx+=1\n",
    "    #end for\n",
    "    return batch_idx, dict_loss_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "test_batch_idx = 0\n",
    "dict_loss_arrays = {}\n",
    "test_dict_loss_arrays = {}\n",
    "\n",
    "# Launch\n",
    "for epoch in range(1, yaml_config[\"optimizer_settings\"][\"num_epochs\"] + 1):\n",
    "  torus_ae.to(device)\n",
    "  batch_idx, dict_loss_arrays = train(epoch=epoch,batch_idx=batch_idx,dict_loss_arrays=dict_loss_arrays)\n",
    "  if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True :\n",
    "    dict2print = ricci_regularization.PlottingTools.translate_dict(dict2print=dict_loss_arrays, \n",
    "                include_curvature_plots=yaml_config[\"training_mode\"][\"compute_curvature\"],\n",
    "                eps=yaml_config[\"loss_settings\"][\"eps\"])\n",
    "    ricci_regularization.PlottingTools.plotsmart(dict2print)\n",
    "  #else:\n",
    "  #  ricci_regularization.PlottingTools.plotfromdict(dict_of_losses=dict_loss_arrays)  \n",
    "  if (yaml_config[\"dataset\"][\"name\"] == \"MNIST01\"):\n",
    "    ricci_regularization.PlottingTools.plot_ae_outputs_selected(\n",
    "      test_dataset=test_dataset,\n",
    "      encoder=torus_ae.cpu().encoder2lifting,\n",
    "      decoder=torus_ae.cpu().decoder_torus,\n",
    "      selected_labels=yaml_config[\"dataset\"][\"selected_labels\"] )\n",
    "  elif (yaml_config[\"dataset\"][\"name\"] == \"MNIST\"):\n",
    "    ricci_regularization.PlottingTools.plot_ae_outputs(\n",
    "      test_dataset=test_dataset,\n",
    "      encoder=torus_ae.cpu().encoder2lifting,\n",
    "      decoder=torus_ae.cpu().decoder_torus )\n",
    "  # end if\n",
    "  # Test \n",
    "  torus_ae.to(device)\n",
    "  test_batch_idx,test_dict_loss_arrays = test(batch_idx=test_batch_idx,dict_loss_arrays=test_dict_loss_arrays) \n",
    "  # end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Report of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test losses, $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_squared_losses(ae = torus_ae, data_loader = test_loader, \n",
    "                             device = device, input_dim = yaml_config[\"architecture\"][\"input_dim\"]):\n",
    "    len_test_loader = len(data_loader)\n",
    "    mse_loss = 0\n",
    "    curv_loss = 0\n",
    "    unif_loss = 0\n",
    "    input_dataset_list = []\n",
    "    ae.to(device)\n",
    "\n",
    "    for (data, labels) in data_loader:\n",
    "        data = data.to(device)\n",
    "        input_dataset_list.append(data.cpu())\n",
    "        input = data\n",
    "        recon = torus_ae(data)[0]\n",
    "        z = ae(data)[1]\n",
    "        enc = torus_ae.encoder2lifting(data.view(-1,input_dim))\n",
    "        dict_losses = loss_function(recon, input, z,\n",
    "                                    decoder=ae.decoder_torus,\n",
    "                                    compute_curvature=True)\n",
    "        \n",
    "        mse_loss += dict_losses[\"MSE\"].cpu().detach()/len_test_loader\n",
    "        unif_loss += dict_losses[\"Uniform\"].cpu().detach()/len_test_loader\n",
    "        curv_loss += dict_losses[\"Curvature\"].cpu().detach()/len_test_loader\n",
    "    input_dataset_tensor = torch.cat(input_dataset_list).view(-1,input_dim)\n",
    "    var = torch.var(input_dataset_tensor.flatten())\n",
    "    R_squared = 1 - mse_loss/var\n",
    "    return mse_loss, unif_loss, curv_loss, R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse, test_unif, test_curv, test_R_squared = compute_R_squared_losses(data_loader=test_loader, )\n",
    "print(f\"Test losses:\\nmse:{test_mse}, unif_loss:{test_unif}, curv_loss:{test_curv}\")\n",
    "print(f\"R_squared: {test_R_squared.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_ae = f'{Path_pictures}/ae_weights.pt'\n",
    "torch.save(torus_ae.state_dict(), PATH_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss ploting\n",
    "if yaml_config[\"training_mode\"][\"diagnostic_mode\"] == True:\n",
    "    #fig,axes = ricci_regularization.PlottingTools.plotsmart(dict2print)\n",
    "    fig,axes = ricci_regularization.PlottingTools.PlotSmartConvolve(dict2print)\n",
    "else:\n",
    "    fig,axes = ricci_regularization.PlottingTools.plotfromdict(dict_loss_arrays)\n",
    "fig.savefig(f\"{Path_pictures}/losses.pdf\",bbox_inches='tight',format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,yaml_config[\"architecture\"][\"input_dim\"])))\n",
    "    colorlist.append(labels) \n",
    "# end for\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()/math.pi\n",
    "color_array = torch.cat(colorlist).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the number of classes of data\n",
    "if yaml_config[\"dataset\"][\"name\"] == \"MNIST\":\n",
    "    k = 10\n",
    "elif yaml_config[\"dataset\"][\"name\"] == \"MNIST01\":\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "elif yaml_config[\"dataset\"][\"name\"] == \"Synthetic\":\n",
    "    k = yaml_config[\"dataset\"][\"k\"]\n",
    "\n",
    "# plotting latent space\n",
    "plt.figure(figsize=(8, 6))\n",
    "if yaml_config[\"dataset\"][\"name\"] == \"Swissroll\":\n",
    "    my_cmap = \"jet\"\n",
    "else:\n",
    "    my_cmap = ricci_regularization.PlottingTools.discrete_cmap(k, 'jet')\n",
    "p = plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array,\n",
    "             marker='o', edgecolor='none', cmap=my_cmap)\n",
    "if yaml_config[\"dataset\"][\"name\"] in [\"Synthetic\",\"MNIST\",\"MNIST01\"]:\n",
    "    # a smart way to place ticks nicely on a colorbar\n",
    "    from matplotlib.colors import  BoundaryNorm\n",
    "    bounds = np.linspace(-0.5, k - 0.5, k + 1)\n",
    "    norm = BoundaryNorm(bounds, my_cmap.N)\n",
    "    cbar = plt.colorbar(p, boundaries=bounds, norm=norm, ticks=np.arange(k))\n",
    "\n",
    "plt.grid( True )\n",
    "plt.savefig( Path_pictures + \"/latent_space.pdf\", bbox_inches = 'tight', format = \"pdf\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving json report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_results = {\n",
    "        \"R^2_test_data\": test_R_squared.item(),\n",
    "        \"mse_loss_test_data\": test_mse.item(),  \n",
    "        \"unif_loss_test_data\": test_unif.item(), \n",
    "        \"curv_loss_test_data\": test_curv.item()  \n",
    "}\n",
    "\n",
    "with open(f\"{Path_pictures}/results.json\", 'w') as json_file:\n",
    "    json.dump(json_results, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
