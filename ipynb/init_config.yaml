architecture:
  type: "TorusAE"  # Type of architecture being used
  # type = "TorusConvAE"  # Another type of architecture
  latent_dim: 2 # latent space dimension
  output_dim: 784 # output dimension

dataset:
  name: "MNIST01" # MNIST01 is a dataset with ANY two labels chosen from mnist
  #name: "Swissroll"
  #name: "Synthetic"
  #name: "MNIST"
  
  # Generating parameters for synthetic dataset
  k: 2              # number of classes
  n: 18000          # relevant for synthetic and Swissroll datasets
  D: 784            # dataset dim
  d: 2              # intrinstic latent space dimention
  shift_class: 0. 
  intercl_var: 0.1
  var_class: 1.   

  # Parameters for MNIST dataset  
  selected_labels: [5,8] # (Only for MNIST) Labels selected for the experiment
  
  # Parameters for Swissroll dataset
  sr_noise: 1e-06 # only for Swissroll

experiment:
  violent_saving: False  # If True a folder for experiment results is created and all plots will be saved there
  weights_loaded: False  # Flag indicating whether weights are loaded
  weights_saved: False  # Flag indicating whether weights should be saved
  experiment_name: "ISaidCallItExperiment9" # number of the current experiment

training_mode:
  diagnostic_mode: True  # Diagnostic mode flag
  compute_curvature: True  # Flag to indicate whether to compute curvature
  OOD_regime: True  # Out-of-distribution regime flag

loss_settings:
  lambda_recon: 1.0  # Weight for mean squared error in the loss function
  lambda_unif: 0.0005  # Weight for week convergence to uniform distribution in the loss function
  lambda_curv: 0.1  # Weight for curvature regularization
  lambda_contractive_decoder: 0.0  # Weight for contractive decoder in the loss function
  lambda_contractive_encoder: 0.0  # Weight for contractive encoder
  num_moments: 4  # Number of empirical moments of the distribution penalized in the loss function
  eps: 0.0  # Regularization parameter for inverse of metric computation (involved in Scalar curvature computation)
  delta_decoder: 2  # Threshold parameter for outliers of the decoder Frobenius norm
  #djnpm = "mean"  # Decoder Jacobian norm penalization mode (not used yet). Could be "mean" or "max"
  delta_encoder: 0.0  # Threshold parameter for the encoder Frobenius norm
  #ejnpm = "max"  # Encoder Jacobian norm penalization mode (not used yet). Could be "mean" or "max"
  curvature_penalization_mode: "mean"  # Mode for curvature penalization
  delta_curv: 0.1  # Delta parameter for curvature penalization (meaningful only if "curvature_penalization_mode == max")

optimizer_settings:
  lr: 0.001  # Learning rate for the optimizer
  num_epochs: 1  # Number of epochs for training
  weight_decay: 0.0  # Weight decay for the optimizer

data_loader_settings:
  batch_size: 128  # Batch size 
  split_ratio: 0.2  # Ratio for splitting the data into training and validation
  random_shuffling: false  # Flag to indicate whether to shuffle data randomly
  random_seed: 0  # Seed for random number generation

OOD_settings:
  T_ood: 20  # Period of OOD penalization
  n_ood: 5  # Number of OOD samples per point
  sigma_ood: 0.2  # Sigma of OOD Gaussian samples: 0.2 swissroll
  N_extr: 16  # Batch size of extremal curvature points
  r_ood: 0.001  # Decay factor
  OOD_w: 0.1  # Weight on curvature in OOD sampling
  start_ood: 0  # OOD starting batch
