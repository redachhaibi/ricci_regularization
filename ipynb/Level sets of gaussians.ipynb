{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for dataset\n",
    "D = 784       #dimension\n",
    "d = 2         # latent space dimension\n",
    "k = 3         # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "shift_class = 0\n",
    "intercl_var = 0.1 # this creates a gaussian, \n",
    "# i.e.random shift \n",
    "# proportional to the value of intercl_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for data loaders\n",
    "batch_size  = 32 # was 16 initially\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "# torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_w = 1.0\n",
    "curv_w = 1.0 #weight on curvature\n",
    "\n",
    "### Define the loss function\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr         = 2e-6\n",
    "momentum   = 0.8\n",
    "num_epochs = 2\n",
    "batches_per_plot = 50 #initially 200 \n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding path to the set generating package\n",
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "\n",
    "import ricci_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ricci_regularization as RR\n",
    "#import torchvision\n",
    "\n",
    "# Generate dataset \n",
    "\n",
    "# old style\n",
    "# train_dataset = ricci_regularization.generate_dataset(D, k, n, shift_class=shift_class, intercl_var=intercl_var)\n",
    "\n",
    "# via classes\n",
    "torch.manual_seed(0) # reproducibility\n",
    "my_dataset = RR.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                    shift_class=shift_class, intercl_var=intercl_var)\n",
    "\n",
    "train_dataset = my_dataset.create\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_data[:][0] will give the vectors of data without labels from the test part of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Declaration of AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is available\n",
    "cuda_on = torch.cuda.is_available()\n",
    "if cuda_on:\n",
    "    device  = torch.device(\"cuda\") \n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.linear4 = nn.Linear(128, hidden_dim)\n",
    "        #self.activation = nn.ELU()\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear4(y)\n",
    "        out = self.activation(y)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative 2layer simplified decoder\n",
    "\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, output_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = torch.nn.functional.relu(self.linear1(z))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        #return z.reshape((-1, 1, 28, 28))\n",
    "        return z\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClassicalAE\n",
    "encoder = Encoder(input_dim=784, hidden_dim=d)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=784)\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.RMSprop(params_to_optimize, lr=lr, momentum=momentum, weight_decay=0.0)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III*. Adding Curvature functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization as RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RR.metric_jacfwd_vmap(torch.rand(10,2),function=decoder).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choice of curvature functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func(encoded_data):\n",
    "    metric_on_data = RR.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    det_on_data = torch.det(metric_on_data)\n",
    "    Sc_on_data = RR.Sc_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    N = metric_on_data.shape[0]\n",
    "    Integral_of_Sc = (1/N)*(torch.sqrt(det_on_data)*torch.square(Sc_on_data)).sum()\n",
    "    return Integral_of_Sc\n",
    "\n",
    "\"\"\"\n",
    "# minimizing |g-I|_F\n",
    "def Func(encoded_data):\n",
    "    metric_on_data = RR.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    N = metric_on_data.shape[0]\n",
    "    func = (1/N)*(metric_on_data-torch.eye(d)).norm(dim=(1,2)).sum()\n",
    "    return func\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III**. Plotting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(encoder, data, batch_idx):\n",
    "\n",
    "    labels = data[:][1]\n",
    "    data   = data[:][0]\n",
    "\n",
    "    # Encode\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.view(-1,28*28) # reshape the img\n",
    "        data = data.to(device)\n",
    "        encoded_data = encoder(data)\n",
    "\n",
    "    # Record codes\n",
    "    latent = encoded_data.cpu().numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    #Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, marker='o', edgecolor='none', cmap=discrete_cmap(k, 'jet'))\n",
    "    plt.title( f'''Latent space for test data in AE at batch {batch_idx}''')\n",
    "    plt.colorbar(ticks=range(k))\n",
    "    axes = plt.gca()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches per epoch\n",
    "print( \"Reality check of batch splitting: \")\n",
    "print( \"-- Batches per epoch\", len(train_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(train_loader)*batch_size )\n",
    "print( \"-- To be compared to:\", (1.0-split_ratio)*n*k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches per epoch\n",
    "print( \"Reality check of batch splitting: \")\n",
    "print( \"-- Batches per epoch\", len(test_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(test_loader)*batch_size )\n",
    "print( \"-- To be compared to:\", split_ratio*n*k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 0 # to enumerate the plots\n",
    "batch_idx = 0\n",
    "\n",
    "mse_loss = []\n",
    "curv_loss = []\n",
    "test_mse_loss_list = []\n",
    "test_curv_loss_list = []\n",
    "\n",
    "# to iterate though the batches of test data \n",
    "# simoultanuousely with train data\n",
    "iter_test_loader = iter(test_loader)\n",
    "      \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "   # Set train mode for both the encoder and the decoder\n",
    "   encoder.train()\n",
    "   decoder.train()\n",
    "   \n",
    "   \n",
    "   # Iterate the dataloader: no need  for the label\n",
    "   # values, this is unsupervised learning\n",
    "   for image_batch, _ in train_loader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "      #shaping the images properly\n",
    "      image_batch = image_batch.view(-1,28*28)\n",
    "      # Move tensor to the proper device\n",
    "      image_batch = image_batch.to(device)\n",
    "      # True batch size\n",
    "      true_batch_size = image_batch.shape[0]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # Front-propagation\n",
    "      # -- Encode data\n",
    "      encoded_data = encoder(image_batch)\n",
    "      # -- Decode data\n",
    "      decoded_data = decoder(encoded_data)\n",
    "      # --Evaluate loss\n",
    "      mse_loss_batch = torch.sum( (decoded_data-image_batch)**2 )/true_batch_size\n",
    "      curvature_train_batch = Func(encoded_data)\n",
    "      \n",
    "      loss = mse_w*mse_loss_batch + curv_w*curvature_train_batch\n",
    "      \n",
    "      # Backward pass\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # Print batch loss\n",
    "      #print('\\t MSE loss per batch (single batch): %f' % (mse_loss_batch.data))\n",
    "      #print('\\t Total loss per batch (single batch): %f' % (loss.data))\n",
    "      \n",
    "      if batch_idx % len(test_loader):\n",
    "         iter_test_loader = iter(test_loader)\n",
    "      test_images = next(iter_test_loader)[0].view(-1,D).to(device)\n",
    "      encoded_test_data = encoder(test_images)\n",
    "      decoded_test_data = decoder(encoded_test_data)\n",
    "\n",
    "      # True test_batch size\n",
    "      true_test_batch_size = test_images.shape[0]\n",
    "      with torch.no_grad():\n",
    "         test_mse_loss = torch.sum( (decoded_test_data - test_images)**2 )/true_test_batch_size\n",
    "         test_mse_loss_list.append(test_mse_loss.detach().cpu().numpy())\n",
    "         test_curv_loss = Func(encoded_test_data)\n",
    "         test_curv_loss_list.append(test_curv_loss.detach().cpu().numpy())\n",
    "      #print('\\t test MSE loss per batch (single batch): %f' % (test_mse_loss.data))\n",
    "      #print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "      \n",
    "      mse_loss.append(float(mse_loss_batch.detach().cpu().numpy()))\n",
    "      curv_loss.append(float(curvature_train_batch.detach().cpu().numpy()))\n",
    "\n",
    "      # Plot and compute test loss      \n",
    "      if (batch_idx % batches_per_plot == 0):\n",
    "         #test loss\n",
    "\n",
    "         #plotting\n",
    "         plot = point_plot(encoder, test_data, batch_idx)\n",
    "         plot.savefig('../plots/pointplots_in_training_testdata/pp{0}.png'.format(num_plots))\n",
    "         num_plots += 1\n",
    "         plot.show()\n",
    "\n",
    "         # plotting losses\n",
    "         if batch_idx>0:\n",
    "            fig, ax1 = plt.subplots()\n",
    "\n",
    "            ax1.set_xlabel('Batches')\n",
    "            ax1.set_ylabel('MSE')\n",
    "            ax1.plot(mse_loss, label='train_MSE_loss', color='tab:orange')\n",
    "            ax1.plot(test_mse_loss_list, label='test_MSE_loss', color='tab:red')\n",
    "            \n",
    "            ax1.tick_params(axis='y')\n",
    "            plt.legend(loc='lower left')\n",
    "\n",
    "            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "            ax2.set_ylabel('Curvature')  # we already handled the x-label with ax1\n",
    "            ax2.semilogy(curv_loss, label='train_Curv_loss',color='tab:olive')\n",
    "            ax2.semilogy(test_curv_loss_list, label='test_Curv_loss', color='tab:green')\n",
    "            \n",
    "            ax2.tick_params(axis='y')\n",
    "            plt.legend(loc='lower right')\n",
    "            fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "            plt.show()\n",
    "            # end if\n",
    "       # end if\n",
    "      batch_idx += 1\n",
    "   # end for\n",
    "   print('\\n EPOCH {}/{} \\t MSE loss: {}, Curvature loss: {}'.format(epoch + 1, num_epochs, np.mean(mse_loss),np.mean(curv_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17}) # makes all fonts on the plot be 24\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Batches')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.plot(mse_loss, label='train_MSE_loss', color='tab:orange')\n",
    "ax1.plot(test_mse_loss_list, label='test_MSE_loss', color='tab:red')\n",
    "\n",
    "ax1.tick_params(axis='y')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('Curvature')  # we already handled the x-label with ax1\n",
    "ax2.semilogy(curv_loss, label='train_Curv_loss',color='tab:olive')\n",
    "ax2.semilogy(test_curv_loss_list, label='test_Curv_loss', color='tab:green')\n",
    "\n",
    "\n",
    "ax2.tick_params(axis='y')\n",
    "plt.legend(loc='upper right')\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.title(\"Params: lr={0}, batch_size={1},\\n $\\lambda_r$={2}, $\\lambda_c$={3}\".format(lr,batch_size,mse_w,curv_w))\n",
    "plt.show()\n",
    "#plt.savefig('../plots/losses_2layers_decoder.png'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "REDO LATER $\\lambda_{recon}$ inside a string\n",
    "tex_string = \"$\\lambda_{recon}$\"\n",
    "s = f''' toto {tex_string}'''\n",
    "print( s )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level sets of gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rotation matrices \\phi_j and shifts y_j \n",
    "# from the set construction\n",
    "phi = my_dataset.rotations\n",
    "shifts = my_dataset.shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disc of circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "plt.title( \"Canonical version of disc\" )\n",
    "radius_array = torch.sqrt( torch.linspace(0, 1, 40) )\n",
    "theta_array  = torch.linspace(0, 1-1/100, 100)\n",
    "x = torch.cos( 2*torch.pi*theta_array )\n",
    "y = torch.sin( 2*torch.pi*theta_array )\n",
    "for r in radius_array:\n",
    "    r = r.item() # extracting the value of r\n",
    "    plt.scatter( r*x, r*y, c=theta_array, marker='.', cmap='hsv', alpha=1-r )\n",
    "# end for \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk with colormap by polar angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "num_circles = 40 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3\n",
    "\n",
    "radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in \\n the latent space in plane # {plane_idx} with $\\lambda_c=${curv_w}''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        #print(\"theta:\",theta)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        #print(\"x:\",x_array)\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        #print(\"y\",y_array)\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        #circle = design_circle(100, rad=(j+1)*2)\n",
    "        #plot.scatter(x_array,y_array)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        #plt.scatter(circle_in_D[:,0],circle_in_D[:,1])\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1],c=theta, marker='.', cmap='hsv', alpha=1-rad/maxrad)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        #print(rad)\n",
    "    ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "num_circles = 40 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3\n",
    "\n",
    "radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in \\n the latent space in plane # {plane_idx} with $\\lambda_c=${curv_w}''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        plt.grid(True)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "num_circles = 30 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 20\n",
    "\n",
    "radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space with $\\lambda_c=${curv_w}''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        # color by rad\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        # colorby polar angle\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1],c=theta, marker='.', cmap='hsv', alpha=1-rad/maxrad)\n",
    "        plt.grid(True)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "torch.manual_seed(0)\n",
    "samples_over_latent_space = torch.rand(N,2)-1.0\n",
    "\n",
    "#visualize samples\n",
    "plot.scatter(samples_over_latent_space[:,0],samples_over_latent_space[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_at_samples = RR.metric_jacfwd_vmap(samples_over_latent_space,function=decoder).detach()\n",
    "eigenvalues = torch.linalg.eigvalsh(metric_at_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_eigenvalues = eigenvalues[:,0]\n",
    "max_eigenvalues = eigenvalues[:,1]\n",
    "all_eigenvalues = torch.cat((min_eigenvalues,max_eigenvalues),dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "plt.title(f\"Histogram of eigenvalues of metric $G$ evaluated \\n at {N} samples uniformly distributed \\n over the latent space with penalty \\n on curvature $\\lambda_c=${curv_w}\")\n",
    "plt.hist(all_eigenvalues, bins=round(math.sqrt(N)))\n",
    "plt.xlabel(\"All eigenvalues of metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "plt.title(f\"Histogram of minimal eigenvalues of metric $G$ evaluated at {N} \\n samples uniformly distributed over the latent space \")\n",
    "plt.hist(min_eigenvalues, bins=round(math.sqrt(N)))\n",
    "plt.xlabel(\"Min eigenvalues of metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_eigenvalues, bins=round(math.sqrt(N)))\n",
    "plt.title(f\"Histogram of maximal eigenvalues of metric $G$ evaluated at {N} \\n samples uniformly distributed over the latent space \")\n",
    "plt.xlabel(\"Max eigenvalues of metric\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
