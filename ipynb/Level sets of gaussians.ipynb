{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Hyperpameters: set and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#experiment_name = \"current experiment\"\n",
    "experiment_name = \"swissroll_curv_func_oscilations_curv_w=10_eps=0.01\"\n",
    "#experiment_name = \"synthetic_curv_w=1e+1_ls=R^2+OOD\"\n",
    "#experiment_name = \"swissroll_OOD_curv_w=10_sigma_ood=0.2_T_OOD=20_OOD_w=10_20epochs\"\n",
    "#experiment_name = \"synthetic_curv_w=1e+1_ls=R^2\"\n",
    "\n",
    "\n",
    "build_report = True\n",
    "weights_loaded = True\n",
    "violent_saving = True # if False it will not save plots\n",
    "model_weights_saved = False\n",
    "load_weight_name = experiment_name\n",
    "#load_weight_name = \"current_experiment\"\n",
    "save_weight_name = experiment_name\n",
    "#save_weight_name = \"swissroll_curv_w=1_ls=R^2_40epochs_bs=16\"\n",
    "# here you can choose a path for saving the pictures \n",
    "Path_pictures = f\"/home/alazarev/CodeProjects/Experiments/{experiment_name}\"\n",
    "if os.path.exists(Path_pictures) == False:\n",
    "    os.mkdir(Path_pictures) # needs to be commented once the folder for plots is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for dataset\n",
    "#set_name = \"Synthetic\"\n",
    "#where_to_compute_curv = \"random\"\n",
    "where_to_compute_curv = \"batch\"\n",
    "\n",
    "set_name = \"Swissroll\"\n",
    "sr_noise = 0.05\n",
    "sr_numpoints = 18000 #k*n\n",
    "\n",
    "#D = 784       #dimension\n",
    "#D = 2\n",
    "if set_name == \"Swissroll\":\n",
    "    D = 3 # for swissroll\n",
    "elif set_name == \"Synthetic\":\n",
    "    D = 784\n",
    "d = 2         # latent space dimension\n",
    "k = 3         # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "shift_class = 0\n",
    "var_class = 1 # variation of each Gaussian initially 0.1\n",
    "intercl_var = 0.1 # this creates a Gaussian, \n",
    "# i.e.random shift \n",
    "# proportional to the value of intercl_var\n",
    "# initially 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klw = 0 # AE mode on\n",
    "\n",
    "#klw = 5e-3 #VAE mode on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for data loaders\n",
    "batch_size  = 32 # was 32 initially\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "# torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_w = 1.0\n",
    "curv_w = 10.0 #weight on curvature\n",
    "compute_curvature = True\n",
    "\n",
    "### Define the loss function\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr         = 2e-5 #initially 4e-5 for synthetic, 1e-4 for swissroll\n",
    "momentum   = 0.8 #initially 0.8\n",
    "num_epochs = 20 #initially 40\n",
    "batches_per_plot = 400 #initially 200 \n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "# torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# adding path to the set generating package\n",
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization as RR\n",
    "#import torchvision\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I*. Choosing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_name == \"Synthetic\":\n",
    "    # Generate dataset \n",
    "\n",
    "    # old style\n",
    "    # train_dataset = ricci_regularization.generate_dataset(D, k, n, shift_class=shift_class, intercl_var=intercl_var)\n",
    "\n",
    "    # via classes\n",
    "    torch.manual_seed(0) # reproducibility\n",
    "    my_dataset = RR.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                        shift_class=shift_class,\n",
    "                                        var_class = var_class, \n",
    "                                        intercl_var=intercl_var)\n",
    "\n",
    "    train_dataset = my_dataset.create\n",
    "elif set_name == \"Swissroll\":\n",
    "    train_dataset =  sklearn.datasets.make_swiss_roll(n_samples=sr_numpoints, noise=sr_noise, random_state=1)\n",
    "    sr_points = torch.from_numpy(train_dataset[0]).to(torch.float32)\n",
    "    #sr_points = torch.cat((sr_points,torch.zeros(sr_numpoints,D-3)),dim=1)\n",
    "    sr_colors = torch.from_numpy(train_dataset[1]).to(torch.float32)\n",
    "    from torch.utils.data import TensorDataset\n",
    "    train_dataset = TensorDataset(sr_points,sr_colors) \n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "# test_data[:][0] will give the vectors of data without labels from the test part of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. AE declatation and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is available\n",
    "cuda_on = torch.cuda.is_available()\n",
    "if cuda_on:\n",
    "    device  = torch.device(\"cuda\") \n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sine AE\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.linear4 = nn.Linear(128, hidden_dim)\n",
    "        #self.activation = nn.ReLU()\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        return out\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        self.activation = torch.sin\n",
    "        #self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out\n",
    "\"\"\"\n",
    "            \n",
    "# RelU-sine AE\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.linear4 = nn.Linear(128, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        #self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        #out = torch.sin(out)\n",
    "        return out\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        #self.activation = torch.sin\n",
    "        self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# initial structure\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.linear4 = nn.Linear(128, hidden_dim)\n",
    "        #self.activation = nn.ReLU()\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        out = self.activation(out)\n",
    "        return out\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        #self.activation = nn.ReLU()\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        out = self.activation(out)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, cuda=True):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, hidden_dim)\n",
    "        self.linear3 = nn.Linear(512, hidden_dim)\n",
    "        \n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        if cuda:\n",
    "            self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "            self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.sin(self.linear1(x)) \n",
    "        mu =  self.linear2(x)\n",
    "        sigma = torch.exp(self.linear3(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially D=784, d=2\n",
    "# AE/VAE switch\n",
    "if klw > 0:\n",
    "    encoder = VariationalEncoder(input_dim=784, hidden_dim=d, cuda=cuda_on)\n",
    "else:\n",
    "    encoder = Encoder(input_dim=D, hidden_dim=d)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=D)\n",
    "\n",
    "# ClassicalAE\n",
    "#encoder = Encoder(input_dim=D, hidden_dim=d)\n",
    "#decoder = Decoder(hidden_dim=d, output_dim=D)\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.RMSprop(params_to_optimize, lr=lr, momentum=momentum, weight_decay=0.0)\n",
    "\n",
    "#optimizer = torch.optim.Adam(params_to_optimize, lr=lr,weight_decay=0.0)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weights_loaded==True:\n",
    "    PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "    encoder.load_state_dict(torch.load(PATH_enc))\n",
    "    encoder.eval()\n",
    "    PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "    decoder.load_state_dict(torch.load(PATH_dec))\n",
    "    decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choice of curvature functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Func(encoded_data):\n",
    "    metric_on_data = RR.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    det_on_data = torch.det(metric_on_data)\n",
    "    Sc_on_data = RR.Sc_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    N = metric_on_data.shape[0]\n",
    "    Integral_of_Sc = (1/N)*(torch.sqrt(det_on_data)*torch.square(Sc_on_data)).sum()\n",
    "    return Integral_of_Sc\n",
    "\"\"\"\n",
    "# minimizing |g-I|_F\n",
    "def Func(encoded_data):\n",
    "    metric_on_data = RR.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=decoder)\n",
    "    N = metric_on_data.shape[0]\n",
    "    func = (1/N)*(metric_on_data-torch.eye(d)).norm(dim=(1,2)).sum()\n",
    "    return func\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Plotting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\"\"\"\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(encoder, data, batch_idx, show_title = True, colormap = 'jet',s=40,draw_grid = True,figsize = (8, 6)):\n",
    "\n",
    "    labels = data[:][1]\n",
    "    data   = data[:][0]\n",
    "\n",
    "    # Encode\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.view(-1,D) # reshape the img\n",
    "        data = data.to(device)\n",
    "        encoded_data = encoder(data)\n",
    "\n",
    "    # Record codes\n",
    "    latent = encoded_data.cpu().numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    #Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if set_name == \"Swissroll\":\n",
    "        plt.scatter( latent[:,0], latent[:,1],s=s, c=labels, alpha=0.5, marker='o', edgecolor='none', cmap=colormap)\n",
    "    else:\n",
    "        plt.scatter( latent[:,0], latent[:,1],s=s, c=labels, alpha=0.5, marker='o', edgecolor='none', cmap=discrete_cmap(k, colormap))\n",
    "        #plt.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, marker='o')\n",
    "        plt.colorbar(ticks=range(k),orientation='vertical',shrink = 0.7)\n",
    "    if show_title == True:\n",
    "        plt.title( f'''Latent space for test data in AE at batch {batch_idx}''')\n",
    "    axes = plt.gca()\n",
    "    plt.grid(draw_grid)\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches per epoch\n",
    "print( \"Reality check of batch splitting: \")\n",
    "print( \"-- Batches per epoch\", len(train_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(train_loader)*batch_size )\n",
    "print( \"-- To be compared to:\", (1.0-split_ratio)*n*k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches per epoch\n",
    "print( \"Reality check of batch splitting: \")\n",
    "print( \"-- Batches per epoch\", len(test_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(test_loader)*batch_size )\n",
    "print( \"-- To be compared to:\", split_ratio*n*k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 0 # to enumerate the plots\n",
    "batch_idx = 0\n",
    "batches_per_epoch = len(train_loader)\n",
    "\n",
    "mse_loss = []\n",
    "kl_loss = []\n",
    "curv_loss = []\n",
    "test_mse_loss_list = []\n",
    "test_curv_loss_list = []\n",
    "\n",
    "# to iterate though the batches of test data \n",
    "# simoultanuousely with train data\n",
    "iter_test_loader = iter(test_loader)\n",
    "      \n",
    "for epoch in range(num_epochs):\n",
    "   if weights_loaded == True:\n",
    "      break\n",
    "   # Set train mode for both the encoder and the decoder\n",
    "   encoder.train()\n",
    "   decoder.train()\n",
    "   \n",
    "   \n",
    "   # Iterate the dataloader: no need  for the label\n",
    "   # values, this is unsupervised learning\n",
    "   for image_batch, _ in train_loader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "      #shaping the images properly\n",
    "      image_batch = image_batch.view(-1,D)\n",
    "      # Move tensor to the proper device\n",
    "      image_batch = image_batch.to(device)\n",
    "      # True batch size\n",
    "      true_batch_size = image_batch.shape[0]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # Front-propagation\n",
    "      # -- Encode data\n",
    "      encoded_data = encoder(image_batch)\n",
    "      # -- Decode data\n",
    "      decoded_data = decoder(encoded_data)\n",
    "      # --Evaluate loss\n",
    "      mse_loss_batch = torch.sum( (decoded_data-image_batch)**2 )/true_batch_size\n",
    "      \n",
    "      if compute_curvature == True:\n",
    "         if where_to_compute_curv == \"batch\":\n",
    "            curvature_train_batch = Func(encoded_data)\n",
    "         elif where_to_compute_curv == \"random\":\n",
    "            curvature_train_batch = Func(2*torch.rand(batch_size,2)-1)\n",
    "      else:\n",
    "         curvature_train_batch = 0.0\n",
    "      \n",
    "      loss = mse_w*mse_loss_batch + curv_w*curvature_train_batch\n",
    "      \n",
    "      # if VAE mode is on\n",
    "      if klw > 0:\n",
    "          kl_loss_batch = encoder.kl \n",
    "          loss += klw*kl_loss_batch\n",
    "          kl_loss.append(kl_loss_batch.data)\n",
    "      else:\n",
    "          kl_loss_batch = 0.0\n",
    "\n",
    "      # Backward pass\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # Print batch loss\n",
    "      #print('\\t MSE loss per batch (single batch): %f' % (mse_loss_batch.data))\n",
    "      #print('\\t Total loss per batch (single batch): %f' % (loss.data))\n",
    "\n",
    "      if batch_idx % len(test_loader):\n",
    "         iter_test_loader = iter(test_loader)\n",
    "      test_images = next(iter_test_loader)[0].view(-1,D).to(device)\n",
    "      encoded_test_data = encoder(test_images)\n",
    "      decoded_test_data = decoder(encoded_test_data)\n",
    "\n",
    "      # True test_batch size\n",
    "      true_test_batch_size = test_images.shape[0]\n",
    "      with torch.no_grad():\n",
    "         test_mse_loss = torch.sum( (decoded_test_data - test_images)**2 )/true_test_batch_size\n",
    "         test_mse_loss_list.append(test_mse_loss.detach().cpu().numpy())\n",
    "         if compute_curvature == True:\n",
    "            test_curv_loss = Func(encoded_test_data)\n",
    "            test_curv_loss_list.append(test_curv_loss.detach().cpu().numpy())\n",
    "         # end if\n",
    "      # end with\n",
    "      #print('\\t test MSE loss per batch (single batch): %f' % (test_mse_loss.data))\n",
    "      #print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "      \n",
    "      mse_loss.append(float(mse_loss_batch.detach().cpu().numpy()))\n",
    "      if compute_curvature == True:\n",
    "         curv_loss.append(float(curvature_train_batch.detach().cpu().numpy()))\n",
    "\n",
    "      # Plot and compute test loss      \n",
    "      if (batch_idx % batches_per_plot == 0):\n",
    "         #test loss\n",
    "\n",
    "         #plotting\n",
    "         plot = point_plot(encoder, test_data, batch_idx)\n",
    "         if violent_saving == True:\n",
    "            plot.savefig('../plots/pointplots_in_training_testdata/pp{0}.eps'.format(num_plots),format='eps')\n",
    "         num_plots += 1\n",
    "         plot.show()\n",
    "\n",
    "         # plotting losses\n",
    "         if batch_idx>0:\n",
    "            fig, ax1 = plt.subplots()\n",
    "\n",
    "            ax1.set_xlabel('Batches')\n",
    "            ax1.set_ylabel('MSE')\n",
    "            ax1.semilogy(mse_loss, label='train_MSE_loss', color='tab:orange')\n",
    "            ax1.semilogy(test_mse_loss_list, label='test_MSE_loss', color='tab:red')\n",
    "            \n",
    "            ax1.tick_params(axis='y')\n",
    "            plt.legend(loc='lower left')\n",
    "\n",
    "            if compute_curvature == True:\n",
    "\n",
    "               ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "               ax2.set_ylabel('Curvature')  # we already handled the x-label with ax1\n",
    "               ax2.semilogy(curv_loss, label='train_Curv_loss',color='tab:olive')\n",
    "               ax2.semilogy(test_curv_loss_list, label='test_Curv_loss', color='tab:green')\n",
    "               \n",
    "               ax2.tick_params(axis='y')\n",
    "               plt.legend(loc='lower right')\n",
    "            # end if\n",
    "            fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "            plt.show()\n",
    "            # end if\n",
    "       # end if\n",
    "      batch_idx += 1\n",
    "   # end for\n",
    "   #print('\\n EPOCH {}/{}. \\t Average values over epoch:\\n MSE loss: {}, Curvature loss: {}'.format(epoch + 1, num_epochs, np.mean(mse_loss[-batches_per_epoch:]),np.mean(curv_loss[-batches_per_epoch:])))\n",
    "   print(f'\\n EPOCH {epoch + 1}/{num_epochs}. \\t Average values over epoch:\\n MSE loss: {np.mean(mse_loss[-batches_per_epoch:])}, Curvature loss: {np.mean(curv_loss[-batches_per_epoch:])}, KL loss: {np.mean(kl_loss[-batches_per_epoch:])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_weights_saved == True):\n",
    "    PATH_enc = f'../nn_weights/encoder_{save_weight_name}'\n",
    "    torch.save(encoder.state_dict(), PATH_enc)\n",
    "    PATH_dec = f'../nn_weights/decoder_{save_weight_name}'\n",
    "    torch.save(decoder.state_dict(), PATH_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determination coefficient and training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_name == \"Swissroll\":\n",
    "    points_tensor = torch.tensor(sr_points)\n",
    "    cov_matrix = torch.cov(points_tensor.T)\n",
    "    print(\"Covariance matrix:\\n\", cov_matrix)\n",
    "    mean = points_tensor.mean(dim=0)\n",
    "    print(\"Mean vector:\", mean)\n",
    "    R_squared = 1 - ((decoder(encoder(sr_points)).data-sr_points).norm()**2)/((sr_points-mean).norm()**2)\n",
    "    print(\"Determination coef R^2:\", R_squared)\n",
    "    MSE = (1/sr_numpoints)*(decoder(encoder(sr_points)).data-sr_points).norm()**2\n",
    "    print(\"MSE:\", MSE)\n",
    "    print(\"tr(Q):\", cov_matrix.trace())\n",
    "    print(\"MSE/tr(Q):\", MSE/cov_matrix.trace())\n",
    "    print(\"R^2 = 1-MSE/tr(Q):\", 1-MSE/cov_matrix.trace())\n",
    "elif set_name ==\"Synthetic\":\n",
    "    points_tensor = train_dataset[:][0]\n",
    "    cov_matrix = torch.cov(points_tensor.T)\n",
    "    #print(\"Covariance matrix:\\n\", cov_matrix)\n",
    "    mean = points_tensor.mean(dim=0)\n",
    "    #print(\"Mean vector:\", mean)\n",
    "    R_squared = 1 - ((decoder(encoder(points_tensor)).data-train_dataset[:][0]).norm()**2)/((train_dataset[:][0]-mean).norm()**2)\n",
    "    print(\"Determination coef R^2:\", R_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_loss_on_train_data = Func(encoder(train_data[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 17}) # makes all fonts on the plot be 24\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('Batches')\n",
    "ax1.set_ylabel('MSE')\n",
    "ax1.semilogy(mse_loss, label='train_MSE_loss', color='tab:orange')\n",
    "ax1.semilogy(test_mse_loss_list, label='test_MSE_loss', color='tab:red')\n",
    "\n",
    "ax1.tick_params(axis='y')\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "if compute_curvature == True:\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    #ax2.set_ylabel('G-I loss')\n",
    "    ax2.set_ylabel('Curvature')  # we already handled the x-label with ax1\n",
    "    ax2.semilogy(curv_loss, label='train_Curv_loss',color='tab:olive')\n",
    "    ax2.semilogy(test_curv_loss_list, label='test_Curv_loss', color='tab:green')\n",
    "    ax2.tick_params(axis='y')\n",
    "    plt.legend(loc='upper right')\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#fig.text(0.05,-0.25,f'The dataset has {k*n} points originated \\nby {k} Gaussian(s). \\nAverage losses over the last epoch: \\nMSE loss: {np.mean(mse_loss[-batches_per_epoch:]):.3f}, \\nCurvature loss: {np.mean(curv_loss[-batches_per_epoch:]):.3f}')\n",
    "# Average losses over the last epoch\n",
    "if set_name == \"Swissroll\":\n",
    "    fig.text(0.05,-0.25,f\"Set params: n={sr_numpoints}, noise={sr_noise}. \\nMSE loss: {np.mean(mse_loss[-batches_per_epoch:]):.3f}, \\nCurvature loss: {np.mean(curv_loss[-batches_per_epoch:]):.3f}, \\n$R^2=${R_squared:.4f}\")\n",
    "else:    \n",
    "    fig.text(0.05,-0.25,f\"Set params: n={n}, k={k}, d={d}, D={D}, $\\sigma$={var_class}, $\\sigma_{{I}}$={intercl_var}. \\nMSE loss: {np.mean(mse_loss[-batches_per_epoch:]):.3f}, \\nCurvature loss: {np.mean(curv_loss[-batches_per_epoch:]):.3f}, \\n $R^2=${R_squared:.4f}, \\n Curvature loss over train dataset: {curv_loss_on_train_data:.4f}\" )\n",
    "str_lambda_recon = \"$\\lambda_{recon}$\"\n",
    "str_lambda_curv = \"$\\lambda_{curv}$\"\n",
    "plt.title(f\"Params: lr={lr}, batch_size={batch_size},\\n {str_lambda_recon}={mse_w}, {str_lambda_curv}={curv_w}\")\n",
    "#plt.title(\"Params: lr={0}, batch_size={1},\\n $\\lambda_r$={2}, $\\lambda_c$={3},{4}\".format(lr,batch_size,mse_w,curv_w,str1))\n",
    "if (violent_saving == True) & (weights_loaded == False):\n",
    "    plt.savefig(f'{Path_pictures}/losses.pdf',bbox_inches='tight',format='pdf')\n",
    "#plt.savefig(f'{Path_pictures}/losses.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and metric losses heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose data\n",
    "#data_for_plot = train_data\n",
    "data_for_plot = test_data\n",
    "\n",
    "latent = encoder(data_for_plot[:][0].squeeze()).detach()\n",
    "labels = data_for_plot[:][1]\n",
    "init_data = data_for_plot[:][0]\n",
    "recon_data = decoder(encoder(init_data).detach())\n",
    "abs_error_array = (recon_data-init_data).squeeze()\n",
    "mse_array = abs_error_array.norm(dim=1)**2\n",
    "mse_array = mse_array.detach()\n",
    "curvature_array = RR.Sc_jacfwd_vmap(latent,function=decoder).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "size_of_points = 20\n",
    "fig, (ax00,ax0)= plt.subplots(ncols=2, nrows=1,figsize=(15,6),dpi=300)\n",
    "# (ax3,ax4) can  be added\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax00.title.set_text(\"AE latent space\")\n",
    "if set_name == \"Synthetic\":\n",
    "    p00 = ax00.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap=discrete_cmap(k, \"jet\"))\n",
    "    fig.colorbar(p00,label=\"initial color\", ticks=(np.arange(k)))\n",
    "else:\n",
    "    p00 = ax00.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet')\n",
    "    fig.colorbar(p00,label=\"initial color\")\n",
    "\n",
    "ax0.title.set_text(\"Reconstruction loss\")\n",
    "p0 = ax0.scatter( latent[:,0], latent[:,1], c=mse_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.LogNorm())\n",
    "fig.colorbar(p0,label=\"squared l2 norm errors\")\n",
    "\n",
    "\"\"\"\n",
    "ax1.title.set_text(\"Absolute value of scalar curvature\")\n",
    "p1 = ax1.scatter( latent[:,0], latent[:,1], c=abs(curvature_array), alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.LogNorm())\n",
    "fig.colorbar(p1,label=\"curvature abs value\")\n",
    "\n",
    "ax2.title.set_text(\"Scalar curvature\")\n",
    "p2 = ax2.scatter( latent[:,0], latent[:,1], c=curvature_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.SymLogNorm(linthresh=1e-2))\n",
    "fig.colorbar(p2,label=\"curvature\")\n",
    "\"\"\"\n",
    "\n",
    "#ax3.title.set_text(\"Only negative curvature loss in logscale\")\n",
    "#p3 = ax3.scatter( latent[:,0], latent[:,1], c=-curvature_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.LogNorm())\n",
    "#fig.colorbar(p3,label=\"-curvature\")\n",
    "\n",
    "#ax4.title.set_text(\"Only positive curvature loss in logscale\")\n",
    "#p4 = ax4.scatter( latent[:,0], latent[:,1], c=curvature_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.LogNorm())\n",
    "#fig.colorbar(p4,label=\"curvature\")\n",
    "\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/init_colors_recon_loss.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_array = RR.metric_jacfwd_vmap(encoder(init_data),function=decoder).detach()\n",
    "det_array = torch.det(metric_array)\n",
    "trace_array = torch.einsum('jii->j',metric_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = latent[:,0].min()\n",
    "right = latent[:,0].max()\n",
    "bottom = latent[:,1].min()\n",
    "top = latent[:,1].max()\n",
    "\n",
    "xsize = right - left\n",
    "ysize = top - bottom\n",
    "xcenter = 0.5*(left + right)\n",
    "ycenter = 0.5*(bottom + top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsize = 200\n",
    "#xsize = 8\n",
    "#ysize = 10\n",
    "#xcenter = 0.0\n",
    "#ycenter = -1.0\n",
    "\n",
    "import torch.func as TF\n",
    "grid_on_ls = RR.make_grid(linsize,xsize=xsize,ysize=ysize,xcenter=xcenter,ycenter=ycenter)\n",
    "metric_on_grid = RR.metric_jacfwd_vmap(grid_on_ls,function=decoder)\n",
    "metric_det_on_grid = torch.det(metric_on_grid)\n",
    "metric_trace_on_grid = TF.vmap(torch.trace)(metric_on_grid)\n",
    "curv_on_the_grid = RR.Sc_jacfwd_vmap(grid_on_ls, function = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curvature_array, bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curv_on_the_grid.detach(), bins = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xcenter = 0.0 \n",
    "#ycenter = 0.0\n",
    "xshift = 0.0\n",
    "yshift = 0.0\n",
    "numticks = 5\n",
    "if set_name == \"Synthetic\":\n",
    "    tick_decimals = 2\n",
    "else:\n",
    "    tick_decimals = 1\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels ]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "im1 = ax1.imshow(abs(curv_on_the_grid.detach().reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm())\n",
    "fig.colorbar(im1,ax = ax1, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "im2 = ax2.imshow(curv_on_the_grid.detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=abs(0.01*curv_on_the_grid.mean()).item()))\n",
    "fig.colorbar(im2,ax = ax2, shrink = 1, label = \"curvature\")\n",
    "ax2.set_title(\"Scalar curvature\")\n",
    "\n",
    "im3 = ax3.imshow((torch.sqrt(metric_det_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax1, ax2, ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/heatmaps_not_scaled.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scalar curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_curvature = curv_on_the_grid.max().item()\n",
    "min_curvature = curv_on_the_grid.min().item()\n",
    "linthresh_curvature = 0.01*abs(curv_on_the_grid.mean()).item()\n",
    "linthresh_curvature\n",
    "\n",
    "max_abs_curvature = abs(curv_on_the_grid).max().item()\n",
    "min_abs_curvature = 0.01*abs(curv_on_the_grid).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "\n",
    "ax1.title.set_text(\"Absolute value of scalar curvature\")\n",
    "p1 = ax1.scatter( latent[:,0], latent[:,1], c=abs(curvature_array), \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                vmax = max_abs_curvature))\n",
    "fig.colorbar(p1,label=\"curvature abs value\")\n",
    "\n",
    "ax2.title.set_text(\"Absolute value of scalar curvature overall\")\n",
    "im1 = ax2.imshow(abs(curv_on_the_grid.detach().reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                  vmax = max_abs_curvature))\n",
    "fig.colorbar(im1,ax = ax2, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "ax3.title.set_text(\"Scalar curvature\")\n",
    "p2 = ax3.scatter( latent[:,0], latent[:,1], c=curvature_array, \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(p2,label=\"curvature\")\n",
    "\n",
    "ax4.title.set_text(\"Scalar curvature overall\")\n",
    "im2 = ax4.imshow(curv_on_the_grid.detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(im2,ax = ax4, shrink = 1, label = \"curvature\")\n",
    "ax4.set_title(\"Scalar curvature overall\")\n",
    "\n",
    "axs = (ax1, ax3)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "axs = (ax2, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/curvature_heatmaps.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax3),(ax2,ax4))= plt.subplots(ncols=2,nrows=2,figsize = (15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax1.title.set_text(\"$\\sqrt{det(G)}$\")\n",
    "p = ax1.scatter( latent[:,0], latent[:,1],\n",
    "                c=torch.sqrt(abs(det_array)), alpha=1, s = size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=metric_det_on_grid.max().sqrt().item())\n",
    "fig.colorbar(p,label=\"$\\sqrt{det(G)}$\")\n",
    "ax2.title.set_text(\"0.5$\\cdot$tr(G)\")\n",
    "q = ax2.scatter( latent[:,0], latent[:,1], \n",
    "                c=0.5*(trace_array), alpha=1, s= size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(q,label=\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "im3 = ax3.imshow((torch.sqrt(metric_det_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None,\n",
    "                 vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "axs = (ax1, ax2)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    #plt.savefig(f'{Path_pictures}/metric_det_trace.eps',bbox_inches='tight',format='eps')\n",
    "    plt.savefig(f'{Path_pictures}/metric_det_trace.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_report = True\n",
    "if build_report == True:\n",
    "    pdfs = [f'{Path_pictures}/losses.pdf', f'{Path_pictures}/9losses.pdf', f'{Path_pictures}/init_colors_recon_loss.pdf', f'{Path_pictures}/curvature_heatmaps.pdf', f'{Path_pictures}/metric_det_trace.pdf']\n",
    "    pdfs = [f'{Path_pictures}/losses.pdf', f'{Path_pictures}/9losses.pdf', f'{Path_pictures}/init_colors_recon_loss.pdf', f'{Path_pictures}/curvature_heatmaps.pdf', f'{Path_pictures}/metric_det_trace.pdf']\n",
    "\n",
    "    merger = PdfMerger()\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    merger.write(f\"{Path_pictures}/report_{save_weight_name}.pdf\")\n",
    "    merger.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latex plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "size_of_points = 40\n",
    "fig, ax1 = plt.subplots(ncols=1, nrows=1,figsize=(9,9),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "#ax00.title.set_text(\"AE latent space\")\n",
    "if set_name == \"Synthetic\":\n",
    "    p = ax1.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap=discrete_cmap(k, \"jet\"))\n",
    "    #fig.colorbar(p,label=\"initial color\", ticks=(np.arange(k)))\n",
    "else:\n",
    "    p = ax1.scatter( latent[:,0], latent[:,1], c=labels, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet')\n",
    "    #fig.colorbar(p,label=\"initial color\")\n",
    "\n",
    "ax1.set_ylim(bottom,top)\n",
    "ax1.set_xlim(left,right)\n",
    "ax1.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "ax1.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/latex_ls.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax2 = plt.subplots(ncols=1, nrows=1,figsize=(9,9),dpi=300)\n",
    "\n",
    "#ax2.title.set_text(\"Scalar curvature overall\")\n",
    "im2 = ax2.imshow(curv_on_the_grid.detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "#vmax = 1e+2))\n",
    "cbar = fig.colorbar(im2,ax = ax2, shrink = 0.8, label = \"curvature\")\n",
    "\n",
    "cbar.ax.tick_params(rotation=0)\n",
    "\n",
    "new_cbar_ticks = np.delete(cbar.get_ticks(),np.where((abs(cbar.get_ticks()) <= linthresh_curvature)&(cbar.get_ticks()!=0)))\n",
    "new_cbar_ticks\n",
    "\n",
    "cbar.ax.set_yticks(new_cbar_ticks)\n",
    "\n",
    "ax2.set_xticks(ticks_places,labels = xtick_labels)\n",
    "ax2.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/latex_curvature_heatmap.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Level sets of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rotation matrices \\phi_j and shifts y_j \n",
    "# from the set construction\n",
    "phi = my_dataset.rotations\n",
    "shifts = my_dataset.shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances to means of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_plot = test_data\n",
    "\n",
    "latent = encoder(data_for_plot[:][0].squeeze()).detach()\n",
    "labels = data_for_plot[:][1]\n",
    "int_labels = labels.to(int)\n",
    "init_data = data_for_plot[:][0]\n",
    "centers = []\n",
    "\n",
    "for label in int_labels:\n",
    "    centers.append(shifts[label])\n",
    "centers_tensor = torch.from_numpy(np.array(centers).squeeze())\n",
    "distances = torch.norm(init_data-centers_tensor,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9),dpi=400)\n",
    "plt.scatter( latent[:,0], latent[:,1],s=40, c=distances, alpha=0.5, marker='o', edgecolor='none', cmap='jet')\n",
    "# use for logscale: norm=matplotlib.colors.LogNorm()\n",
    "#plt.colorbar(label=\"Distance to cloud center\",orientation='vertical',shrink = 0.7)\n",
    "#plt.title(f\"ReLU-sine AE latent space for the \\n {set_name} dataset\")\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/distance_to_means_heatmap.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 different colormaps with cbars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plt.rcParams.update({'font.size': 20}) # makes all fonts on the plot be 24\n",
    "latent_labels_distances = torch.cat((latent,labels.unsqueeze(1),distances.unsqueeze(1)),dim=1)\n",
    "my_dataframe = pd.DataFrame(latent_labels_distances)\n",
    "cmaps = [\"jet\",\"hsv\",\"twilight\"]\n",
    "#cmaps = [\"jet\",\"plasma\",\"twilight\"]\n",
    "#cmaps = [\"jet\",\"turbo\",\"hsv\"]\n",
    "colorbar_locations = [\"right\",\"bottom\",\"left\"]\n",
    "colorbar_orientations = [\"vertical\",\"horizontal\",\"vertical\"]\n",
    "colorbar_shrinks = [0.5,0.5,0.5]\n",
    "colorbar_anchors = [(0.5,0.75),(0.75,0.5),(0.5,0.5)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi=400)\n",
    "#plt.title(\"AE latent space for the Synthetic dataset\")\n",
    "for plane_idx in range(k):\n",
    "    # d is the number of the last column. It contains labels, i.e. colors\n",
    "    results_df = my_dataframe.loc[my_dataframe[d] == plane_idx]\n",
    "    #select all columns but the labeling color\n",
    "    latent_points_in_plane = torch.tensor(results_df.loc[:,results_df.columns!=d].values)\n",
    "    p = ax.scatter( latent_points_in_plane[:,0], latent_points_in_plane[:,1], c=latent_points_in_plane[:,2], alpha=0.5, marker='o', edgecolor='none', cmap=cmaps[plane_idx])\n",
    "    fig.colorbar(p, label=f\"Distance to the center of cloud {plane_idx}\", orientation=colorbar_orientations[plane_idx],shrink = colorbar_shrinks[plane_idx],location = colorbar_locations[plane_idx],pad = 0.05, anchor = colorbar_anchors[plane_idx])\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/distance_to_means_3heatmaps_withcbars.pdf',bbox_inches='tight',format='pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 colormaps no cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plt.rcParams.update({'font.size': 20}) # makes all fonts on the plot be 24\n",
    "latent_labels_distances = torch.cat((latent,labels.unsqueeze(1),distances.unsqueeze(1)),dim=1)\n",
    "my_dataframe = pd.DataFrame(latent_labels_distances)\n",
    "cmaps = [\"jet\",\"hsv\",\"twilight\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi=300)\n",
    "#plt.title(\"AE latent space for the Synthetic dataset\")\n",
    "for plane_idx in range(k):\n",
    "    # d is the number of the last column. It contains labels, i.e. colors\n",
    "    results_df = my_dataframe.loc[my_dataframe[d] == plane_idx]\n",
    "    #select all columns but the labeling color\n",
    "    latent_points_in_plane = torch.tensor(results_df.loc[:,results_df.columns!=d].values)\n",
    "    p = ax.scatter( latent_points_in_plane[:,0], latent_points_in_plane[:,1], \n",
    "                   c=latent_points_in_plane[:,2], alpha=0.5, marker='o', \n",
    "                   s= size_of_points, edgecolor='none', cmap=cmaps[plane_idx])\n",
    "ax.set_ylim(bottom,top)\n",
    "ax.set_xlim(left,right)\n",
    "ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/distance2means_synthetic_curv_w={curv_w}.pdf',bbox_inches='tight',format='pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.05, 0.80, 0.9, 0.1])\n",
    "\n",
    "cb = mpl.colorbar.ColorbarBase(ax, orientation='horizontal', \n",
    "                               cmap='jet',)\n",
    "\n",
    "plt.savefig(f'{Path_pictures}/just_colorbar.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disc of circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "num_circles = 5 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3\n",
    "#radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "radius_array = maxrad*np.linspace(0,1,num_circles)\n",
    "\n",
    "plt.title( \"Canonical version of disc\" )\n",
    "theta_array  = torch.linspace(0, 1-1/100, 100)\n",
    "x = torch.cos( 2*torch.pi*theta_array )\n",
    "y = torch.sin( 2*torch.pi*theta_array )\n",
    "for r in radius_array:\n",
    "    r = r.item() # extracting the value of r\n",
    "    plt.scatter( r*x, r*y, c=theta_array, marker='.', cmap='hsv', alpha=0.5*(2-r/maxrad) )\n",
    "# end for \n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/Canonical_disk.eps',bbox_inches='tight',format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk with colormap by polar angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "#num_circles = 40 # circles per plane\n",
    "#numpoints = 100 #points per circle\n",
    "#maxrad = 3\n",
    "#radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in \\n the latent space in plane # {plane_idx} with {str_lambda_curv}={curv_w}''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        #print(\"theta:\",theta)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        #print(\"x:\",x_array)\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        #print(\"y\",y_array)\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        #circle = design_circle(100, rad=(j+1)*2)\n",
    "        #plot.scatter(x_array,y_array)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        #plt.scatter(circle_in_D[:,0],circle_in_D[:,1])\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1],c=theta, marker='.', cmap='hsv', alpha=0.5*(2-rad/maxrad))\n",
    "        plt.grid(True)\n",
    "        \n",
    "        #print(rad)\n",
    "    ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    if violent_saving == True:\n",
    "        plt.savefig(f'{Path_pictures}/circle_in_plane#{plane_idx}_byangle.eps',bbox_inches='tight',format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "num_circles = 5 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3\n",
    "\n",
    "radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in \\n the latent space in plane # {plane_idx} with $\\lambda_{{curv}}=${curv_w}''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1],s=15)\n",
    "        plt.grid(True)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "    if violent_saving == True:\n",
    "        plt.savefig(f'{Path_pictures}/circle_in_plane#{plane_idx}_bycolor.eps',bbox_inches='tight',format='eps')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plane_idx = 0\n",
    "num_circles = 5 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3*math.sqrt(var_class)\n",
    "\n",
    "radius_array = maxrad*np.sqrt(np.linspace(0,1,num_circles))\n",
    "\n",
    "for plane_idx in range(k):\n",
    "    #plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space with \\n penalty on frobenius norm of $G-I$ equal to  {curv_w}''')\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        \n",
    "        # color by rad\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1],marker='.',cmap='jet',s=20)\n",
    "        #print(3*rad*np.ones(numpoints))\n",
    "        # colorby polar angle\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1],c=theta, marker='.', cmap='hsv', alpha=1-rad/maxrad)\n",
    "        plt.grid(True)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/circles_color_by_radius.png',bbox_inches='tight',format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plane_idx in range(k):\n",
    "    #plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space with \\n penalty on frobenius norm of $G-I$ equal to  {curv_w}''')\n",
    "    plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        circle_in_D = torch.matmul(phi[plane_idx],circle.T).T+shifts[plane_idx].squeeze()\n",
    "        encoded_circle = encoder(circle_in_D).detach()\n",
    "        \n",
    "        # color by rad\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        # colorby polar angle\n",
    "        plt.scatter(encoded_circle[:,0],encoded_circle[:,1],c=theta, marker='.', cmap='hsv', alpha=1-rad/maxrad)\n",
    "        plt.grid(True)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/circles_color_by_angle.eps',bbox_inches='tight',format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ideal circles (for Aniti days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_circles = 7 # circles per plane\n",
    "numpoints = 100 #points per circle\n",
    "maxrad = 3*math.sqrt(var_class)\n",
    "\n",
    "radius_array = maxrad*(np.linspace(0,1,num_circles))\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "for plane_idx in range(k):\n",
    "    #plt.title( f'''Embedding of {num_circles} circles of radius up to {maxrad} in each \\n of the {k} planes in the latent space with \\n penalty on frobenius norm of $G-I$ equal to  {curv_w}''')\n",
    "    plt.title( f'''Canonical disks in the latent space''')\n",
    "    for rad in radius_array:\n",
    "        theta = torch.linspace(0.,2*torch.pi*(numpoints-1)/numpoints,\n",
    "                           numpoints)\n",
    "        x_array = rad*torch.cos(theta).unsqueeze(0).T\n",
    "        y_array = rad*torch.sin(theta).unsqueeze(0).T\n",
    "        circle = torch.cat((x_array,y_array),dim=-1)\n",
    "        torch.manual_seed(4*plane_idx)\n",
    "        circle_shifted = 1/9*(circle) + 1/2.5*(torch.randn(2))\n",
    "        \n",
    "        # color by rad\n",
    "        #plt.scatter(encoded_circle[:,0],encoded_circle[:,1])\n",
    "        # colorby polar angle\n",
    "        plt.scatter(circle_shifted[:,0],circle_shifted[:,1],c=theta, marker='.', cmap='hsv', alpha=1-rad/maxrad)\n",
    "        plt.grid(False)\n",
    "        plt.xlim(-1.0,1.0)\n",
    "        plt.ylim(-1.0,1.0)\n",
    "    #ax = plt.gca()\n",
    "    # to make equal axis scales\n",
    "    #ax.set_aspect('equal') \n",
    "    #plt.figure(figsize=(8, 8))\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/3canonical_disks.eps',bbox_inches='tight',format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Histograms of metric eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linsize = 300 #linear size of the grid\n",
    "\n",
    "# on train_data\n",
    "\n",
    "samples_over_latent_space = (encoder(train_data[:][0]).detach()).squeeze()\n",
    "\n",
    "#visualize samples\n",
    "plt.title(\"Train dataset in latent space\")\n",
    "plt.scatter(samples_over_latent_space[:,0],samples_over_latent_space[:,1],marker=\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_at_samples = RR.metric_jacfwd_vmap(samples_over_latent_space,function=decoder).detach()\n",
    "eigenvalues = torch.linalg.eigvalsh(metric_at_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_eigenvalues = eigenvalues[:,0]\n",
    "max_eigenvalues = eigenvalues[:,1]\n",
    "all_eigenvalues = torch.cat((min_eigenvalues,max_eigenvalues),dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_trace = min_eigenvalues+max_eigenvalues\n",
    "metric_det = min_eigenvalues*max_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "plt.hist(np.array(metric_det),bins=round(math.sqrt(metric_det.shape[0])))\n",
    "plt.title(\"Metric determinants histogram over train data points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "plt.hist(np.array(metric_trace),bins=round(math.sqrt(metric_trace.shape[0])))\n",
    "plt.title(\"Metric traces histogram over train data points\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
