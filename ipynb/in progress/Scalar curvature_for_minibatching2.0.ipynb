{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            #nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "d = 2\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "\n",
    "# Check if the GPU is available\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Force CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "#without curvature in Loss func\n",
    "PATH_enc = 'encoder_conv_autoenc.pt'\n",
    "PATH_dec = 'decoder_conv_autoenc.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_convAE_curv_0.1.pt'\n",
    "#PATH_dec = 'decoder_convAE_curv_0.1.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_curw_w=0.0001_1epoch.pt'\n",
    "#PATH_dec = 'decoder_curw_w=0.0001_1epoch.pt'\n",
    "\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from latnt code and calculate mean and std\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # calculate mean and std of latent code, generated takining in test images as inputs \n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    latent = encoder(images)\n",
    "    latent = latent.cpu()\n",
    "\n",
    "    mean = latent.mean(dim=0)\n",
    "    print(mean)\n",
    "    std = (latent - mean).pow(2).mean(dim=0).sqrt()\n",
    "    print(std)\n",
    "\n",
    "    # sample latent vectors from the normal distribution\n",
    "    latent = torch.randn(128, d)*std + mean\n",
    "    #print(latent)\n",
    "    #print(latent.shape)\n",
    "\n",
    "    # reconstruct images from the random latent vectors\n",
    "    latent = latent.to(device)\n",
    "    img_recon = decoder(latent)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    #show_image(torchvision.utils.make_grid(img_recon[:100],10,5))\n",
    "    #plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fa63741",
   "metadata": {},
   "source": [
    "Point plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf81ed4",
   "metadata": {},
   "source": [
    "Manifold plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "numsteps = 10\n",
    "xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)\n",
    "ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)\n",
    "uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "# True Manifold plot\n",
    "truegrid = torch.cartesian_prod(ys,- xs)\n",
    "latent = - truegrid.roll(1,1)\n",
    "latent = latent.to(device)\n",
    "img_recon = decoder(latent)\n",
    "img_recon = img_recon.cpu()\n",
    "\n",
    "fig, ax  = plt.subplots(figsize=(20, 8.5))\n",
    "img_grid = torchvision.utils.make_grid(img_recon[:100],10,5)\n",
    "show_image(img_grid.detach())\n",
    "plt.show()\n",
    "print(latent.shape)\n",
    "print(img_recon.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d57b3499",
   "metadata": {},
   "source": [
    "# Fast way to compute metric on a grid over the latent space (torch.roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a863873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "numsteps = 100\n",
    "zoom = 1\n",
    "\n",
    "# Centralized and scaled evaluation \n",
    "xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)/zoom\n",
    "ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)/zoom\n",
    "\n",
    "#fixed location of latent space evaluation\n",
    "#xs = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "#ys = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "\n",
    "#uniform_grid = torch.cartesian_prod(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2867e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true grid starts from left bottom corner. x is the first to increase\n",
    "tgrid = torch.cartesian_prod(ys, xs)\n",
    "tgrid = tgrid.roll(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b33a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makegrid(centers, gridstep): # gridstep is the step of the grid\n",
    "    numpoints = centers.shape[0]\n",
    "    xs = torch.linspace(-2*gridstep, 2*gridstep, steps = 7)\n",
    "    ys = torch.linspace(-2*gridstep, 2*gridstep, steps = 7)\n",
    "    mygrid = torch.cartesian_prod(ys, xs)\n",
    "    mygrid = mygrid.roll(1,1)\n",
    "\n",
    "    new_grid = centers[:,None] + mygrid\n",
    "    new_grid = new_grid.reshape(49*numpoints, 2)\n",
    "    return new_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = makegrid(torch.tensor([[0.,0.],[0.,1.]]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c395334",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f23833",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.roll(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simultaneous differentiation on a grid with torch.roll\n",
    "def diff_by_x(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*h)\n",
    "    return dpsidx\n",
    "def diff_by_y(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee44305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h is step of the minigrid. should be h <=0.01\n",
    "def g(points, h):\n",
    "\n",
    "    grid = makegrid(points, h)\n",
    "    numsteps = 7 #because eachpoint is the center of 7x7 grid\n",
    "    numpoints = points.shape[0]\n",
    "    \n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    psi = decoder(latent)\n",
    "    \n",
    "    dpsidx = diff_by_x(psi, numsteps, h)\n",
    "    dpsidy = diff_by_y(psi, numsteps, h)\n",
    "    \n",
    "    metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    metric = metric.view(4, numsteps*numsteps*numpoints)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps*numpoints, 2, 2)\n",
    "    metric = metric.reshape(numpoints,numsteps,numsteps,2,2)\n",
    "    metric = metric[:,1:-1,1:-1,:,:]\n",
    "    # reshape(numpoints,numsteps*numsteps,2,2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec683a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.tensor([[0.,0.],[0.,0.]])\n",
    "\n",
    "numsteps = 7\n",
    "h = 0.01\n",
    "latent = makegrid(check,0.01)\n",
    "latent = latent.to(device)\n",
    "psi = decoder(latent)\n",
    "dpsidx = diff_by_x(psi, numsteps, h)\n",
    "dpsidy = diff_by_y(psi, numsteps, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46effef",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a779ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_by_x(latent, 7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.reshape(2, 2, 7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpsidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.tensor([[0.,0.],[0.,0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43967266",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = g(check, 0.01)[0]\n",
    "b = g(check, 0.01)[1]\n",
    "torch.equal(a, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f322b6b",
   "metadata": {},
   "source": [
    "Checking if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.Tensor([[0.0,0.0],[0.1,0.1],[0.1,0.1]])\n",
    "#check = torch.Tensor([[0.0,0.0]])\n",
    "g(check, 0.000001)[:][2][2]# is the coordinate of the grid center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacobian at one point\n",
    "#mypoint = (check.view(1,2)).clone().detach().requires_grad_(True)\n",
    "mypoint = (check).requires_grad_(True)\n",
    "inputs = mypoint\n",
    "jac = torch.autograd.functional.jacobian(decoder, inputs)\n",
    "\n",
    "myjac = jac.view(28*28,2)\n",
    "torch.matmul(myjac.t(),myjac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c90f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric computation\n",
    "metric = g(check, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80195e2b",
   "metadata": {},
   "source": [
    "### Derivatives of the metric and Christoffel symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of the metric on a grid\n",
    "def dg (metric, h): #dg\n",
    "    numpoints = metric.shape[0]\n",
    "    numsteps = metric.shape[1]\n",
    "    metric_der = metric\n",
    "    dgdx = diff_by_x(metric, numsteps, h)\n",
    "    dgdy = diff_by_y(metric, numsteps, h)\n",
    "    \n",
    "    metric_der = torch.cat((dgdx, dgdy), 0)\n",
    "    \n",
    "    metric_der = metric_der.view(8, numpoints*numsteps*numsteps)\n",
    "    metric_der = metric_der.transpose(0, 1)\n",
    "    \n",
    "    metric_der = metric_der.reshape(numpoints,numsteps,numsteps,2,2,2)\n",
    "    metric_der = metric_der[:,1:-1,1:-1,:,:,:]\n",
    "    return metric_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der = dg(metric, 0.01)\n",
    "metric_der.shape #numpoints, numsteps, numsteps, derivative by x or y, indices in each derivative matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means that we can simultanuousely invert all the matrices over the grid\n",
    "torch.equal(torch.inverse(metric[0]),torch.inverse(metric)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the inverse of the metric on a grid\n",
    "metric_inv = torch.inverse(metric)\n",
    "metric_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8480365",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inv.reshape(-1,2,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648e4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(metric,metric_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de2ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols on a grid\n",
    "def Ch(inverseMetric, derOfMetric):\n",
    "    numpoints = derOfMetric.shape[0]\n",
    "    numsteps = derOfMetric.shape[1]\n",
    "\n",
    "    metric_inv = inverseMetric[:,1:-1,1:-1,:,:].reshape(-1,2,2)\n",
    "    metric_der = derOfMetric.reshape(-1,2,2,2)\n",
    "    n = metric_der.shape[0]\n",
    "    \n",
    "    Ch = torch.zeros((n, 2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    #Ch^l_ij\n",
    "                    Ch[:,l,i,j] += 0.5  * metric_inv[:,l,k]* (metric_der[:,i,k,j] + metric_der[:,j,i,k] - metric_der[:,k,i,j]) \n",
    "                    \n",
    "                    #Ch[l,i,j] += 0.5 * g_inv(grid)[l,k] * (dg(grid)[i,k,j] + dg(grid)[j,i,k] - dg(grid)[k,i,j]) #Ch^\n",
    "    Ch = Ch.reshape(numpoints, numsteps, numsteps, 2, 2, 2)\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCh = Ch(metric_inv, metric_der)\n",
    "Ch(metric_inv, metric_der).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203419fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of Christoffel symbols\n",
    "def Ch_der(ChristSymb, h):\n",
    "\n",
    "    n = ChristSymb.shape[0]\n",
    "    numsteps = ChristSymb.shape[1]\n",
    "    \n",
    "    Ch_new = ChristSymb.reshape(-1, 2, 2, 2)\n",
    "\n",
    "    Chdx = diff_by_x(Ch_new, numsteps, h)\n",
    "    Chdy = diff_by_y(Ch_new, numsteps, h)\n",
    "    Chder = torch.cat((Chdx, Chdy), -1)\n",
    "    Chder = Chder.view(-1,2,2,2,2)\n",
    "    Chder = Chder.transpose(-1,-2)\n",
    "    \n",
    "    Chder = Chder.reshape(n, numsteps, numsteps, 2, 2, 2, 2)\n",
    "    Chder = Chder[:, 1:-1, 1:-1, :, :, :, :]\n",
    "    return Chder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a92adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCh_der = Ch_der(myCh, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCh_der.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem(Chr_der, Chr):\n",
    "    n = Chr_der.shape[0]\n",
    "    Ch_der = Chr_der.reshape(n, 2, 2, 2, 2)\n",
    "    Ch = Chr[:, 1:-1, 1:-1, :, :, :].reshape(n, 2, 2, 2)\n",
    "    Riem = torch.einsum(\"tiljk->tijkl\",Ch_der) - torch.einsum(\"tikjl->tijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"tikp,tplj->tijkl\", Ch, Ch) - torch.einsum(\"tilp,tpkj->tijkl\", Ch, Ch)\n",
    "    return Riem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRiem = Riem(myCh_der, myCh)\n",
    "myRiem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ric(Riemann):\n",
    "    Ric = torch.einsum(\"tcacb->tab\",Riemann)\n",
    "    return Ric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRic = Ric(myRiem)\n",
    "myRic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a27b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scew symmetry check\n",
    "torch.equal(myRiem[:,0,0,0,1], - myRiem[:,0,0,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60437ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sc(invMetric, Ricci):\n",
    "    metric_inv = invMetric[:, 2:-2, 2:-2, :, :].reshape(-1,2,2)\n",
    "    Sc = torch.einsum(\"tij,tij->t\", metric_inv, Ricci)\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e12f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySc = Sc(metric_inv, myRic)\n",
    "mySc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "curv_loss = mySc.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c074afa5",
   "metadata": {},
   "source": [
    "# Scalar curvature heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast computation of Frobenious norm on the grid without borders\n",
    "Scalar_curv = Scalar_curvature_grid.view(numsteps,numsteps)\n",
    "#Scalar_curv_check = Scalar_curv[30:-30,30:-30].transpose(0,1)\n",
    "Scalar_curv = Scalar_curv[2:-2,2:-2].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map of the Scalar curvature\n",
    "h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "#h = plt.contourf(xs[30:-30], ys[30:-30], Scalar_curv_check)\n",
    "plt.title('Heat map of the Scalar curvature ')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "#plt.xlim(-1.5,1.5)\n",
    "#plt.ylim(-1.5,1.5)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "def372d2",
   "metadata": {},
   "source": [
    "Simplified energy functional computation: $F_{new}(g) = \\int_{M}  R^{2} d\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ef7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_no_border = metric.reshape(numsteps, numsteps,2,2)[2:-2,2:-2]\n",
    "det_metric_no_border = torch.det(metric_no_border)\n",
    "det_sqrt = torch.sqrt(det_metric_no_border)\n",
    "grid = tgrid\n",
    "hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "F_new = (det_sqrt*torch.square(Scalar_curv)*hx*hy).sum()\n",
    "\n",
    "print(F_new)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5808c9e7",
   "metadata": {},
   "source": [
    "# Geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for making a piecewise constant metric from its evaluation on a grid\n",
    "def find_nearest_index (grid, u):\n",
    "    index = int(torch.min(abs(grid - u),0).indices.sum())\n",
    "    #index = int((((u - tgrid[0])*numsteps/size).floor()*torch.tensor([1.,numsteps])).sum()) #thisd could be faster\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y = [u , v]\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    u = y[0:2:]\n",
    "    v = y[2::]\n",
    "    dudt = v\n",
    "    #dvdt = torch.zeros(2)\n",
    "    dvdt = np.zeros(2)\n",
    "    u = torch.from_numpy(u)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[l] -= (Ch(u)[l,i,j]).numpy() * v[i] * v[j]\n",
    "    dydt = np.concatenate((dudt, dvdt))\n",
    "    #dydt = torch.cat((dudt, dvdt),0)\n",
    "    return dydt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be23691a",
   "metadata": {},
   "source": [
    "## Vectorized computation of geodesics (with a loop in find_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could be done faster\n",
    "def find_nearest_indices (grid, u):\n",
    "    #this could be done more efficiently\n",
    "    n = u.shape[0]\n",
    "    indices = torch.zeros(n)\n",
    "    for i in range(n):\n",
    "        indices[i] = find_nearest_index(grid, u[i])\n",
    "    indices = indices.to(torch.int64) # just some magic to make it work\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nearest_index(tgrid, torch.tensor([0.5,0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrid[5563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ecddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce73044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant inverse of g\n",
    "def g_inv_vect (grid, u): #inverse metric\n",
    "    #index = find_nearest_index(tgrid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    #A = metric[index]\n",
    "    A = torch.index_select(metric, 0, indices)\n",
    "    g_inv = torch.inverse(A)\n",
    "    return g_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869be7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_inv_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a52dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant derivatives of g\n",
    "def dg_vect (grid, u): #dg\n",
    "    #index = find_nearest_index(uniform_grid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    g = torch.index_select(metric_der, 0, indices)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6348ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dg_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8850891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols at a vector of n points. u has shape (n, x, y)\n",
    "def Ch_vect(grid, u):\n",
    "    n = u.shape[0]\n",
    "    Ch = torch.zeros((n,2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    Ch[:,l,i,j] += 0.5 * g_inv_vect(grid, u)[:,l,k] * (dg_vect(grid, u)[:,i,k,j] + dg_vect(grid, u)[:,j,i,k] - dg_vect(grid, u)[:,k,i,j]) #Ch^l_ij\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch(check[1])\n",
    "# just to check there is no mistake in vectorized vertion Ch_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ch_vect still exploits the loop in find_indices\n",
    "#Ch_vect(tgrid,tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b88601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y has shape num of points, u, v\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    n = y.shape[0]\n",
    "    u = y[: , 0:2:]\n",
    "    v = y[: , 2::]\n",
    "    dudt = v\n",
    "    dvdt = torch.zeros(n, 2)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[:, l] -= Ch_vect(tgrid, u)[:, l,i,j] * v[:, i] * v[:, j] #here we use Ch_vect instead od Ch\n",
    "    dydt = torch.cat((dudt.T, dvdt.T)).T\n",
    "    # dydt = np.concatenate((dudt, dvdt))\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rungekutta_new(f, y0, t, args=()):\n",
    "    nt = len(t) # number of steps in time\n",
    "    # len(y0[0]) is the number of initial conditions\n",
    "    # len(y0[1]) is the dimention of the state space. In our case it is 4 \n",
    "    y = torch.zeros((nt, y0.shape[0],y0.shape[1]))\n",
    "    y[0,:,:] = y0\n",
    "    for i in range(nt - 1):\n",
    "        y[i+1,:,:] = y[i,:,:] + (t[i+1] - t[i])*f(y[i,:,:], t[i], *args)\n",
    "        print(y[i,:,:])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at random points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 10\n",
    "v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = v.repeat(m,1)\n",
    "u = torch.rand(m,1)\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed = torch.cat((u,v),1)\n",
    "RandStartComSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 21)\n",
    "sol3 = rungekutta_new(geod, RandStartComSpeed, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sol3[:15, :, 0], sol3[:15, :, 1]) #geodesics are shortened by step 15 because of border effects\n",
    "plt.title( \"Plots of geodesics with rnd ititial point and common initial speed\")\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79da24e3",
   "metadata": {},
   "source": [
    "# Scalar curvature and geodesics on one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at different initial points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 15 #number of geodesics\n",
    "#v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = v.repeat(m,1)\n",
    "#u = torch.rand(m,1)\n",
    "#u = torch.linspace(0.01,1.51,steps=m).reshape(15,1)\n",
    "u = torch.linspace(0.01,1.51,steps=m).reshape(15,1)\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed2 = torch.cat((u,v),1)\n",
    "RandStartComSpeed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7652a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 41)\n",
    "sol4 = rungekutta_new(geod, RandStartComSpeed2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96669dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalar curvature and geodesics\n",
    "h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "plt.plot(sol4[:30, :, 0], sol4[:30, :, 1]) #geodesics are shortened by step 30 because of border effects\n",
    "plt.title('Scalar curvature and geodesics')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "plt.xlim(0,1.75)\n",
    "plt.ylim(0,1.25)\n",
    "plt.colorbar(label=\"Scalar curvature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar_curvature_grid[5563]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
