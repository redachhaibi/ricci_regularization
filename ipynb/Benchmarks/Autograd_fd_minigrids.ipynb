{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb61206",
   "metadata": {},
   "source": [
    "NB! This is an old notebook. It contains a wrong (very unprecise) way of computing Scalar curvature of the latent space with f.d. formulas used for computing derivatives. Has to be redone!\n",
    "\n",
    "The autoencoder (AE) consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation*}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi   \n",
    "\\end{equation*}.\n",
    "\n",
    "The notebook contains:\n",
    "1) Loading weights of a pre-trained convolutional AE and plotting its latent space: point plot and manifold plot. If \"violent_saving\" == True, plots are saved locally.\n",
    "2) Auxillary tensors involving higher order derivatives of the decoder $\\Psi$ are computed with f.d.: metric $g$ and its derivatives, Riemann tensor $R^{i}_{jkl}$, Ricci tensor $R_{ij}$ and scalar curvature.\n",
    "3) Geodesics shooting via Runge-Kutta approximation. A single plot with a scalar curvature heatmap and geodesics on it is constructed.\n",
    "4) Prototype of metric evolution by Ricci flow equation \n",
    "\n",
    "NB! by default the metric $g$ is the pull-back by the decoder as described above. But one can use any custom metric by manually setting it in \"specific_metric\" function, that computes the metric matrix at a point $u\\in \\mathbb{R}: \\ g(u)$ given the local coordinates of the point $u$ in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import ricci_regularization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e71c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/MNIST01_exp7_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/Swissroll_exp4_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "violent_saving = False # if False it will not save plots\n",
    "\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0cee7",
   "metadata": {},
   "source": [
    "# Loading data and nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "additional_path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ec95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "\n",
    "#Path_pictures = yaml_config[\"experiment\"][\"path\"]\n",
    "Path_pictures = additional_path + \"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "if violent_saving == True:\n",
    "    # Check and create directories based on configuration\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "    else:\n",
    "        print(f\"Directiry already exists: {Path_pictures}\")\n",
    "\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    #k = yaml_config[\"dataset\"][\"k\"]\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)\n",
    "print(\"Plots saved at:\", Path_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path = additional_path)\n",
    "\n",
    "torus_ae = torus_ae.to(\"cpu\")\n",
    "\n",
    "print(f\"AE weights loaded successfully from {Path_ae_weights}.\")\n",
    "\n",
    "encoder = torus_ae.encoder_torus\n",
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2eabc",
   "metadata": {},
   "source": [
    "# Using mini-grids + minimal verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f906d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_grid(center: torch.Tensor, h: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a 7x7 mini-grid around a given center tensor with step size h.\n",
    "\n",
    "    Args:\n",
    "        center (torch.Tensor): A tensor representing the center of the grid (2D point).\n",
    "        h (float): The step size between grid points. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 7x7 grid of shape (7, 7, 2) where each element is a coordinate.\n",
    "    \"\"\"\n",
    "    # Create a 7x7 grid of relative coordinates (i, j) scaled by step size h\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "    \n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    \n",
    "    # Add the center coordinate to every point in the grid\n",
    "    mini_grid = grid + center.unsqueeze(0).unsqueeze(0)  # Broadcasting center to grid shape\n",
    "    \n",
    "    return mini_grid\n",
    "\n",
    "def build_mini_grid_batch(centers: torch.Tensor, h: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a batch of mini-grids centered at the given batch of points.\n",
    "    \n",
    "    Args:\n",
    "        centers (torch.Tensor): A 2D tensor with shape (N, 2) representing N centers.\n",
    "        grid_size (int): The size of the mini-grid (grid_size x grid_size).\n",
    "        h (float): The step size for the grid.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A batch of mini-grids of shape (N, grid_size * grid_size, 2).\n",
    "    \"\"\"\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "\n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    mini_grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    mini_grid = mini_grid.reshape(49,2) # Shape: (49, 2)\n",
    "    # Expand dimensions to match the number of centers\n",
    "    mini_grid = mini_grid.unsqueeze(0)  # shape: (1, grid_size * grid_size, 2)\n",
    "\n",
    "    # Broadcast the centers to create the batch\n",
    "    centers = centers.unsqueeze(1)  # shape: (N, 1, 2)\n",
    "\n",
    "    # Add the centers to the mini-grid points\n",
    "    batch_minigrids = mini_grid + centers  # shape: (N, grid_size * grid_size, 2)\n",
    "    return batch_minigrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(10,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)   \n",
    "\n",
    "print(\"batch of grids built correctly:\",torch.equal( batch_minigrids[:,24,:], centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(batch_minigrids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07437d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fd_batch_minigrids(batch_minigrids, function):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "    psi = function(batch_minigrids)\n",
    "    psi_next_x =  psi.roll(-1,1)\n",
    "    psi_prev_x =  psi.roll(1,1)\n",
    "    psi_next_y =  psi.roll(-7,1)\n",
    "    psi_prev_y =  psi.roll(7,1)\n",
    "\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "    E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "    F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "    G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "    metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "    metric = metric.view(-1, 7 * 7, 2, 2)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48237fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric_fd_batch_minigrids(batch_minigrids, decoder)\n",
    "metric[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_by_x_minigrids(tensor_on_batch_minigrids, h):\n",
    "    tensor_next_x =  tensor_on_batch_minigrids.roll(-7,1)\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids.roll(7,1)\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids(tensor_on_batch_minigrids, h):\n",
    "    psi_next_y =  tensor_on_batch_minigrids.roll(-1,1)\n",
    "    psi_prev_y =  tensor_on_batch_minigrids.roll(1,1)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy\n",
    "\n",
    "def metric_der_fd_batch_minigrids(batch_minigrids, function):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "    metric = metric_fd_batch_minigrids(batch_minigrids, \n",
    "                    function = function)\n",
    "    dg_dx_fd = diff_by_x_minigrids(metric, h = h)\n",
    "    dg_dy_fd = diff_by_y_minigrids(metric, h = h)\n",
    "    dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n",
    "    return dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der_fd_batch_minigrids(batch_minigrids, decoder)[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e89c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_der_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_inv_batch_minigrids(batch_minigrids, function, eps=0.0):\n",
    "    g = metric_fd_batch_minigrids(batch_minigrids, function)\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "    return g_inv\n",
    "\n",
    "#metric_inv_jacfd_vmap = torch.func.vmap(metric_inv_fd)\n",
    "\n",
    "def Ch_fd_batch_minigrids (batch_minigrids, function, eps = 0.0):\n",
    "    g_inv = metric_inv_batch_minigrids(batch_minigrids,function,\n",
    "                                       eps=eps)\n",
    "    dg = metric_der_fd_batch_minigrids(batch_minigrids,function)\n",
    "    Ch = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              )\n",
    "    return Ch\n",
    "#Ch_fd_vmap = torch.func.vmap(Ch_fd)\n",
    "\n",
    "def Ch_der_fd_batch_minigrids (grid, function, eps=0.0):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "\n",
    "    Ch = Ch_fd_batch_minigrids(grid, function=function, eps=eps)\n",
    "    dChdx = diff_by_x_minigrids(Ch, h)\n",
    "    dChdy = diff_by_y_minigrids(Ch, h)\n",
    "    dCh = torch.cat((dChdx.unsqueeze(-1), dChdy.unsqueeze(-1)), dim = -1)\n",
    "    return dCh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_der_fd_batch_minigrids(batch_minigrids, decoder)[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af305a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Ch_der_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem_fd_batch_minigrids(u, function,eps=0.0):\n",
    "    Ch = Ch_fd_batch_minigrids(u, function, eps=eps)\n",
    "    Ch_der = Ch_der_fd_batch_minigrids(u, function, eps=eps)\n",
    "\n",
    "    Riem = torch.einsum(\"bgiljk->bgijkl\",Ch_der) - torch.einsum(\"bgikjl->bgijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"bgikp,bgplj->bgijkl\", Ch, Ch) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Ch, Ch)\n",
    "    return Riem\n",
    "\n",
    "def Ric_fd_batch_minigrids(u, function, eps=0.0):\n",
    "    Riemann = Riem_fd_batch_minigrids(u, function, eps=eps)\n",
    "    Ric = torch.einsum(\"bgcscr->bgsr\",Riemann)\n",
    "    return Ric\n",
    "\n",
    "def Sc_fd_batch_minigrids_slow (u, function, eps = 0.0):\n",
    "    Ricci = Ric_fd_batch_minigrids(u, function=function,eps=eps)\n",
    "    metric_inv = metric_inv_batch_minigrids(u,function=function, eps=eps)\n",
    "    Sc = torch.einsum('bgsr,bgsr->bg',metric_inv,Ricci)\n",
    "    return Sc\n",
    "\n",
    "\n",
    "# REDO this\n",
    "\n",
    "minigrid_side = 5\n",
    "psi = decoder(batch_minigrids)\n",
    "psi_matrix = psi.reshape(-1,7,7,D)\n",
    "#psi_next_x =  psi_matrix[:,:,2:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_x =  psi_matrix[:,:,:-2,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_next_y =  psi_matrix[:,2:,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_y =  psi_matrix[:,:-2,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "psi_next_x =  psi_matrix[:,1:-1,2:,:]\n",
    "psi_prev_x =  psi_matrix[:,1:-1,:-2,:]\n",
    "psi_next_y =  psi_matrix[:,2:,1:-1,:]\n",
    "psi_prev_y =  psi_matrix[:,:-2,1:-1,:]\n",
    "\n",
    "\n",
    "dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "\n",
    "def diff_by_x_minigrids_fast(tensor_on_batch_minigrids, h, minigrid_side):\n",
    "    dim = tensor_on_batch_minigrids.shape[-1]\n",
    "    tensor_on_batch_minigrids_matrix = tensor_on_batch_minigrids.reshape(-1,minigrid_side,minigrid_side, dim)\n",
    "    tensor_next_x =  tensor_on_batch_minigrids_matrix[:,1:-1,2:,:]\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids_matrix[:,1:-1,:-2,:]\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    \n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids_fast(tensor_on_batch_minigrids, h, minigrid_side):\n",
    "    dim = tensor_on_batch_minigrids.shape[-1]\n",
    "    tensor_on_batch_minigrids_matrix = tensor_on_batch_minigrids.reshape(-1,minigrid_side,minigrid_side, dim)\n",
    "    tensor_next_y =  tensor_on_batch_minigrids_matrix[:,2:,1:-1,:]\n",
    "    tensor_prev_y =  tensor_on_batch_minigrids_matrix[:,:-2,1:-1,:]\n",
    "    tensor_dy = (tensor_next_y - tensor_prev_y)/(2*h)\n",
    "\n",
    "    return tensor_dy\n",
    "\n",
    "\n",
    "def metric_fd_batch_minigrids(batch_minigrids, function, h=0.01):\n",
    "    \n",
    "    psi = function(batch_minigrids)\n",
    "    psi_next_x =  psi.roll(-1,1)\n",
    "    psi_prev_x =  psi.roll(1,1)\n",
    "    psi_next_y =  psi.roll(-7,1)\n",
    "    psi_prev_y =  psi.roll(7,1)\n",
    "\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "    E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "    F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "    G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "    metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "    metric = metric.view(-1, 7 * 7, 2, 2)\n",
    "    return metric\n",
    "\n",
    "\n",
    "def Sc_fd_batch_minigrids (centers, function, h=0.01, eps = 0.0):\n",
    "    \n",
    "    #create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "    #compute metric\n",
    "    g = metric_fd_batch_minigrids(batch_minigrids, function, h)\n",
    "    #compute inverse\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "    #compute metric derivatives\n",
    "    dg_dx_fd = diff_by_x_minigrids(g, h = h)\n",
    "    dg_dy_fd = diff_by_y_minigrids(g, h = h)\n",
    "    del g\n",
    "    dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n",
    "    del dg_dx_fd, dg_dy_fd\n",
    "    #compute Christoffel symbols\n",
    "    Christoffel = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              )\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    #dChristoffel_dx = diff_by_x_minigrids_fast(Christoffel, h,minigrid_side=7)\n",
    "    #dChristoffel_dy = diff_by_y_minigrids_fast(Christoffel, h, minigrid_side=7)\n",
    "    \n",
    "    dChristoffel_dx = diff_by_x_minigrids(Christoffel, h)\n",
    "    dChristoffel_dy = diff_by_y_minigrids(Christoffel, h)\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1)\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    #Compute Riemann tensor\n",
    "    Riemann = torch.einsum(\"bgiljk->bgijkl\",dChristoffel) - torch.einsum(\"bgikjl->bgijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bgikp,bgplj->bgijkl\", Christoffel, Christoffel) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Christoffel, Christoffel)\n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    Ricci = torch.einsum(\"bgcscr->bgsr\",Riemann)\n",
    "    del Riemann, \n",
    "    #Scalar curvature\n",
    "    Sc = torch.einsum('bgsr,bgsr->bg',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd_batch_minigrids(centers, decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(100,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = decoder(batch_minigrids)\n",
    "psi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959089b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_fd_batch_minigrids(batch_minigrids,decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_matrix = psi.reshape(-1,7,7,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd_batch_minigrids(batch_minigrids,decoder)[0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3380d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#psi_next_x = psi_matrix[:,:,1:,:]\n",
    "#print(psi_next_x)\n",
    "\n",
    "minigrid_side = 5\n",
    "psi = decoder(batch_minigrids)\n",
    "psi_matrix = psi.reshape(-1,7,7,D)\n",
    "#psi_next_x =  psi_matrix[:,:,2:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_x =  psi_matrix[:,:,:-2,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_next_y =  psi_matrix[:,2:,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_y =  psi_matrix[:,:-2,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "psi_next_x =  psi_matrix[:,1:-1,2:,:]\n",
    "psi_prev_x =  psi_matrix[:,1:-1,:-2,:]\n",
    "psi_next_y =  psi_matrix[:,2:,1:-1,:]\n",
    "psi_prev_y =  psi_matrix[:,:-2,1:-1,:]\n",
    "\n",
    "\n",
    "dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "E = torch.einsum('bghD,bghD->bgh',dpsidx, dpsidx)\n",
    "F = torch.einsum('bghD,bghD->bgh',dpsidx, dpsidy)\n",
    "G = torch.einsum('bghD,bghD->bgh',dpsidy, dpsidy)\n",
    "\n",
    "metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "metric = metric.view(-1, minigrid_side * minigrid_side, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(psi[:,2:,:] - psi[:,:-2,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi[:,:-14,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_jacfwd(centers[0], decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = function(batch_minigrids)\n",
    "psi_next_x =  psi.roll(-1,1)\n",
    "psi_prev_x =  psi.roll(1,1)\n",
    "psi_next_y =  psi.roll(-7,1)\n",
    "psi_prev_y =  psi.roll(7,1)\n",
    "\n",
    "dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "metric = metric.view(-1, 7 * 7, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60916e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_matrix[:,:,:-2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d716def",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi.roll(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd_batch_minigrids(centers, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd_batch_minigrids_slow(batch_minigrids,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sc_fd_batch_minigrids(batch_minigrids, decoder)[7][24]\n",
    "#ricci_regularization.Sc_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f56535",
   "metadata": {},
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e960d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_fd_jacfwd_batch_minigrids(tensor_fd, tensor_jacfwd):\n",
    "    batch_size = tensor_fd.shape[0]\n",
    "    #finite differences\n",
    "    tensor_fd_central = tensor_fd[:, 24]\n",
    "\n",
    "    error = torch.functional.F.mse_loss(tensor_fd_central, tensor_jacfwd)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09672424",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd = metric_fd_batch_minigrids(batch_minigrids, function=decoder)\n",
    "metric_jacfwd = ricci_regularization.metric_jacfwd_vmap(centers, function=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fd_jacfwd_batch_minigrids(metric_fd, metric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fd_jacfwd_batch_minigrids(metric_fd, metric_jacfwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec825b0",
   "metadata": {},
   "source": [
    "# Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b221c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_values = np.logspace(-4, -1, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor_fd = Sc_fd_batch_minigrids(batch_minigrids, function= decoder)  # Simulate FD grid\n",
    "#tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(batch_minigrids,function= decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d70015",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "batch_size = 64  # Just as an example\n",
    "centers = torch.rand(batch_size, 2)\n",
    "batch_minigrids = build_mini_grid_batch(centers = centers, h = h)\n",
    "Sc_fd_batch_minigrids(batch_minigrids, function= decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# Assume tensor_jacfwd is some precomputed tensor (ground truth)\n",
    "batch_size = 128  # Just as an example\n",
    "centers = torch.rand(batch_size, 2)  # Simulated ground truth\n",
    "\n",
    "# We will compute tensor_fd with varying h\n",
    "h_values = np.logspace(-4, -1, 10)  # Step sizes in logarithmic scale from 1e-5 to 1e-1\n",
    "errors = []\n",
    "\n",
    "for h in h_values:\n",
    "    batch_minigrids = build_mini_grid_batch(centers = centers, h = h)\n",
    "    # Simulate tensor_fd by perturbing tensor_jacfwd with some finite difference approximation\n",
    "    tensor_fd = Sc_fd_batch_minigrids(batch_minigrids, function= decoder)  # Simulate FD grid\n",
    "    tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder)\n",
    "    # Compute the error for this step size\n",
    "    error = error_fd_jacfwd_batch_minigrids(tensor_fd, tensor_jacfwd)\n",
    "    errors.append(error.item())  # Store the error as a scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the error vs. h\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(h_values, errors, marker='o', label=\"MSE Error\")\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Error (MSE)')\n",
    "plt.title('Error vs. Step Size for Finite Differences on minigrid for scalar curvature computation')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.savefig(Path_pictures+\"/fd_minigrid_error.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe193440",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e92413",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(100,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac3c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd = Sc_fd_batch_minigrids(batch_minigrids, function=decoder)\n",
    "Sc_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers, function=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 100\n",
    "\n",
    "batch_sizes = [8, 16, 32,40, 64, 128, 256]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "    current_batch_minigrids = batch_minigrids[:batch_size]\n",
    "\n",
    "    # Timing for Sc_fd\n",
    "    time_fd = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids(current_batch_minigrids, function=decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids, current_batch_minigrids, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_jacfwd\n",
    "    time_jacfwd = timeit.timeit(\n",
    "        stmt=\"ricci_regularization.Sc_jacfwd_vmap(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import ricci_regularization, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"Sc_fd_avg_time\": time_fd / iterations,\n",
    "        \"Sc_jacfwd_avg_time\": time_jacfwd / iterations,\n",
    "    })\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open('timing_results_batch_minigrids.json', 'w') as f:\n",
    "    json.dump(timing_results, f, indent=4)\n",
    "\n",
    "# Print the timing results\n",
    "for result in timing_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "sc_fd_times = [result['Sc_fd_avg_time'] for result in timing_results]\n",
    "sc_jacfwd_times = [result['Sc_jacfwd_avg_time'] for result in timing_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average times for Sc_fd and Sc_jacfwd_vmap\n",
    "plt.plot(batch_sizes, sc_fd_times, marker='o', label='fd on mini_grids', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_jacfwd_times, marker='s', label='jacfwd', linestyle='-')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.title(f'Timing scalar curvature $R$ computation: fd on minigrids vs jacfwd')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_results_batch_minigrids.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
