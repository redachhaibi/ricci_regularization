{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb61206",
   "metadata": {},
   "source": [
    "NB! This is an old notebook. It contains a wrong (very unprecise) way of computing Scalar curvature of the latent space with f.d. formulas used for computing derivatives. Has to be redone!\n",
    "\n",
    "The autoencoder (AE) consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation*}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi   \n",
    "\\end{equation*}.\n",
    "\n",
    "The notebook contains:\n",
    "1) Loading weights of a pre-trained convolutional AE and plotting its latent space: point plot and manifold plot. If \"violent_saving\" == True, plots are saved locally.\n",
    "2) Auxillary tensors involving higher order derivatives of the decoder $\\Psi$ are computed with f.d.: metric $g$ and its derivatives, Riemann tensor $R^{i}_{jkl}$, Ricci tensor $R_{ij}$ and scalar curvature.\n",
    "3) Geodesics shooting via Runge-Kutta approximation. A single plot with a scalar curvature heatmap and geodesics on it is constructed.\n",
    "4) Prototype of metric evolution by Ricci flow equation \n",
    "\n",
    "NB! by default the metric $g$ is the pull-back by the decoder as described above. But one can use any custom metric by manually setting it in \"specific_metric\" function, that computes the metric matrix at a point $u\\in \\mathbb{R}: \\ g(u)$ given the local coordinates of the point $u$ in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import torch\n",
    "import ricci_regularization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e71c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/MNIST01_exp7_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/Swissroll_exp4_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "violent_saving = False # if False it will not save plots\n",
    "\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0cee7",
   "metadata": {},
   "source": [
    "# Loading data and nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "additional_path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ec95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "\n",
    "#Path_pictures = yaml_config[\"experiment\"][\"path\"]\n",
    "Path_pictures = additional_path + \"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "if violent_saving == True:\n",
    "    # Check and create directories based on configuration\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "    else:\n",
    "        print(f\"Directiry already exists: {Path_pictures}\")\n",
    "\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    #k = yaml_config[\"dataset\"][\"k\"]\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)\n",
    "print(\"Plots saved at:\", Path_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path = additional_path)\n",
    "\n",
    "torus_ae = torus_ae.to(\"cpu\")\n",
    "\n",
    "print(f\"AE weights loaded successfully from {Path_ae_weights}.\")\n",
    "\n",
    "encoder = torus_ae.encoder_torus\n",
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(10, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c42e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc, g = ricci_regularization.Sc_g_fd_batch_minigrids_rhombus(centers, function=decoder, h = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12782a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.curvature_loss(points=centers, function=decoder, h = 0.01, eps=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.sqrt( torch.det( ricci_regularization.metric_jacfwd_vmap(centers, function=decoder) ) ) *torch.square( ricci_regularization.Sc_jacfwd_vmap(centers, function=decoder))).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5427f",
   "metadata": {},
   "source": [
    "# Square minigrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e298dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_grid_batch(centers: torch.Tensor, h: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a batch of mini-grids centered at the given batch of points.\n",
    "    \n",
    "    Args:\n",
    "        centers (torch.Tensor): A 2D tensor with shape (N, 2) representing N centers.\n",
    "        grid_size (int): The size of the mini-grid (grid_size x grid_size).\n",
    "        h (float): The step size for the grid.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A batch of mini-grids of shape (N, grid_size * grid_size, 2).\n",
    "    \"\"\"\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "\n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    mini_grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    mini_grid = mini_grid.reshape(49,2) # Shape: (49, 2)\n",
    "    # Expand dimensions to match the number of centers\n",
    "    mini_grid = mini_grid.unsqueeze(0)  # shape: (1, grid_size * grid_size, 2)\n",
    "\n",
    "    # Broadcast the centers to create the batch\n",
    "    centers = centers.unsqueeze(1)  # shape: (N, 1, 2)\n",
    "\n",
    "    # Add the centers to the mini-grid points\n",
    "    batch_minigrids = mini_grid + centers  # shape: (N, grid_size * grid_size, 2)\n",
    "\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    batch_minigrids = batch_minigrids.reshape(batch_size, 7, 7, d) # shape batch_size * 7 * 7 * d\n",
    "    return batch_minigrids\n",
    "\n",
    "def diff_by_x_minigrids(tensor_on_batch_minigrids, h):\n",
    "    # entry of shape batch_size * minigrid_side * minigrid_side * something\n",
    "    tensor_next_x =  tensor_on_batch_minigrids[:,2:,1:-1]\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids[:,:-2,1:-1]\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids(tensor_on_batch_minigrids, h):\n",
    "    # entry of shape batch_size * minigrid_side * minigrid_side * something\n",
    "    tensor_next_y =  tensor_on_batch_minigrids[:,1:-1,2:]\n",
    "    tensor_prev_y =  tensor_on_batch_minigrids[:,1:-1,:-2]\n",
    "    tensor_dy = (tensor_next_y - tensor_prev_y)/(2*h)\n",
    "    return tensor_dy\n",
    "\n",
    "\n",
    "def metric_fd_batch_minigrids(centers, function, h=0.01):\n",
    "    \n",
    "    batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = diff_by_x_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsidy = diff_by_y_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) # shape batch_size * 5 * 5 * D * 2\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    metric = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi)\n",
    "    return metric\n",
    "\n",
    "def Sc_fd_batch_minigrids (centers, function, h=0.01, eps = 0.0):\n",
    "    # d is latent dimension\n",
    "    d = centers.shape[-1]\n",
    "    #create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "#    batch_minigrids = batch_minigrids.reshape(batch_minigrids.shape[0], 7, 7, d) # shape batch_size * 7 * 7 * d\n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = diff_by_x_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsidy = diff_by_y_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) # shape batch_size * 5 * 5 * D * d\n",
    "    \n",
    "    #compute metric\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi) # shape batch_size * 5 * 5 * d * d\n",
    "\n",
    "    #compute metric derivatives\n",
    "    dg_dx = diff_by_x_minigrids(g, h)\n",
    "    dg_dy = diff_by_y_minigrids(g, h)\n",
    "\n",
    "    #compute inverse\n",
    "    device = g.device\n",
    "    \n",
    "    #cutting the shape of g to compute g_inv\n",
    "    g = g[:,1:-1,1:-1] # shape batch_size * 3 * 3 * d * d\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device)) # shape batch_size * 3 * 3 * d * d\n",
    "    \n",
    "\n",
    "    del g\n",
    "    dg = torch.cat((dg_dx.unsqueeze(-1), dg_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg_dx, dg_dy\n",
    "\n",
    "    #compute Christoffel symbols\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, i, m, k, l are local coordinates\n",
    "    Christoffel = 0.5*(torch.einsum('bghim,bghmkl->bghikl',g_inv,dg)+\n",
    "              torch.einsum('bghim,bghmlk->bghikl',g_inv,dg)-\n",
    "              torch.einsum('bghim,bghklm->bghikl',g_inv,dg)\n",
    "              ) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    \n",
    "    dChristoffel_dx = diff_by_x_minigrids(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "    dChristoffel_dy = diff_by_y_minigrids(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 1 * 1 * d * d * d * d\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    # squeezing since we only have values at centers of minigrids (one point)\n",
    "    dChristoffel = dChristoffel.squeeze() # shape batch_size * d * d * d * d\n",
    "    \n",
    "    #Compute Riemann tensor\n",
    "    #here we only need christoffels and derivatives at centers\n",
    "    Christoffel = Christoffel[:,1:-1,1:-1].squeeze() # shape batch_size * d * d * d\n",
    "    #b is batch_size i, j, k, l, p are local coordinates\n",
    "    Riemann = torch.einsum(\"biljk->bijkl\",dChristoffel) - torch.einsum(\"bikjl->bijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bikp,bplj->bijkl\", Christoffel, Christoffel) - torch.einsum(\"bilp,bpkj->bijkl\", Christoffel, Christoffel)\n",
    "    # Riemann shape: batch_size * d * d * d\n",
    "    \n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    #b is batch_size c, s, r are local coordinates\n",
    "    Ricci = torch.einsum(\"bcscr->bsr\",Riemann)\n",
    "    del Riemann\n",
    "\n",
    "    #Compute scalar curvature\n",
    "    #we only need inverse of the metric at one central point:\n",
    "    g_inv = g_inv[:,1:-1,1:-1].squeeze() # shape batch_size * d * d\n",
    "    #b is batch_size s, r are local coordinates\n",
    "    Sc = torch.einsum('bsr,bsr->b',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc87a0a",
   "metadata": {},
   "source": [
    "# Rhombus minigrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Size of the matrix (7x7)\n",
    "matrix_size = 7\n",
    "center = matrix_size // 2  # This gives the index 3, which is the center of a 7x7 matrix\n",
    "\n",
    "# Create the 7x7 matrix filled with zeros\n",
    "matrix = torch.zeros((matrix_size, matrix_size))\n",
    "\n",
    "# Get the indices that form the rhombus shape\n",
    "rhombus_indices = []\n",
    "for i in range(matrix_size):\n",
    "    for j in range(matrix_size):\n",
    "        if abs(i - center) + abs(j - center) <= 3:\n",
    "            rhombus_indices.append((i, j))\n",
    "            matrix[i, j] = 1  # Mark the rhombus area for visualization\n",
    "\n",
    "# Print the indices of the rhombus\n",
    "print(\"Indices that form the rhombus:\")\n",
    "print(rhombus_indices)\n",
    "\n",
    "# Visualize the rhombus\n",
    "print(\"Rhombus shape in the 7x7 matrix:\")\n",
    "print(matrix)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhombus_mask():\n",
    "    # Create the 7x7 mask for the rhombus indices without a loop\n",
    "    center = 3\n",
    "    grid_x, grid_y = torch.meshgrid(torch.arange(7), torch.arange(7), indexing=\"ij\")\n",
    "\n",
    "    # Compute Manhattan distance from the center (3, 3)\n",
    "    manhattan_distance = torch.abs(grid_x - center) + torch.abs(grid_y - center)\n",
    "\n",
    "    # The rhombus is where the Manhattan distance is less than or equal to 3\n",
    "    mask = manhattan_distance <= 3\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sc_fd_batch_minigrids_rhombus_slow (centers, function, h=0.01, eps = 0.0):\n",
    "    # d is latent dimension\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    # create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "\n",
    "    # Create the rhombus mask \n",
    "    mask = rhombus_mask()\n",
    "    # expand the mask to shape [batch_size, 7, 7, d] \n",
    "    batch_mask = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, d)\n",
    "\n",
    "    # Extract rhombus values for the batch (use the mask on the batch of minigrids)\n",
    "    rhombus_minigrids_batch = batch_minigrids[batch_mask].view(batch_size, -1, d)\n",
    "\n",
    "    # Evaluate the decoder psi only on the rhombus\n",
    "    psi = function( rhombus_minigrids_batch ) # shape batch_size * 25 * D\n",
    "    D = psi.shape[-1] # psi output dimension: D\n",
    "    # Reinitialize the batch of minigrids tensor filled with zeros (same shape as the original batch)\n",
    "    result_tensor = torch.zeros(batch_size, 7, 7, D)\n",
    "\n",
    "    # expand the mask to shape [batch_size, 7, 7, D]\n",
    "    batch_mask_D = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, D)\n",
    "    \n",
    "    # use the batch_mask to insert the psi values on the rhombus into the corresponding positions\n",
    "    result_tensor[batch_mask_D] = psi.view(-1)\n",
    "    psi = result_tensor\n",
    "\n",
    "    # compute dpsi\n",
    "    dpsidx = diff_by_x_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsidy = diff_by_y_minigrids(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) # shape batch_size * 5 * 5 * D * d\n",
    "    \n",
    "    # compute metric\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi) # shape batch_size * 5 * 5 * d * d\n",
    "\n",
    "    # compute metric derivatives\n",
    "    dg_dx = diff_by_x_minigrids(g, h)\n",
    "    dg_dy = diff_by_y_minigrids(g, h)\n",
    "    dg = torch.cat((dg_dx.unsqueeze(-1), dg_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg_dx, dg_dy\n",
    "\n",
    "    # compute inverse of g\n",
    "    device = g.device\n",
    "    # cutting the shape of g to compute g_inv\n",
    "    g = g[:,1:-1,1:-1] # shape batch_size * 3 * 3 * d * d\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device)) # shape batch_size * 3 * 3 * d * d\n",
    "    del g\n",
    "\n",
    "    # compute Christoffel symbols\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, i, m, k, l are local coordinates\n",
    "    Christoffel = 0.5*(torch.einsum('bghim,bghmkl->bghikl',g_inv,dg)+\n",
    "              torch.einsum('bghim,bghmlk->bghikl',g_inv,dg)-\n",
    "              torch.einsum('bghim,bghklm->bghikl',g_inv,dg)\n",
    "              ) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg\n",
    "\n",
    "    # compute Christoffel symbols' derivatives\n",
    "    dChristoffel_dx = diff_by_x_minigrids(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "    dChristoffel_dy = diff_by_y_minigrids(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 1 * 1 * d * d * d * d\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    # squeezing since we only have values at centers of minigrids (one point)\n",
    "    dChristoffel = dChristoffel.squeeze() # shape batch_size * d * d * d * d\n",
    "    \n",
    "    # compute Riemann tensor\n",
    "    # here we only need christoffels and derivatives at centers\n",
    "    Christoffel = Christoffel[:,1:-1,1:-1].squeeze() # shape batch_size * d * d * d\n",
    "    # b is batch_size i, j, k, l, p are local coordinates\n",
    "    Riemann = torch.einsum(\"biljk->bijkl\",dChristoffel) - torch.einsum(\"bikjl->bijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bikp,bplj->bijkl\", Christoffel, Christoffel) - torch.einsum(\"bilp,bpkj->bijkl\", Christoffel, Christoffel)\n",
    "    # Riemann shape: batch_size * d * d * d\n",
    "    del dChristoffel, Christoffel\n",
    "\n",
    "    # compute Ricci\n",
    "    # b is batch_size c, s, r are local coordinates\n",
    "    Ricci = torch.einsum(\"bcscr->bsr\",Riemann)\n",
    "    del Riemann\n",
    "\n",
    "    # compute scalar curvature\n",
    "    # we only need inverse of the metric at one central point:\n",
    "    g_inv = g_inv[:,1:-1,1:-1].squeeze() # shape batch_size * d * d\n",
    "    # b is batch_size s, r are local coordinates\n",
    "    Sc = torch.einsum('bsr,bsr->b',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_indices(printing = False):\n",
    "    # Step 1: Create a 7x7 tensor initialized with zeros (int type)\n",
    "    matrix_size = 7\n",
    "    rhombus_tensor = - torch.ones((matrix_size, matrix_size), dtype=torch.int)  # Change dtype to int\n",
    "\n",
    "    # Step 2: Create the 7x7 mask for the rhombus indices without a loop\n",
    "    center = 3\n",
    "    grid_x, grid_y = torch.meshgrid(torch.arange(matrix_size), torch.arange(matrix_size), indexing=\"ij\")\n",
    "\n",
    "    # Compute Manhattan distance from the center (3, 3)\n",
    "    manhattan_distance = torch.abs(grid_x - center) + torch.abs(grid_y - center)\n",
    "\n",
    "    # The rhombus is where the Manhattan distance is less than or equal to 3\n",
    "    mask = manhattan_distance <= 3\n",
    "\n",
    "    # Step 3: Fill the tensor using the mask with the same dtype\n",
    "    indices = torch.arange(25, dtype=torch.int)  # Ensure indices are of int type\n",
    "    rhombus_tensor[mask] = indices  # Fill masked positions with values 0 to 24\n",
    "\n",
    "    # Step 4: Print the resulting tensor\n",
    "    if printing == True:\n",
    "        print(\"Rhombus Tensor with Non-Zero Cells:\")\n",
    "        print(rhombus_tensor)\n",
    "        print(\"Transposed indices:\")\n",
    "        print(rhombus_tensor.T)\n",
    "        print(\"Transposed indexing:\", indices)\n",
    "    non_negative_elements = rhombus_tensor.T[rhombus_tensor.T != -1]\n",
    "    indices = non_negative_elements.flatten()\n",
    "    return indices\n",
    "\n",
    "def metric_fd_batch_minigrids_rhombus_slow (centers, function, h=0.01, eps = 0.0):\n",
    "    # d is latent dimension\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    # create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "\n",
    "    # Create the rhombus mask \n",
    "    mask = rhombus_mask()\n",
    "    # expand the mask to shape [batch_size, 7, 7, d] \n",
    "    batch_mask = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, d)\n",
    "\n",
    "    # Extract rhombus values for the batch (use the mask on the batch of minigrids)\n",
    "    rhombus_minigrids_batch = batch_minigrids[batch_mask].view(batch_size, -1, d)\n",
    "\n",
    "    # Evaluate the decoder psi only on the rhombus\n",
    "    psi = function( rhombus_minigrids_batch ) # shape batch_size * 25 * D\n",
    "\n",
    "    # compute dpsi\n",
    "    indices = proper_indices()\n",
    "    dpsi_dx_rhombus = ( psi[:, indices[2:],:] - psi[:, indices[:-2],:] ) / ( 2 * h )   # shape batch_size * 23 * D\n",
    "    dpsi_dy_rhombus = ( psi[:,2:,:] - psi[:,:-2,:] ) / ( 2 * h )    # shape batch_size * 23 * D\n",
    "    dpsi = torch.cat(( dpsi_dx_rhombus.unsqueeze(-1), dpsi_dy_rhombus.unsqueeze(-1) ), -1) # shape batch_size * 23 * D * d\n",
    "    \n",
    "    # compute metric\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bgDi,bgDj->bgij', dpsi,dpsi) # shape batch_size * 23 * D\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices (minigrid_size = 7):\n",
    "    # fill the grid by -1\n",
    "    rhombus_tensor = - torch.ones((minigrid_size, minigrid_size), dtype=torch.int)  # Change dtype to int\n",
    "\n",
    "    # Step 1: Create the minigrid_size x minigrid_size mask for the rhombus indices\n",
    "    center = minigrid_size // 2\n",
    "    grid_x, grid_y = torch.meshgrid(torch.arange(minigrid_size), torch.arange(minigrid_size), indexing=\"ij\")\n",
    "\n",
    "    # Compute Manhattan distance from the center (3, 3)\n",
    "    manhattan_distance = torch.abs(grid_x - center) + torch.abs(grid_y - center)\n",
    "\n",
    "    # The rhombus is where the Manhattan distance is less than or equal to 3\n",
    "    mask = manhattan_distance <= center\n",
    "\n",
    "    # Step 2: Fill the tensor using the mask with the same dtype\n",
    "    num_rhombus_points = ( minigrid_size * minigrid_size ) // 2 + 1\n",
    "    indices = torch.arange(num_rhombus_points, dtype=torch.int)  # Ensure indices are of int type\n",
    "    rhombus_tensor[mask] = indices  # Fill masked positions with values 0 to 24\n",
    "\n",
    "    # Compute Manhattan distance from the point (center + 1 , center)\n",
    "    manhattan_distance_x_next = torch.abs(grid_x - (center + 1) ) + torch.abs(grid_y - center)\n",
    "    mask_x_next = manhattan_distance_x_next <= center - 1\n",
    "\n",
    "    # Compute Manhattan distance from the point (center - 1 , center)\n",
    "    manhattan_distance_x_prev = torch.abs(grid_x - (center - 1) ) + torch.abs(grid_y - center)\n",
    "    mask_x_prev = manhattan_distance_x_prev <= center - 1\n",
    "\n",
    "    # Compute Manhattan distance from the point (center, center + 1)\n",
    "    manhattan_distance_y_next = torch.abs(grid_x - center ) + torch.abs( grid_y - ( center + 1 ) )\n",
    "    mask_y_next = manhattan_distance_y_next <= center - 1\n",
    "\n",
    "    # Compute Manhattan distance from the point (center, center - 1)\n",
    "    manhattan_distance_y_prev = torch.abs(grid_x - center ) + torch.abs( grid_y - ( center - 1 ) )\n",
    "    mask_y_prev = manhattan_distance_y_prev <= center - 1\n",
    "\n",
    "    # Compute Manhattan distance from the point (center, center)\n",
    "    manhattan_distance_central = torch.abs(grid_x - center ) + torch.abs( grid_y - center )\n",
    "    mask_central = manhattan_distance_central <= center - 1\n",
    "\n",
    "    # Step 3: give the proper indices for steps in x and y directions on the rhombus\n",
    "    indices_x_next = rhombus_tensor[mask_x_next]\n",
    "    indices_x_prev = rhombus_tensor[mask_x_prev]\n",
    "    indices_y_next = rhombus_tensor[mask_y_next]\n",
    "    indices_y_prev = rhombus_tensor[mask_y_prev]\n",
    "    indices_central = rhombus_tensor[mask_central]\n",
    "    return mask, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev, indices_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fd_batch_minigrids_rhombus (centers, function, h=0.01, eps = 0.0):\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    # create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "\n",
    "    # Create the rhombus mask and indices for differentiation \n",
    "    mask, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev, _ = indices()\n",
    "    # expand the mask to shape [batch_size, 7, 7, d] \n",
    "    batch_mask = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, d)\n",
    "\n",
    "    # Extract rhombus values for the batch (use the mask on the batch of minigrids)\n",
    "    rhombus_minigrids_batch = batch_minigrids[batch_mask].view(batch_size, -1, d)\n",
    "\n",
    "    # Evaluate the decoder psi only on the rhombus\n",
    "    psi = function( rhombus_minigrids_batch ) # shape batch_size * 25 * D\n",
    "\n",
    "    # compute dpsi\n",
    "    dpsi_dx_fast = ( psi[:, indices_x_next] - psi[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi_dy_fast = ( psi[:, indices_y_next] - psi[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi = torch.cat(( dpsi_dx_fast.unsqueeze(-1), dpsi_dy_fast.unsqueeze(-1) ), -1) # shape batch_size * 13 * D * d\n",
    "    \n",
    "    # compute metric\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bgDi,bgDj->bgij', dpsi,dpsi) # shape batch_size * 13 * d * d\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2da483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ch_fd_batch_minigrids_rhombus (centers, function, h=0.01, eps = 0.0):\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    # create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "\n",
    "    # Create the rhombus mask and indices for differentiation \n",
    "    mask, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev,_ = indices( minigrid_size = 7)\n",
    "    # expand the mask to shape [batch_size, 7, 7, d] \n",
    "    batch_mask = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, d)\n",
    "\n",
    "    # Extract rhombus values for the batch (use the mask on the batch of minigrids)\n",
    "    rhombus_minigrids_batch = batch_minigrids[batch_mask].view(batch_size, -1, d)\n",
    "\n",
    "    # Evaluate the decoder psi only on the rhombus\n",
    "    psi = function( rhombus_minigrids_batch ) # shape batch_size * 25 * D\n",
    "\n",
    "    # compute dpsi\n",
    "    dpsi_dx_fast = ( psi[:, indices_x_next] - psi[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi_dy_fast = ( psi[:, indices_y_next] - psi[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi = torch.cat(( dpsi_dx_fast.unsqueeze(-1), dpsi_dy_fast.unsqueeze(-1) ), -1) # shape batch_size * 13 * D * d\n",
    "    \n",
    "    # compute metric\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bgDi,bgDj->bgij', dpsi,dpsi) # shape batch_size * 13 * d * d\n",
    "\n",
    "    # compute metric derivatives\n",
    "\n",
    "    # Get new indices for differentiation \n",
    "    _, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev, indices_central  = indices(minigrid_size = 5)\n",
    "\n",
    "    dg_dx = ( g[:, indices_x_next] - g[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 5 * D\n",
    "    dg_dy = ( g[:, indices_y_next] - g[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 5 * D\n",
    "    dg = torch.cat((dg_dx.unsqueeze(-1), dg_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 5 * d * d * d\n",
    "    del dg_dx, dg_dy\n",
    "\n",
    "    # compute inverse of g\n",
    "    device = g.device\n",
    "    \n",
    "    # cutting the shape of g to compute g_inv\n",
    "    g = g[:, indices_central] # shape batch_size * 5 * d * d\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device)) # shape batch_size * 5 * d * d\n",
    "    del g\n",
    "\n",
    "    # compute Christoffel symbols\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, i, m, k, l are local coordinates\n",
    "    Christoffel = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              ) # shape batch_size * 5 * d * d * d\n",
    "    return Christoffel\n",
    "\n",
    "def Sc_fd_batch_minigrids_rhombus (centers, function, h=0.01, eps = 0.0):\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    # create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "\n",
    "    # Create the rhombus mask and indices for differentiation \n",
    "    mask, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev,_ = indices( minigrid_size = 7)\n",
    "    # expand the mask to shape [batch_size, 7, 7, d] \n",
    "    batch_mask = mask.unsqueeze(0).unsqueeze(-1).expand(batch_size, 7, 7, d)\n",
    "\n",
    "    # Extract rhombus values for the batch (use the mask on the batch of minigrids)\n",
    "    rhombus_minigrids_batch = batch_minigrids[batch_mask].view(batch_size, -1, d)\n",
    "\n",
    "    # Evaluate the decoder psi only on the rhombus\n",
    "    psi = function( rhombus_minigrids_batch ) # shape batch_size * 25 * D\n",
    "\n",
    "    # compute dpsi\n",
    "    dpsi_dx_fast = ( psi[:, indices_x_next] - psi[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi_dy_fast = ( psi[:, indices_y_next] - psi[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 13 * D\n",
    "    dpsi = torch.cat(( dpsi_dx_fast.unsqueeze(-1), dpsi_dy_fast.unsqueeze(-1) ), -1) # shape batch_size * 13 * D * d\n",
    "    \n",
    "    # compute metric\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bgDi,bgDj->bgij', dpsi,dpsi) # shape batch_size * 13 * d * d\n",
    "\n",
    "    # compute metric derivatives\n",
    "\n",
    "    # Get new indices for differentiation \n",
    "    _, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev, indices_central  = indices(minigrid_size = 5)\n",
    "\n",
    "    dg_dx = ( g[:, indices_x_next] - g[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 5 * D\n",
    "    dg_dy = ( g[:, indices_y_next] - g[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 5 * D\n",
    "    dg = torch.cat((dg_dx.unsqueeze(-1), dg_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 5 * d * d * d\n",
    "    del dg_dx, dg_dy\n",
    "\n",
    "    # compute inverse of g\n",
    "    device = g.device\n",
    "    \n",
    "    # cutting the shape of g to compute g_inv\n",
    "    g = g[:, indices_central] # new shape: batch_size * 5 * d * d\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device)) # shape batch_size * 5 * d * d\n",
    "    del g\n",
    "\n",
    "    # compute Christoffel symbols\n",
    "    # b is batch_size, g,h are coordinates on the minigrid, i, m, k, l are local coordinates\n",
    "    Christoffel = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              ) # shape batch_size * 5 * d * d * d\n",
    "    del dg\n",
    "\n",
    "    # compute Christoffel symbols' derivatives\n",
    "    # Get new indices for differentiation \n",
    "    _, indices_x_next, indices_x_prev, indices_y_next, indices_y_prev, indices_central  = indices(minigrid_size = 3)\n",
    "\n",
    "    dChristoffel_dx = ( Christoffel[:, indices_x_next] - Christoffel[:, indices_x_prev] ) / ( 2 * h ) # shape batch_size * 1 * D\n",
    "    dChristoffel_dy = ( Christoffel[:, indices_y_next] - Christoffel[:, indices_y_prev] ) / ( 2 * h ) # shape batch_size * 1 * D\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 1 * d * d * d * d\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    # squeezing since we only have values at centers of minigrids (one point)\n",
    "    dChristoffel = dChristoffel.squeeze() # shape batch_size * d * d * d * d\n",
    "    \n",
    "    # compute Riemann tensor\n",
    "\n",
    "    # cutting the shape of Christoffels to compute Riemann\n",
    "    assert indices_central[0] == 2 # the central index should be 2 indeed\n",
    "    Christoffel = Christoffel[:, indices_central].squeeze() # new shape: batch_size * d * d * d\n",
    "    # b is batch_size i, j, k, l, p are local coordinates\n",
    "    Riemann = torch.einsum(\"biljk->bijkl\",dChristoffel) - torch.einsum(\"bikjl->bijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bikp,bplj->bijkl\", Christoffel, Christoffel) - torch.einsum(\"bilp,bpkj->bijkl\", Christoffel, Christoffel)\n",
    "    # Riemann shape: batch_size * d * d * d\n",
    "    del dChristoffel, Christoffel\n",
    "\n",
    "    # compute Ricci\n",
    "    # b is batch_size c, s, r are local coordinates\n",
    "    Ricci = torch.einsum(\"bcscr->bsr\",Riemann)\n",
    "    del Riemann\n",
    "\n",
    "    # compute scalar curvature\n",
    "    # cutting the shape of the inverse of the metric. Only needed at one central point:\n",
    "    g_inv = g_inv[:,indices_central].squeeze() # shape batch_size * d * d\n",
    "    # b is batch_size s, r are local coordinates\n",
    "    Sc = torch.einsum('bsr,bsr->b',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889782cb",
   "metadata": {},
   "source": [
    "# Timing: metric vs scalar curvature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 1\n",
    "\n",
    "batch_sizes = [32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "    \n",
    "    # Timing for metric_fd_batch_minigrids\n",
    "    time_metric_fd = timeit.timeit(\n",
    "        stmt=\"metric_fd_batch_minigrids(current_centers, decoder, h)\",\n",
    "        setup=\"from __main__ import metric_fd_batch_minigrids, current_centers, decoder, h\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_fd_batch_minigrids\n",
    "    time_sc_fd = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids(current_centers, decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"metric_fd_avg_time\": time_metric_fd / iterations,\n",
    "        \"Sc_fd_avg_time\": time_sc_fd / iterations,\n",
    "    })\n",
    "\n",
    "# Output the timing results\n",
    "for result in timing_results:\n",
    "    print(f\"Batch Size: {result['batch_size']}, Metric_fd_avg_time: {result['metric_fd_avg_time']:.6f} sec, \"\n",
    "          f\"Sc_fd_avg_time: {result['Sc_fd_avg_time']:.6f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea471c8",
   "metadata": {},
   "source": [
    "plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9867b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the batch sizes, metric_fd times, and Sc_fd times\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "metric_fd_times = [result['metric_fd_avg_time'] for result in timing_results]\n",
    "sc_fd_times = [result['Sc_fd_avg_time'] for result in timing_results]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, metric_fd_times, label='Metric $g$', marker='o')\n",
    "plt.plot(batch_sizes, sc_fd_times, label='Scalar curvature $R$', marker='s')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.title('Timing metric $g$ vs scalar curvature $R$ computation with f.d. for different batch sizes')\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "# Save the plot\n",
    "#plt.savefig(Path_pictures+'/timing_metric_Sc_minigrids.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4ee44",
   "metadata": {},
   "source": [
    "# Timing: metric computation breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of iterations for averaging\n",
    "iterations = 1\n",
    "\n",
    "batch_sizes = [32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "minigrid_side = 7\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust batch_minigrids to match the current batch_size\n",
    "    \n",
    "    current_centers = centers[:batch_size]\n",
    "    current_batch_minigrids = batch_minigrids[:batch_size]\n",
    "    psi = decoder(current_batch_minigrids)\n",
    "\n",
    "    # Step 1: Time for decoder(batch_minigrids)\n",
    "    time_decoder = timeit.timeit(\n",
    "        stmt=\"psi = decoder(current_batch_minigrids)\",\n",
    "        setup=\"from __main__ import decoder, current_batch_minigrids\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Step 2: Time for diff_by_x_minigrids and diff_by_y_minigrids\n",
    "    time_diff = timeit.timeit(\n",
    "        stmt=\"\"\"\n",
    "dpsidx = diff_by_x_minigrids(psi, h) \n",
    "dpsidy = diff_by_y_minigrids(psi, h) \n",
    "dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) \n",
    "metric = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi)\n",
    "        \"\"\",\n",
    "        setup=\"from __main__ import torch, diff_by_x_minigrids, diff_by_y_minigrids, decoder, current_centers, h, psi\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Step 3: Time for metric_fd_batch_minigrids\n",
    "    time_metric_fd = timeit.timeit(\n",
    "        stmt=\"metric_fd_batch_minigrids(current_centers, decoder, h)\",\n",
    "        setup=\"from __main__ import metric_fd_batch_minigrids, current_centers, decoder, h\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"decoder_time\": time_decoder / iterations,\n",
    "        \"diff_time\": time_diff / iterations,\n",
    "        \"metric_fd_time\": time_metric_fd / iterations,\n",
    "    })\n",
    "\n",
    "# Output the timing results\n",
    "for result in timing_results:\n",
    "    print(f\"Batch Size: {result['batch_size']}, Decoder Time: {result['decoder_time']:.6f} sec, \"\n",
    "          f\"Roll Time: {result['diff_time']:.6f} sec, \"\n",
    "          f\"Metric_fd Time: {result['metric_fd_time']:.6f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29bbdc",
   "metadata": {},
   "source": [
    "plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26080ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract values for plotting\n",
    "batch_sizes = [result[\"batch_size\"] for result in timing_results]\n",
    "decoder_times = [result[\"decoder_time\"] for result in timing_results]\n",
    "diff_times = [result[\"diff_time\"] for result in timing_results]\n",
    "metric_fd_times = [result[\"metric_fd_time\"] for result in timing_results]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(batch_sizes, decoder_times, label='Decoder Time', marker='o')\n",
    "plt.plot(batch_sizes, diff_times, label='Diff Time', marker='o')\n",
    "plt.plot(batch_sizes, metric_fd_times, label='Metric FD Time', marker='o')\n",
    "\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Timing Results for Different Batch Sizes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "\n",
    "# Save the plot\n",
    "#plt.savefig(Path_pictures+'/timing_metric_batch_minigrids.pdf', bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97256f3d",
   "metadata": {},
   "source": [
    "# Timing: fd vs jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4130746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 100\n",
    "\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "\n",
    "    # Timing for Sc_fd\n",
    "    time_fd = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_fd_fast\n",
    "    time_fd_fast = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids_rhombus(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids_rhombus, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_jacfwd\n",
    "    time_jacfwd = timeit.timeit(\n",
    "        stmt=\"ricci_regularization.Sc_jacfwd_vmap(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import ricci_regularization, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"Sc_fd_avg_time\": time_fd / iterations,\n",
    "        \"Sc_fd_rhombus_avg_time\": time_fd_fast / iterations,\n",
    "        \"Sc_jacfwd_avg_time\": time_jacfwd / iterations,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file\n",
    "with open(Path_pictures+'/timing_results_batch_minigrids.json', 'w') as f:\n",
    "    json.dump(timing_results, f, indent=4)\n",
    "\n",
    "# Print the timing results\n",
    "for result in timing_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "sc_fd_times = [result['Sc_fd_avg_time'] for result in timing_results]\n",
    "sc_fd_rhombus_times = [result['Sc_fd_rhombus_avg_time'] for result in timing_results]\n",
    "sc_jacfwd_times = [result['Sc_jacfwd_avg_time'] for result in timing_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average times for Sc_fd and Sc_jacfwd_vmap\n",
    "plt.plot(batch_sizes, sc_fd_times, marker='o', label='fd on square mini_grids', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_fd_rhombus_times, marker='o', label='fd on rhombus mini_grids', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_jacfwd_times, marker='s', label='jacfwd', linestyle='-')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.title(f'Timing scalar curvature $R$ computation: fd on minigrids vs jacfwd')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_jacfwd_fd_square_rhombus.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec825b0",
   "metadata": {},
   "source": [
    "# Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# Assume tensor_jacfwd is some precomputed tensor (ground truth)\n",
    "batch_size = 128  # Just as an example\n",
    "centers = torch.rand(batch_size, 2)  # Simulated ground truth\n",
    "\n",
    "# We will compute tensor_fd with varying h\n",
    "h_values = np.logspace(-3, -1, 10)  # Step sizes in logarithmic scale from 1e-5 to 1e-1\n",
    "errors = []\n",
    "mean_relative_errors = []\n",
    "mean_abs_values = []\n",
    "mae_errors = []\n",
    "\n",
    "for h in h_values:\n",
    "    # Simulate tensor_fd by perturbing tensor_jacfwd with some finite difference approximation\n",
    "    with torch.no_grad():\n",
    "        tensor_fd = Sc_fd_batch_minigrids(centers, function= decoder,h=h)  # Simulate FD grid\n",
    "    tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder).detach()\n",
    "    # Compute the error for this step size\n",
    "    error = torch.functional.F.mse_loss(tensor_fd, tensor_jacfwd)\n",
    "    mean_abs_values.append( torch.mean( torch.abs(tensor_jacfwd) ) )\n",
    "    errors.append(error.item())  # Store the error as a scalar\n",
    "    mae_errors.append( torch.mean( torch.abs( tensor_fd - tensor_jacfwd ) ) )\n",
    "    mean_relative_errors.append( 100*( torch.abs( tensor_fd - tensor_jacfwd ) / torch.abs(tensor_jacfwd) ).mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the error vs. h\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(h_values, mean_relative_errors, marker='o', label=\"Relative error in %\")\n",
    "\n",
    "\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Relative error of $|R|$ in %')\n",
    "plt.title(f'FP32: Mean relative error of scalar curvature $R$ computation f.d. vs jacfwd, batch size: {batch_size}.')\n",
    "\n",
    "plt.xticks(h_values, [f'{h:.3f}' for h in h_values])  # Ensuring h_values are shown as tick labels # Setting the x-ticks to match h_values\n",
    "plt.yticks(mean_relative_errors, [f'{y:.2f}' for y in mean_relative_errors])  # Ensuring h_values are shown as tick labels # Setting the x-ticks to match h_values\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(Path_pictures+\"/fd_relative_error.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the error vs. h\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(h_values, errors, marker='o', label=\"MSE Error\")\n",
    "plt.loglog(h_values, mae_errors, marker='o', label=\"MAE Error\")\n",
    "plt.loglog(h_values, mean_abs_values, marker='o', label=\"Mean value of $|R|$\")\n",
    "\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Error ')\n",
    "plt.title('FP32: Errors vs. Step Size for f.d. on minigrid for scalar curvature $R$')\n",
    "\n",
    "plt.xticks(h_values, [f'{h:.3f}' for h in h_values])  # Ensuring h_values are shown as tick labels # Setting the x-ticks to match h_values\n",
    "plt.legend(loc = \"center left\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(Path_pictures+\"/fd_minigrid_error.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
