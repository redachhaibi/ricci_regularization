{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! This is a very old notebook.\n",
    "\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation*}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi \\ .  \n",
    "\\end{equation*}\n",
    "\n",
    "Here computational time for computing scalar curvature (https://en.wikipedia.org/wiki/Scalar_curvature) is measured for different latent space dimension $d$.\n",
    "\n",
    "One can switch between 2 curvature computation modes: \n",
    "1) PyTorch back-propagation tool: torch.func.torch.func.jacrev. \n",
    "See https://pytorch.org/docs/stable/generated/torch.func.torch.func.jacrev.html\n",
    "2) PyTorch forward-propagation tool: torch.func.jacfwd. \n",
    "See https://pytorch.org/functorch/stable/generated/functorch.jacfwd.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import timeit\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# adding path to the set generating package\n",
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        self.activation = torch.sin\n",
    "        #self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "D = 784\n",
    "d = 6\n",
    "decoder = Decoder(d,D)\n",
    "x = torch.rand(d)\n",
    "ricci_regularization.Sc_jacrev(x, function = decoder)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_to_repeat = 20\n",
    "#jacfwd_timer = []\n",
    "jacrev_timer = []\n",
    "D = 32*32\n",
    "\n",
    "hidden_dim_array = np.array([2,3,4,5,6])\n",
    "\n",
    "for d in hidden_dim_array:\n",
    "    x = torch.rand(d)\n",
    "    decoder = Decoder(d,D)\n",
    "    #jacfwd_timer.append(timeit.timeit(stmt=\"ricci_regularization.Sc_jacfwd(x, function = decoder)\",number=times_to_repeat,globals=globals())/times_to_repeat)\n",
    "    jacrev_timer.append(timeit.timeit(stmt=\"ricci_regularization.Sc_jacrev(x, function = decoder)\",number=times_to_repeat,globals=globals())/times_to_repeat)\n",
    "#print(\"jacfwd time:\",jacfwd_timer)\n",
    "print(\"torch.func.jacrev time:\",jacrev_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.func.jacrev timing for d = 2,  3,  4,  5,  6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54,\n",
    "#       58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 100\n",
    "#with open(\"jacfwd_timing\", \"w\") as fp:\n",
    "#    json.dump(new_jacfw_timer.tolist(), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is jacrev_timing for d = 2, 3, 4, 5, 6\n",
    "#with open(\"jacrev_timing\", \"r\") as fp:\n",
    "#    b = json.load(fp)\n",
    "#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_to_repeat = 10\n",
    "jacfwd_timer = []\n",
    "#D = 784\n",
    "\n",
    "#hidden_dim_array = (np.arange(100)+1)[1::4]\n",
    "hidden_dim_array = np.array([ 2,  3,  4,  5,  6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54,\n",
    "       58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 100])\n",
    "\n",
    "for d in hidden_dim_array:\n",
    "    x = torch.rand(d)\n",
    "    decoder = Decoder(d,D)\n",
    "    jacfwd_timer.append(timeit.timeit(stmt=\"ricci_regularization.Sc_jacfwd(x, function = decoder)\",number=times_to_repeat,globals=globals())/times_to_repeat)\n",
    "print(\"jacfwd time:\",jacfwd_timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24}) # makes all fonts on the plot be 24\n",
    "plt.figure(figsize=(9,9),dpi=300)\n",
    "plt.semilogy(jacfwd_timer,label=\"jacfwd\", marker='o')\n",
    "plt.semilogy(jacrev_timer,label=\"torch.func.jacrev\", marker='o')\n",
    "#plt.xticks(((hidden_dim_array-hidden_dim_array[0])/4)[::4],labels=hidden_dim_array[::4],rotation = 0)\n",
    "plt.xticks(np.array([0,4,10,15,20,27]),labels=([2,6,30,50,70,100]))\n",
    "#plt.xticks(np.array([0,3,6,9,12,24]),labels=([2,6,10,30,50,100]))\n",
    "plt.title(f\"Scalar curvature evaluation time for D={D}.\")\n",
    "plt.xlabel(\"Latent space dimension d\")\n",
    "plt.ylabel(\"Log of time in seconds\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(f'jacrev_jacfwd_time_D={D}.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
