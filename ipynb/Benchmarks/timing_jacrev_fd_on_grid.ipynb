{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "import ricci_regularization\n",
    "import torch, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/MNIST01_exp7_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/Swissroll_exp4_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "violent_saving = False # if False it will not save plots\n",
    "\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "additional_path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "\n",
    "#Path_pictures = yaml_config[\"experiment\"][\"path\"]\n",
    "Path_pictures = additional_path + \"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "if violent_saving == True:\n",
    "    # Check and create directories based on configuration\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "    else:\n",
    "        print(f\"Directiry already exists: {Path_pictures}\")\n",
    "\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    #k = yaml_config[\"dataset\"][\"k\"]\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)\n",
    "print(\"Plots saved at:\", Path_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path = additional_path)\n",
    "\n",
    "torus_ae = torus_ae.to(\"cpu\")\n",
    "\n",
    "print(f\"AE weights loaded successfully from {Path_ae_weights}.\")\n",
    "\n",
    "encoder = torus_ae.encoder_torus\n",
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of iterations for averaging\n",
    "iterations = 100\n",
    "\n",
    "# Define numsteps values\n",
    "numsteps_values = [7, 15, 20, 30, 50,100]\n",
    "\n",
    "timing_results = []\n",
    "\n",
    "# Create a function to time both algorithms for different tgrid sizes\n",
    "\n",
    "for numsteps in numsteps_values:\n",
    "    # Build tgrid for the current numsteps\n",
    "    tgrid = ricci_regularization.FiniteDifferences.make_grid(numsteps= numsteps)\n",
    "\n",
    "    # Set up timeit environment dynamically for the current tgrid\n",
    "    setup_code = f\"\"\"from __main__ import ricci_regularization, decoder, tgrid\"\"\"\n",
    "    \n",
    "    # Time for `Sc_fd`\n",
    "    time_fd = timeit.timeit(\n",
    "        stmt=f\"ricci_regularization.Sc_fd(tgrid, function=decoder)\",\n",
    "        setup=setup_code,\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Time for `Sc_jacfwd_vmap`\n",
    "    time_jacfwd_vmap = timeit.timeit(\n",
    "        stmt=f\"ricci_regularization.Sc_jacfwd_vmap(tgrid, function=decoder)\",\n",
    "        setup=setup_code,\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Save the results in a dictionary and append to the results list\n",
    "    timing_results.append({\n",
    "        'grid_size': f'{numsteps}x{numsteps}',\n",
    "        'Sc_fd_avg_time': time_fd / iterations,\n",
    "        'Sc_jacfwd_vmap_avg_time': time_jacfwd_vmap / iterations\n",
    "    })\n",
    "\n",
    "# Now `timing_results` contains the list of results\n",
    "print(\"\\nTiming Results:\")\n",
    "for result in timing_results:\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "# Save timing results to a JSON file\n",
    "with open(Path_pictures+'/timing_results.json', mode='w') as file:\n",
    "    json.dump(timing_results, file, indent=4)\n",
    "\n",
    "print(\"Results saved to timing_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store the data\n",
    "grid_sizes = []\n",
    "sc_fd_times = []\n",
    "sc_jacfwd_vmap_times = []\n",
    "\n",
    "# Read the timing results from the JSON file\n",
    "with open(Path_pictures+'/timing_results.json', 'r') as file:\n",
    "    timing_results = json.load(file)\n",
    "    for result in timing_results:\n",
    "        grid_sizes.append(result['grid_size'])\n",
    "        sc_fd_times.append(result['Sc_fd_avg_time'])\n",
    "        sc_jacfwd_vmap_times.append(result['Sc_jacfwd_vmap_avg_time'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average times for Sc_fd and Sc_jacfwd_vmap\n",
    "plt.plot(grid_sizes, sc_fd_times, marker='o', label='fd', linestyle='-')\n",
    "plt.plot(grid_sizes, sc_jacfwd_vmap_times, marker='s', label='jacfwd', linestyle='-')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.xlabel('Grid Size')\n",
    "plt.title('Performance Comparison of scalar curvature $R$ computation: fd vs jacfwd')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_results_plot.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
