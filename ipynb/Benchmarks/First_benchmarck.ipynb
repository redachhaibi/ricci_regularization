{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the first naive benchmark for the geodesics in the latent space of the autoencoder.\n",
    "\n",
    "The benchmarks evaluates the effect of curvature regularization, measuring how far straight lines are from being the geodesics.\n",
    "\\medskip\n",
    "\n",
    "Let us consider straight line segments $\\alpha_{ij} \\subset M \\subset \\R^2$ connecting pairs of points $X_i$\n",
    "and $X_j$ given by:\n",
    "$$\n",
    "\\alpha_{ij} ( t ) = t \\Phi_{\\theta}(X_i) + (1-t) \\Phi_{\\theta}(X_j) \\ .\n",
    "$$\n",
    "Let us consider the images of $\\alpha_{ij}$ through the decoder $\\Psi$. One obtains curves in $\\R^D$ given by:\n",
    "$$\n",
    "\\gamma_{ij} ( t ) = \\Psi(t \\Phi_{\\theta}(X_i) + (1-t) \\Phi_{\\theta}(X_j)) \\ .\n",
    "$$\n",
    "\n",
    "Namely for a curve $\\gamma_{ij}(t)$ one can consider several functionals:\n",
    "The functional computing the second derivative of $\\gamma (t)$. If $t$ were a natural parameter, the functional below would compute the norm of the acceleration of the curve along the curve. However it does not, once the metric in $M$ is not Euclidean and thus $t$ is not the natural parameter.\n",
    "\\begin{equation}\n",
    "    \\text{1. }\\widetilde E_{ij} = \\int\\limits_0^1 \\|\\gamma_{ij}'' (t)\\|^2 dt \\ .\n",
    "\\end{equation}\n",
    "The energy functional of $\\alpha_{ij} ( t )$:\n",
    "\\begin{equation}\n",
    "    \\text{2. } E_{ij} = \\int\\limits_0^1 \\|\\alpha_{ij}' (t)\\|_g^2 dt = \\int\\limits_0^1 \\|\\gamma_{ij}' (t)\\|^2 dt \\ ,\n",
    "\\end{equation}\n",
    "recall $g = J_\\Psi^* J_\\Psi$ is the pull-back of the Euclidean metric by the decoder $\\Psi$.\n",
    "\n",
    "And finally, the acceleration functional:\n",
    "\\begin{equation}\n",
    "    \\text{3. } A_{ij} = \\int\\limits_0^1 \\| \\nabla_{\\alpha_{ij}' (t)} \\alpha_{ij}' (t) \\|^2 dt \\ ,\n",
    "\\end{equation}\n",
    "All the functionals are avereged:\n",
    "\\begin{equation}\n",
    "    \\mathcal{E} = \\frac{1}{\\binom{K}{2}} \\sum\\limits_{1 \\leq i < j \\leq K} E_{ij} \\ .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "import ricci_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/MNIST01_exp8_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/Swissroll_exp1_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "violent_saving = True # if False it will not save plots\n",
    "\n",
    "#number of points to be paiwise connected by straight lines\n",
    "#K = 100 # this can go up to 300 in practice\n",
    "K = 150\n",
    "d = 2\n",
    "print(\"number of points to be paiwise connected by straight lines:\", K)\n",
    "print(\"straight lines constructed\", int(K*(K-1)/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the curve $\\gamma (t)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma (t, x, y, decoder):\n",
    "    return decoder(x*t + y*(1-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\gamma ' ( x ) \\approx \\frac{ \\gamma ( x + h ) - \\gamma ( x - h ) }{ 2 h }\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first derivative at point (x,y) of the latent space \n",
    "def gamma_prime(t, h,  x, y):\n",
    "    return (gamma(t+h, x, y) - gamma(t-h, x, y))/( 2 * h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\gamma''(x) \\approx \\frac{\\gamma(x+h) - 2\\gamma(x) + \\gamma(x-h)}{h^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_second(t, h,  x, y, decoder ):\n",
    "    return (gamma(t+h, x, y, decoder = decoder) - 2*gamma(t, x, y, decoder = decoder) + gamma(t-h, x, y, decoder = decoder))/(h**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\n",
    " \\widetilde E_{ij} \\approx \\frac{1}{2 (n-1)} \\sum\\limits_{k=0}^{n-2} \\left( \\| \\gamma''_{ij}(t_k) \\| + \\| \\gamma''_{ij}(t_{k+1}) \\| \\right)\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_tilde(x_i,x_j,n_partition, decoder):\n",
    "    n = n_partition\n",
    "    segment_partition = ( 1 / (n-1) ) * torch.arange(n, dtype=torch.float32)\n",
    "    gamma_second_array = gamma_second (segment_partition.reshape(-1,d),\n",
    "              h = 1/n, x = x_i, y = x_j,\n",
    "              decoder = decoder)\n",
    "    gamma_second_norm_array = gamma_second_array.norm(dim=1)\n",
    "    E_ij = ( 0.5 / ( n - 1 ) ) * torch.sum( (gamma_second_norm_array[:-1] + gamma_second_norm_array[1:]) )\n",
    "    # return E_ij.item() doesnot work with vmap\n",
    "    return E_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\n",
    " E_{ij} \\approx \\frac{1}{2} \\sum_{k=0}^{N} \\left\\| \\gamma(kh+h) - \\gamma(kh-h) \\right\\|_2^2\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_gamma(t, h,  x, y, decoder):\n",
    "    return (gamma(t+h, x, y, decoder) - gamma(t-h, x, y, decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(x_i,x_j,n_partition, decoder):\n",
    "    # n_partition is number of points in partition for \n",
    "    # the integral approximation by its Riemann sum\n",
    "    n = n_partition\n",
    "    segment_partition = (1/(n-1))*torch.arange(n,dtype=torch.float32)\n",
    "\n",
    "    delta_gamma_array = delta_gamma (segment_partition.reshape(-1,d),\n",
    "              h = 1/n, x = x_i, y = x_j,\n",
    "              decoder = decoder)\n",
    "    delta_gamma_array_norm_array = delta_gamma_array.norm(dim=1)\n",
    "    E_ij = 0.5 * torch.sum( delta_gamma_array_norm_array ** 2 )\n",
    "    # return E_ij.item() doesnot work with vmap\n",
    "    return E_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vmap vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_tilde_vmap = torch.func.vmap(E_tilde)\n",
    "E_vmap = torch.func.vmap(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def make_pairs(batch_of_points):\n",
    "    start_points_list = []\n",
    "    end_points_list = []\n",
    "    for i in range(K):\n",
    "        for j in range(i+1,K):\n",
    "            start_points_list.append(batch_of_points[i].unsqueeze(0))\n",
    "            end_points_list.append(batch_of_points[j].unsqueeze(0))\n",
    "    start_points = torch.cat(start_points_list, dim = 0)\n",
    "    end_points = torch.cat(end_points_list)\n",
    "    return start_points, end_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "additional_path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "\n",
    "#Path_pictures = yaml_config[\"experiment\"][\"path\"]\n",
    "Path_pictures = additional_path + \"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "if violent_saving == True:\n",
    "    # Check and create directories based on configuration\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "    else:\n",
    "        print(f\"Directiry already exists: {Path_pictures}\")\n",
    "\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    #k = yaml_config[\"dataset\"][\"k\"]\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)\n",
    "print(\"Plots saved at:\", Path_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(test_dataset)\n",
    "\n",
    "first_benchmark_data,rest = torch.utils.data.random_split(test_dataset, [K, l - K])\n",
    "\n",
    "#reformating\n",
    "first_benchmark_data = torch.stack([first_benchmark_data[i][0] for i in range(len(first_benchmark_data))])\n",
    "first_benchmark_data = first_benchmark_data.reshape(-1,D)\n",
    "\n",
    "d = yaml_config[\"architecture\"][\"latent_dim\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../../experiments/Swissroll_exp0_config.yaml', 'r') as yaml_file:\n",
    "#    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path = additional_path)\n",
    "\n",
    "torus_ae = torus_ae.to(\"cpu\")\n",
    "\n",
    "print(f\"AE weights loaded successfully from {Path_ae_weights}.\")\n",
    "\n",
    "encoder = torus_ae.encoder_torus\n",
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the curves $\\alpha_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# define a square box where points are sampled\n",
    "square_side = 2*torch.pi\n",
    "center_of_square = torch.zeros(2)\n",
    "\n",
    "random_points_latent_space = square_side * ( torch.rand(K, 2) - 0.5 )  + center_of_square\n",
    "# Convert the tensor to a numpy array\n",
    "points_np = random_points_latent_space.numpy()\n",
    "\n",
    "# Plot the points\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(points_np[:, 0], points_np[:, 1], c='blue', marker='o', edgecolor='k')\n",
    "plt.title('Random Points in Latent Space')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same Random points (uniformly distributed) not depending on the encoder:\n",
    "\n",
    "start_points_latent_space, end_points_latent_space = make_pairs(random_points_latent_space)\n",
    "# Random points depending on the encoder:\n",
    "#start_points, end_points = make_pairs(first_benchmark_data)\n",
    "#start_points_latent_space = encoder(start_points).detach()\n",
    "#end_points_latent_space = encoder(end_points).detach()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(start_points_latent_space[:, 0], start_points_latent_space[:, 1], color='blue', label='Start Points')\n",
    "plt.scatter(end_points_latent_space[:, 0], end_points_latent_space[:, 1], color='red', label='End Points')\n",
    "for start, end in zip(start_points_latent_space, end_points_latent_space):\n",
    "    plt.plot([start[0], end[0]], [start[1], end[1]], 'k--', color='blue')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(r'Lines $\\alpha_{ij}$ Connecting Points in the latent space')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing Functiolnals \n",
    "\n",
    "E_tilde_array = E_tilde_vmap (start_points_latent_space, end_points_latent_space, n_partition=100, decoder = decoder)\n",
    "Energy_array = E_vmap (start_points_latent_space, end_points_latent_space, n_partition=100, decoder = decoder)\n",
    "\n",
    "#E_tilde_array = E_tilde_vmap(encoder(start_points),encoder(end_points),n_partition=100,decoder = decoder)\n",
    "#Energy_array = E_vmap(encoder(start_points),encoder(end_points),n_partition=100,decoder = decoder)\n",
    "#Distance_ls_pairwize_array_no_curv_pen = (encoder(end_points) - encoder(start_points)).norm(dim=1)\n",
    "#Distance_RD_pairwize_array_no_curv_pen = (end_points - start_points).norm(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionals $\\widetilde E_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(E_tilde_array.detach(), bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Functional $\\widetilde E_{ij}$ Values')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.title(r'Histogram of energy functional $E_{ij}$ values')\n",
    "\n",
    "# Show grid for better readability\n",
    "plt.grid(True)\n",
    "plt.savefig(Path_pictures+f\"/Histogram_E_tilde_ij_{experiment_name}.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = E_tilde_array.detach()  # Detach from the computation graph\n",
    "N = len(samples)  # Number of samples (straight lines)\n",
    "mean_value = samples.mean().item()  # Mean value of the energy functional\n",
    "std_dev = torch.std(samples).item()  # Standard deviation\n",
    "SE = std_dev / math.sqrt(N)  # Standard error (SE)\n",
    "# printing here\n",
    "print(\"Number of samples):\", N)\n",
    "print(f\"Mean value of funtional E_tilde: {mean_value:.3f}\")\n",
    "print(f\"Std of funtional E_tilde: {std_dev:.3f}\")\n",
    "print(f\"Standard error of mean (SE): {SE:.3f}\")\n",
    "# Define the path to the output file\n",
    "output_file_path = f\"{Path_pictures}/statistical_analysys_E_tilde_{experiment_name}.txt\"\n",
    "\n",
    "# Save the results to the text file\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(f\"Number of straight lines (samples): {N}\\n\")\n",
    "    f.write(f\"Mean value of energy functional E: {mean_value:.3f}\\n\")\n",
    "    f.write(f\"Standard deviation of E: {std_dev:.3f}\\n\")\n",
    "    f.write(f\"Standard error of the mean (SE): {SE:.3f}\\n\")\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionals $ E_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(Energy_array.detach(), bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Energy functional $E_{ij}$ Values')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.title(r'Histogram of energy functional $E_{ij}$ values')\n",
    "\n",
    "# Show grid for better readability\n",
    "plt.grid(True)\n",
    "plt.savefig(Path_pictures+f\"/Histogram_E_ij_{experiment_name}.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the necessary imports and variable definitions are here\n",
    "samples = Energy_array.detach()  # Detach from the computation graph\n",
    "N = len(samples)  # Number of samples (straight lines)\n",
    "mean_value = samples.mean().item()  # Mean value of the energy functional\n",
    "std_dev = torch.std(samples).item()  # Standard deviation\n",
    "SE = std_dev / math.sqrt(N)  # Standard error (SE)\n",
    "# printing here\n",
    "print(\"Number of straight lines(samples):\", N)\n",
    "print(f\"Mean value of energy funtional E: {mean_value:.3f}\")\n",
    "print(f\"Std of energy funtional E: {std_dev:.3f}\")\n",
    "print(f\"Standard error of mean (SE): {SE:.3f}\")\n",
    "# Define the path to the output file\n",
    "output_file_path = f\"{Path_pictures}/statistical_analysys_E_{experiment_name}.txt\"\n",
    "\n",
    "# Save the results to the text file\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(f\"Number of straight lines (samples): {N}\\n\")\n",
    "    f.write(f\"Mean value of energy functional E: {mean_value:.3f}\\n\")\n",
    "    f.write(f\"Standard deviation of E: {std_dev:.3f}\\n\")\n",
    "    f.write(f\"Standard error of the mean (SE): {SE:.3f}\\n\")\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the mess starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with penalty on curvature\n",
    "load_weight_name = \"swissroll_curv_w=1_ls=R^2\"\n",
    "#load_weight_name = \"swissroll_curv_w=10_ls=R^2\"\n",
    "#load_weight_name = \"swissroll_curv_w=10_ls=R^2_20epochs_bs=32\"\n",
    "PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()\n",
    "\n",
    "start_points, end_points = make_pairs()\n",
    "\n",
    "Energy_pairwise_array_with_curv_pen = E_vmap(encoder(start_points),encoder(end_points),n_partition=100)\n",
    "Distance_ls_pairwize_array_with_curv_pen = (encoder(end_points) - encoder(start_points)).norm(dim=1)\n",
    "Distance_RD_pairwize_array_with_curv_pen = (end_points - start_points).norm(dim=1)\n",
    "#Energy_pairwise_array_with_curv_pen = E_vmap(start_points,end_points,n_partition=100)\n",
    "#Distance_ls_pairwize_array_with_curv_pen = (end_points - start_points).norm(dim=1)\n",
    "#Distance_RD_pairwize_array_with_curv_pen = (decoder(end_points) - decoder(start_points)).norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with penalty on curvature\n",
    "\n",
    "load_weight_name = \"swissroll_curv_w=10_ls=R^2_20epochs_bs=32\"\n",
    "PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()\n",
    "\n",
    "start_points, end_points = make_pairs()\n",
    "\n",
    "Energy_pairwise_array_curv_w10_pen = E_vmap(encoder(start_points),encoder(end_points),n_partition=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_RD_pairwize_array_with_curv_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_RD_pairwize_array_no_curv_pen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ground truth check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((Distance_RD_pairwize_array_no_curv_pen-Distance_RD_pairwize_array_with_curv_pen).detach(), bins = 50)\n",
    "plt.title(\"Distances in $\\mathbb{R}^D$ with and without curvature penalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((Distance_ls_pairwize_array_no_curv_pen-Distance_ls_pairwize_array_with_curv_pen).detach(), bins = 50)\n",
    "plt.title(\"Distances in latent space with and without curvature penalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "#plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in $\\mathbb{{R}}^3$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_no_curv_pen.detach().numpy(),Energy_array.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_curv_w10_pen.detach().numpy(),\n",
    "            color = \"green\", s = 10, label = \"$\\lambda_{curv} = 10$\")\n",
    "ax.legend(loc='upper left')\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "#ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_R3_swissroll.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "#plt.title(f\"Swissroll: enegry of paths change $E_{{ij}}^{{\\lambda_{{curv}} = 1}} - E_{{ij}}^{{\\lambda_{{curv}} = 0}}$ \\n vs distance in $\\mathbb{{R}}^3$ for $C_{{{K}}}^2$ paths\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen,\n",
    "           (Energy_pairwise_array_with_curv_pen - Energy_array).detach().numpy(),\n",
    "            color = \"magenta\", s = 10)\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "#ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$')\n",
    "ax.set_ylabel('Change in $E_{ij}$')\n",
    "#ax.set_ylabel('$E_{ij}^{\\lambda_{curv} = 1} - E_{ij}^{\\lambda_{curv} = 0}$')\n",
    "fig.savefig(\"Scatterplot_change_E_ij_dist_R3_swissroll.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in $\\mathbb{{R}}^3$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_no_curv_pen.detach().numpy(),Energy_array.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.legend(loc='upper left')\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "#ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_R3_swissroll_ylogscale.pdf\", format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in latent space\")\n",
    "ax.scatter(Distance_ls_pairwize_array_no_curv_pen.detach().numpy(),Energy_array.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_ls_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$\\|\\Theta(X_i) - \\Theta(X_j)\\|_2$, $\\Theta(X_i) \\in \\mathbb{R}^2$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_ls_swissroll.pdf\", format = \"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
