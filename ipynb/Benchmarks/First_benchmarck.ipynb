{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the first naive benchmark for the geodesics in the latent space of the autoencoder. The benchmarks evaluates the effect of curvature regularization, measuring how different from straight lines are the geodesics. Namely for a curve $\\gamma(t)$ one can consider a functional:\n",
    "\\begin{equation}\n",
    "    E_{ij} = \\int\\limits_0^1 \\|\\gamma'' (t)\\|^2 dt \\ ,\n",
    "\\end{equation}\n",
    "where $\\gamma(t) = \\Psi(t \\Phi_{\\theta}(X_i) + (1-t) \\Phi_{\\theta}(X_j))$, recall $\\Psi$ is the decoder function of the autoencoder. We obtain the average Euclidean energy:\n",
    "\\begin{equation}\n",
    "    \\mathcal{E} = \\frac{1}{\\binom{K}{2}} \\sum\\limits_{1 \\leq i < j \\leq K} E_{ij} \\ .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Swissroll\"\n",
    "#dataset_name = \"Synthetic\"\n",
    "\n",
    "K = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# adding path to the set generating package\n",
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "# Set hyperparameters \n",
    "# Swiss roll\n",
    "sr_noise = 0.05\n",
    "sr_numpoints = 18000 #k*n\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Synthetic\n",
    "d = 2         # latent space dimension\n",
    "k = 3         # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "shift_class = 0\n",
    "variance_of_classes = 1 # variation of each Gaussian initially 0.1\n",
    "interclass_variance = 0.1 # this creates a Gaussian, \n",
    "# i.e.random shift \n",
    "# proportional to the value of interclass_variance\n",
    "# initially 0.1\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#K = 50\n",
    "\n",
    "if dataset_name == \"Synthetic\":\n",
    "    D = 784\n",
    "    my_dataset = ricci_regularization.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                        shift_class=shift_class,\n",
    "                                        variance_of_classes = variance_of_classes, \n",
    "                                        interclass_variance=interclass_variance)\n",
    "\n",
    "    train_dataset = my_dataset.create\n",
    "elif dataset_name == \"Swissroll\":\n",
    "    D = 3\n",
    "    train_dataset =  sklearn.datasets.make_swiss_roll(n_samples=sr_numpoints, noise=sr_noise, random_state=1)\n",
    "    sr_points = torch.from_numpy(train_dataset[0]).to(torch.float32)\n",
    "    #sr_points = torch.cat((sr_points,torch.zeros(sr_numpoints,D-3)),dim=1)\n",
    "    sr_colors = torch.from_numpy(train_dataset[1]).to(torch.float32)\n",
    "    from torch.utils.data import TensorDataset\n",
    "    train_dataset = TensorDataset(sr_points,sr_colors)\n",
    "\n",
    "m = len(train_dataset)\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "#test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "#train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "l = test_data[:][0].shape[0]\n",
    "\n",
    "first_benchmark_data,rest = torch.utils.data.random_split(test_data, [K, l - K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introducing gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.linear4 = nn.Linear(128, hidden_dim)\n",
    "        #self.activation = nn.ReLU()\n",
    "        self.activation = torch.sin\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(hidden_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.linear3 = nn.Linear(256, 512)\n",
    "        self.linear4 = nn.Linear(512, output_dim)\n",
    "        self.activation = torch.sin\n",
    "        #self.activation = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        y = self.linear1(x)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear2(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.linear3(y)\n",
    "        y = self.activation(y)\n",
    "        out = self.linear4(y)\n",
    "        #out = self.activation(out)\n",
    "        #out = torch.sigmoid(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=D, hidden_dim=d)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma (t, x, y):\n",
    "    return decoder(x*t + y*(1-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma (torch.arange(10).reshape(10,1), torch.rand(d), torch.rand(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_second(t, h,  x, y):\n",
    "    return (gamma(t+h, x, y) - 2*gamma(t, x, y) + gamma(t-h, x, y))/(h**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\frac{1}{n-1}\\sum\\limits_{i=0}^{n-2} \\frac{\\gamma(t_i) + \\gamma(t_{i+1})}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(x_i,x_j,n_partition):\n",
    "    n = n_partition\n",
    "    segment_partition = (1/(n-1))*torch.arange(n,dtype=torch.float32)\n",
    "    gamma_second_array = gamma_second (segment_partition.reshape(-1,d),\n",
    "              h = 1/n, x = x_i, y = x_j)\n",
    "    gamma_second_norm_array = gamma_second_array.norm(dim=1)\n",
    "    E_ij = (0.5/(n-1))*torch.sum((gamma_second_norm_array[:-1]+gamma_second_norm_array[1:]))\n",
    "    # return E_ij.item() doesnot work with vmap\n",
    "    return E_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "E(torch.rand(d),torch.rand(d), n_partition = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vmap vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_vmap = torch.func.vmap(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more efficiently\n",
    "import math\n",
    "\n",
    "#K = 100 # this can go up to 300 in practice\n",
    "\n",
    "def make_pairs():\n",
    "    #first_bencmark_data_in_ls = encoder(first_benchmark_data[:][0])\n",
    "    initial_points = first_benchmark_data[:][0]\n",
    "    start_points_list = []\n",
    "    end_points_list = []\n",
    "    for i in range(K):\n",
    "        for j in range(i+1,K):\n",
    "            start_points_list.append(initial_points[i].unsqueeze(0))\n",
    "            end_points_list.append(initial_points[j].unsqueeze(0))\n",
    "            #start_points_list.append(first_bencmark_data_in_ls[i].unsqueeze(0))\n",
    "            #end_points_list.append(first_bencmark_data_in_ls[j].unsqueeze(0))\n",
    "    start_points = torch.cat(start_points_list, dim = 0)\n",
    "    end_points = torch.cat(end_points_list)\n",
    "    return start_points, end_points\n",
    "# now let us build C_K^2 pairs of start and end points we want to\n",
    "\"\"\"\n",
    "start_points = first_bencmark_data_in_ls.repeat((math.ceil(K/2),1))\n",
    "\n",
    "def cyclic_perm (tensor):\n",
    "    new_tensor = torch.cat((tensor[1:],tensor[0].unsqueeze(0)),dim=0)\n",
    "    return new_tensor\n",
    "\n",
    "end_points_list = []\n",
    "\n",
    "first_bencmark_data_in_ls_permuted = first_bencmark_data_in_ls\n",
    "for i in range(math.ceil(K/2)):\n",
    "    first_bencmark_data_in_ls_permuted = cyclic_perm(first_bencmark_data_in_ls_permuted)\n",
    "    end_points_list.append(first_bencmark_data_in_ls_permuted)\n",
    "\n",
    "end_points = torch.cat(end_points_list)\n",
    "\n",
    "if (K%2 == 0):\n",
    "    start_points = start_points[:-(K//2)]\n",
    "    end_points = end_points[:-(K//2)]\n",
    "\"\"\"\n",
    "# finally we get K*(K-1)/2 pairs of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no penalty on curvature\n",
    "load_weight_name = \"swissroll_curv_w=0_ls=R^2\"\n",
    "PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()\n",
    "\n",
    "start_points, end_points = make_pairs()\n",
    "Energy_pairwise_array_no_curv_pen = E_vmap(encoder(start_points),encoder(end_points),n_partition=100)\n",
    "Distance_ls_pairwize_array_no_curv_pen = (encoder(end_points) - encoder(start_points)).norm(dim=1)\n",
    "Distance_RD_pairwize_array_no_curv_pen = (end_points - start_points).norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with penalty on curvature\n",
    "load_weight_name = \"swissroll_curv_w=1_ls=R^2\"\n",
    "#load_weight_name = \"swissroll_curv_w=10_ls=R^2\"\n",
    "#load_weight_name = \"swissroll_curv_w=10_ls=R^2_20epochs_bs=32\"\n",
    "PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()\n",
    "\n",
    "start_points, end_points = make_pairs()\n",
    "\n",
    "Energy_pairwise_array_with_curv_pen = E_vmap(encoder(start_points),encoder(end_points),n_partition=100)\n",
    "Distance_ls_pairwize_array_with_curv_pen = (encoder(end_points) - encoder(start_points)).norm(dim=1)\n",
    "Distance_RD_pairwize_array_with_curv_pen = (end_points - start_points).norm(dim=1)\n",
    "#Energy_pairwise_array_with_curv_pen = E_vmap(start_points,end_points,n_partition=100)\n",
    "#Distance_ls_pairwize_array_with_curv_pen = (end_points - start_points).norm(dim=1)\n",
    "#Distance_RD_pairwize_array_with_curv_pen = (decoder(end_points) - decoder(start_points)).norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with penalty on curvature\n",
    "\n",
    "load_weight_name = \"swissroll_curv_w=10_ls=R^2_20epochs_bs=32\"\n",
    "PATH_enc = f'../nn_weights/encoder_{load_weight_name}'\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "PATH_dec = f'../nn_weights/decoder_{load_weight_name}'\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()\n",
    "\n",
    "start_points, end_points = make_pairs()\n",
    "\n",
    "Energy_pairwise_array_curv_w10_pen = E_vmap(encoder(start_points),encoder(end_points),n_partition=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_RD_pairwize_array_with_curv_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance_RD_pairwize_array_no_curv_pen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ground truth check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((Distance_RD_pairwize_array_no_curv_pen-Distance_RD_pairwize_array_with_curv_pen).detach(), bins = 50)\n",
    "plt.title(\"Distances in $\\mathbb{R}^D$ with and without curvature penalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((Distance_ls_pairwize_array_no_curv_pen-Distance_ls_pairwize_array_with_curv_pen).detach(), bins = 50)\n",
    "plt.title(\"Distances in latent space with and without curvature penalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "#plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in $\\mathbb{{R}}^3$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_no_curv_pen.detach().numpy(),Energy_pairwise_array_no_curv_pen.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_curv_w10_pen.detach().numpy(),\n",
    "            color = \"green\", s = 10, label = \"$\\lambda_{curv} = 10$\")\n",
    "ax.legend(loc='upper left')\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "#ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_R3_swissroll.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 24})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "#plt.title(f\"Swissroll: enegry of paths change $E_{{ij}}^{{\\lambda_{{curv}} = 1}} - E_{{ij}}^{{\\lambda_{{curv}} = 0}}$ \\n vs distance in $\\mathbb{{R}}^3$ for $C_{{{K}}}^2$ paths\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen,\n",
    "           (Energy_pairwise_array_with_curv_pen - Energy_pairwise_array_no_curv_pen).detach().numpy(),\n",
    "            color = \"magenta\", s = 10)\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "#ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$')\n",
    "ax.set_ylabel('Change in $E_{ij}$')\n",
    "#ax.set_ylabel('$E_{ij}^{\\lambda_{curv} = 1} - E_{ij}^{\\lambda_{curv} = 0}$')\n",
    "fig.savefig(\"Scatterplot_change_E_ij_dist_R3_swissroll.pdf\",bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in $\\mathbb{{R}}^3$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_no_curv_pen.detach().numpy(),Energy_pairwise_array_no_curv_pen.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_RD_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.legend(loc='upper left')\n",
    "#ax.set_xlabel('$\\|\\Psi \\circ \\Theta(X_i) - \\Psi \\circ \\Theta(X_j)\\|_2$, $\\Psi \\circ \\Theta(X_i)\\in \\mathbb{R}^3$')\n",
    "ax.set_xlabel('$\\|X_i - X_j\\|_2$, $X_i \\in \\mathbb{R}^3$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "#ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_R3_swissroll_ylogscale.pdf\", format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "fig, ax = plt.subplots(figsize=(9,9),dpi = 300)\n",
    "plt.title(f\"Swissroll: Energy of $C_{{{K}}}^2$ paths $E_{{ij}}$ vs distance in latent space\")\n",
    "ax.scatter(Distance_ls_pairwize_array_no_curv_pen.detach().numpy(),Energy_pairwise_array_no_curv_pen.detach().numpy(),\n",
    "            color = \"red\", s = 10, label = \"$\\lambda_{curv} = 0$\")\n",
    "ax.scatter(Distance_ls_pairwize_array_with_curv_pen.detach().numpy(),Energy_pairwise_array_with_curv_pen.detach().numpy(),\n",
    "            color = \"blue\", s = 10, label = \"$\\lambda_{curv} = 1$\")\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$\\|\\Theta(X_i) - \\Theta(X_j)\\|_2$, $\\Theta(X_i) \\in \\mathbb{R}^2$')\n",
    "ax.set_ylabel('$E_{ij}$')\n",
    "fig.savefig(\"Scatterplot_E_ij_dist_ls_swissroll.pdf\", format = \"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
