{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook produces the barplots comparing Autograd and finite differences with presicion FP32 and FP64. The plots are in Section 4.3.3 of chapter 4 of my thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, ricci_regularization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ricci_regularization import Sc_g_fd_batch_minigrids_rhombus\n",
    "import math\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "Path_pictures = \"../../experiments/AD_FD\"\n",
    "\n",
    "# Choose dtype\n",
    "dtype = torch.float32\n",
    "#dtype = torch.float64\n",
    "\n",
    "# Choose latent dimension\n",
    "d = 2 # for FD using rhombus it can only be == 2\n",
    "torus_ae = ricci_regularization.Architectures.TorusAE(\n",
    "        x_dim=784,\n",
    "        h_dim1=512,\n",
    "        h_dim2=256,\n",
    "        z_dim=d,\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "# Standard FP32 and FP64 error levels\n",
    "fp32_error_level = 5.96e-8\n",
    "fp64_error_level = 1.11e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(torus_ae.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing relative errors for different step h of FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "tensor_name = \"R\" # \"R\"\n",
    "# Assume tensor_jacfwd is some precomputed tensor (ground truth)\n",
    "batch_size = 1024  # Just as an example\n",
    "centers = 1.9*torch.pi*(torch.rand(batch_size, d, dtype=dtype) - 0.5)  # Simulated ground truth\n",
    "\n",
    "# We will compute tensor_fd with varying h\n",
    "if dtype == torch.float64:\n",
    "    if tensor_name == \"g\":\n",
    "        h_values = np.logspace(-9, -2, 7)  # Step sizes in logarithmic scale from 1e-5 to 1e-1 for FP64\n",
    "    elif tensor_name == \"R\":\n",
    "        h_values = np.logspace(-5, -1, 7)  # Step sizes in logarithmic scale from 1e-5 to 1e-1 for FP64\n",
    "elif dtype == torch.float32:\n",
    "    if tensor_name == \"g\":\n",
    "        h_values = 5 * np.logspace(-5, -1, 7) #np.array([0.005, 0.01, 0.02, 0.05, 0.1, 0.2])\n",
    "    elif tensor_name == \"R\":\n",
    "        h_values = 5 * np.logspace(-3, -1, 7)  # Step sizes in logarithmic scale from 1e-5 to 1e-1 for FP64\n",
    "errors = []\n",
    "mean_relative_errors = []\n",
    "mean_abs_values = []\n",
    "mae_errors = []\n",
    "distribution_of_relative_errors = []\n",
    "\n",
    "for h in h_values:\n",
    "    # Simulate tensor_fd by perturbing tensor_jacfwd with some finite difference approximation\n",
    "    if tensor_name == \"R\":\n",
    "        with torch.no_grad():\n",
    "            tensor_fd,_ = Sc_g_fd_batch_minigrids_rhombus(centers, function= decoder,h=h)  # Simulate FD grid\n",
    "        tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder)[0].detach()\n",
    "    elif tensor_name == \"g\":\n",
    "        with torch.no_grad():\n",
    "            _,tensor_fd = Sc_g_fd_batch_minigrids_rhombus(centers, function= decoder,h=h)  # Simulate FD grid\n",
    "        tensor_jacfwd = ricci_regularization.metric_jacfwd_vmap(centers,function= decoder).detach()\n",
    "    # Compute the error for this step size\n",
    "    error = torch.functional.F.mse_loss(tensor_fd, tensor_jacfwd, )\n",
    "    mean_abs_values.append( torch.mean( torch.abs(tensor_jacfwd) ) )\n",
    "    errors.append(error.item())  # Store the error as a scalar\n",
    "    mae_errors.append( torch.mean( torch.abs( tensor_fd - tensor_jacfwd ) ) )\n",
    "    mean_relative_errors.append( ( torch.abs( tensor_fd - tensor_jacfwd ) / torch.abs(tensor_jacfwd) ).mean() )\n",
    "    distribution_of_relative_errors.append( torch.abs( tensor_fd - tensor_jacfwd ) / torch.abs(tensor_jacfwd) )\n",
    "    # in %\n",
    "    #mean_relative_errors.append( 100*( torch.abs( tensor_fd - tensor_jacfwd ) / torch.abs(tensor_jacfwd) ).mean() )\n",
    "log_distribution_of_relative_errors = [torch.log10(x.flatten()) for x in distribution_of_relative_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_distribution_of_relative_errors[0].flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log of distribution of relative errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update plot configurations\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the relative error data\n",
    "plt.boxplot(log_distribution_of_relative_errors, showmeans=True, meanline=True)\n",
    "\n",
    "if dtype == torch.float32:\n",
    "    # Plot the FP32 error line as a dashed line\n",
    "    plt.axhline(y=math.log10(fp32_error_level), color='r', linestyle='--', linewidth=1.5, label=\"FP32 error (5.96e-8)\")\n",
    "elif dtype == torch.float64:\n",
    "    plt.axhline(y=math.log10(fp64_error_level), color='r', linestyle='--', linewidth=1.5, label=\"FP64 error (1.11e-15)\")\n",
    "# Axis labels\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel(f'Log of relative error of ${tensor_name}$')\n",
    "\n",
    "# Set x-ticks to only values in h_values, using const × 10^n format\n",
    "plt.xticks(np.arange(7)+1, [f'{h / (10**np.floor(np.log10(h))):.0f} $\\cdot 10^{{{int(np.floor(np.log10(h)))}}}$' for h in h_values])\n",
    "\n",
    "# Set y-ticks using scientific notation\n",
    "#plt.yticks(mean_relative_errors, [f'{y:.0e}' for y in mean_relative_errors])  # Format y-ticks in scientific notation\n",
    "\n",
    "# Add legend elements\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='green', linestyle='--', label='Mean'),\n",
    "    Line2D([0], [0], color='orange', label='Median')\n",
    "]\n",
    "# Legend and grid\n",
    "legend = plt.legend()\n",
    "plt.legend(handles = legend_elements + legend.legend_handles, loc = \"lower right\")\n",
    "plt.grid(True)\n",
    "#plt.yticks(mean_relative_errors, [f'{y:.1e}' for y in mean_relative_errors])  # Format y-ticks in scientific notation\n",
    "\n",
    "\n",
    "# Save and show plot\n",
    "plt.savefig(Path_pictures+\"/fd_\"+f'{dtype}'+f\"relative_error_boxplot_{tensor_name}.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of the optimal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy \n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Use the first part of the distribution for the test\n",
    "data = log_distribution_of_relative_errors[2]\n",
    "mean = data.mean()\n",
    "std = data.std()\n",
    "\n",
    "# Create the histograms\n",
    "plt.hist(data.numpy(), bins=100, density=True, alpha=0.8, label=\"Relative errors\")\n",
    "plt.hist(std * torch.randn(1024) + mean, bins=100, density=True, alpha=0.5, label=\"Normal samples\")\n",
    "\n",
    "# Normalize the data for Shapiro-Wilk test\n",
    "normalized_data = 5*(data - mean) / std + 0. * torch.randn(1024)\n",
    "#normalized_data = data\n",
    "# Perform Shapiro-Wilk test\n",
    "statistic, p_value = scipy.stats.shapiro(normalized_data_wo_outlyers.numpy())\n",
    "#statistic,  = scipy.stats.shapiro(normalized_data.numpy())\n",
    "# Print the results\n",
    "print(f\"Shapiro-Wilk statistic: {statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the p-value\n",
    "shapiro_result = \"\"\n",
    "if p_value > 0.05:\n",
    "    shapiro_result = \"The data is likely normally distributed (fail to reject H0).\"\n",
    "else:\n",
    "    shapiro_result = \"The data is likely not normally distributed (reject H0).\"\n",
    "\n",
    "# Add the legend\n",
    "plt.legend(loc=\"center left\")\n",
    "\n",
    "# Add the Shapiro-Wilk test result as text on the plot\n",
    "plt.text(0., -0.15, f\"Shapiro-Wilk statistic: {statistic:.3f}\", transform=plt.gca().transAxes)\n",
    "plt.text(0., -0.25, f\"P-value: {p_value / (10**np.floor(np.log10(p_value))):.0f} $\\cdot 10^{{{int(np.floor(np.log10(p_value)))}}}$\", transform=plt.gca().transAxes)\n",
    "plt.text(0., -0.35, f\"{shapiro_result}\", transform=plt.gca().transAxes)\n",
    "\n",
    "# Save and show plot\n",
    "plt.savefig(Path_pictures+\"/fd_\"+f'{dtype}'+f\"relative_error_hisogram_{tensor_name}.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_wo_outlyers = torch.sort(normalized_data).values[100:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import scipy.stats\n",
    "scipy.stats.probplot(normalized_data_wo_outlyers, dist=\"norm\", plot=pylab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log of mean relative errors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update plot configurations\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the relative error data\n",
    "plt.loglog(h_values, mean_relative_errors, marker='o', label=\"Relative error\")\n",
    "\n",
    "if dtype == torch.float32:\n",
    "    # Plot the FP32 error line as a dashed line\n",
    "    plt.axhline(y=fp32_error_level, color='r', linestyle='--', linewidth=1.5, label=\"FP32 error (5.96e-8)\")\n",
    "elif dtype == torch.float64:\n",
    "    plt.axhline(y=fp64_error_level, color='r', linestyle='--', linewidth=1.5, label=\"FP64 error (1.11e-15)\")\n",
    "# Axis labels\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Relative error of $|R|$')\n",
    "\n",
    "# Set x-ticks to only values in h_values, using scientific notation\n",
    "#plt.xticks(h_values, [f'{h:.0e}' for h in h_values])  # Format x-ticks in scientific notation\n",
    "# Set x-ticks to only values in h_values, using const × 10^n format\n",
    "plt.xticks(h_values, [f'{h / (10**np.floor(np.log10(h))):.0f} $\\cdot 10^{{{int(np.floor(np.log10(h)))}}}$' for h in h_values])\n",
    "\n",
    "# Set y-ticks using scientific notation\n",
    "#plt.yticks(mean_relative_errors, [f'{y:.0e}' for y in mean_relative_errors])  # Format y-ticks in scientific notation\n",
    "\n",
    "# Legend and grid\n",
    "plt.legend(loc = \"center right\")\n",
    "plt.grid(True)\n",
    "#plt.yticks(mean_relative_errors, [f'{y:.1e}' for y in mean_relative_errors])  # Format y-ticks in scientific notation\n",
    "\n",
    "\n",
    "# Save and show plot\n",
    "plt.savefig(Path_pictures+\"/fd_\"+f'{dtype}'+f\"relative_error_{tensor_name}.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute errors MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the error vs. h\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(h_values, errors, marker='o', label=\"MSE Error\")\n",
    "plt.loglog(h_values, mae_errors, marker='o', label=\"MAE Error\")\n",
    "plt.loglog(h_values, mean_abs_values, marker='o', label=\"Mean value of $|R|$\")\n",
    "\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Error ')\n",
    "plt.title(f'{dtype}: Errors vs. Step Size for f.d. on minigrid for scalar curvature $R$')\n",
    "\n",
    "plt.xticks(h_values, [f'{h:.3f}' for h in h_values])  # Ensuring h_values are shown as tick labels # Setting the x-ticks to match h_values\n",
    "plt.legend(loc = \"center left\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(Path_pictures+\"/fd_\"+f'{dtype}'+\"_error.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing AD vs FD with different batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 100\n",
    "\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = ricci_regularization.build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "\n",
    "    # Timing for Sc_fd\n",
    "    time_fd_fast = timeit.timeit(\n",
    "        stmt=\"ricci_regularization.curvature_loss(current_centers, h=0.01, eps=0.0, function=decoder)\",\n",
    "        setup=\"from __main__ import ricci_regularization, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_jacfwd\n",
    "    time_jacfwd = timeit.timeit(\n",
    "        stmt=\"ricci_regularization.curvature_loss_jacfwd(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import ricci_regularization, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"Sc_fd_rhombus_avg_time\": time_fd_fast / iterations,\n",
    "        \"Sc_jacfwd_avg_time\": time_jacfwd / iterations,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file\n",
    "with open(Path_pictures+'/timing_results_batch_minigrids.json', 'w') as f:\n",
    "    json.dump(timing_results, f, indent=4)\n",
    "\n",
    "# Print the timing results\n",
    "for result in timing_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "batch_sizes = [result['batch_size'] for result in timing_results][1:]\n",
    "sc_fd_rhombus_times = [result['Sc_fd_rhombus_avg_time'] for result in timing_results][1:]\n",
    "sc_jacfwd_times = [result['Sc_jacfwd_avg_time'] for result in timing_results][1:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average times for Sc_fd and Sc_jacfwd_vmap\n",
    "plt.plot(batch_sizes, sc_fd_rhombus_times, marker='o', label='FD', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_jacfwd_times, marker='s', label='AD', linestyle='-')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.xlabel('Batch Size')\n",
    "#plt.title('Timing curvature loss $\\widehat\\mathcal{L}_\\mathrm{curv}$ computation: fd on minigrids vs jacfwd')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_AD_FD.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
