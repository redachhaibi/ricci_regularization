{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "%matplotlib inline\n",
    "from functorch import jacrev,jacfwd\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"MNIST_torus_AE\"\n",
    "experiment_number = 0\n",
    "violent_saving = False # if False it will not save plots\n",
    "Path_experiments = \"/home/alazarev/CodeProjects/Experiments/\"\n",
    "Path_pictures = f\"/home/alazarev/CodeProjects/Experiments/{experiment_name}/experiment{experiment_number}\"\n",
    "if os.path.exists(Path_pictures) == False:\n",
    "    os.mkdir(Path_pictures) # needs to be commented once the folder for plots is created\n",
    "Path_weights = \"/home/alazarev/CodeProjects/ricci_regularization/\"\n",
    "#set_name = \"Swissroll\"\n",
    "#set_name = \"Synthetic\"\n",
    "set_name = \"MNIST\"\n",
    "\n",
    "d = 2         # latent space dimension\n",
    "weights_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_w = 1e4\n",
    "unif_w = 0 # 4e1\n",
    "curv_w = 0 # if 0 curvature is not computed\n",
    "compute_curvature = False\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr         = 1e-3\n",
    "momentum   = 0.8\n",
    "num_epochs = 10\n",
    "\n",
    "# Hyperparameters for data loaders\n",
    "batch_size  = 256 # was 16 initially\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "# torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Sample dictionary\n",
    "hyperparameters = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"experiment_number\":experiment_number,\n",
    "    \"set_name\": set_name,\n",
    "    \"learning_rate\": lr,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"mse_w\": mse_w,\n",
    "    \"unif_w\": unif_w,\n",
    "    \"curv_w\": curv_w,\n",
    "    \"Path_pictures\": Path_pictures,\n",
    "    \"Path_weights\": Path_weights\n",
    "}\n",
    "\n",
    "# Save dictionary to JSON file\n",
    "with open(f'{Path_experiments}json_files/hyperparameters_exp{experiment_number}.json', 'w') as json_file:\n",
    "    json.dump(hyperparameters, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization as RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of workers in DataLoader\n",
    "num_workers = 10\n",
    "\n",
    "if set_name == \"MNIST\":\n",
    "    D = 784\n",
    "    k = 10 # number of classes\n",
    "    #MNIST_SIZE = 28\n",
    "    # MNIST Dataset\n",
    "    train_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    #train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    #test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "elif set_name == \"Synthetic\":\n",
    "    D = 784       #dimension\n",
    "    k = 3         # num of 2d planes in dim D\n",
    "    n = 6*(10**3) # num of points in each plane\n",
    "    shift_class = 0.0\n",
    "    var_class = 1.0\n",
    "    intercl_var = 0.1 # this has to be greater than 0.04\n",
    "    # this creates a gaussian, \n",
    "    # i.e.random shift \n",
    "    # proportional to the value of intercl_var\n",
    "    # Generate dataset\n",
    "    # via classes\n",
    "    torch.manual_seed(0) # reproducibility\n",
    "    my_dataset = RR.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                        shift_class=shift_class, intercl_var=intercl_var, var_class=var_class)\n",
    "\n",
    "    train_dataset = my_dataset.create\n",
    "elif set_name == \"Swissroll\":\n",
    "    D = 3\n",
    "    sr_noise = 1e-6\n",
    "    sr_numpoints = 18000 #k*n\n",
    "    train_dataset =  sklearn.datasets.make_swiss_roll(n_samples=sr_numpoints, noise=sr_noise)\n",
    "    sr_points = torch.from_numpy(train_dataset[0]).to(torch.float32)\n",
    "    #sr_points = torch.cat((sr_points,torch.zeros(sr_numpoints,D-3)),dim=1)\n",
    "    sr_colors = torch.from_numpy(train_dataset[1]).to(torch.float32)\n",
    "    from torch.utils.data import TensorDataset\n",
    "    train_dataset = TensorDataset(sr_points,sr_colors)\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # Non-linearity\n",
    "        self.non_linearity = torch.sin\n",
    "        self.non_linearity2 = torch.cos # should this not be vice versa??\n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc3 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        # Double dimension as circle is mimicked using sin and cos charts\n",
    "        self.fc4 = nn.Linear(2*z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        # Concatenate sin and cos non-linearities\n",
    "        # Warning: Done along dimension 1, as dimension 0 is the batch dimension\n",
    "        #h = torch.cat( (self.non_linearity(h), self.non_linearity2(h)), 1)\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1)\n",
    "        return h # Latent variable z, Wannabe uniform on the circle\n",
    "    def encoder2lifting(self, x):\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        # Concatenate sin and cos non-linearities\n",
    "        # Warning: Done along dimension 1, as dimension 0 is the batch dimension\n",
    "        #h = torch.cat( (self.non_linearity(h), self.non_linearity2(h)), 1)\n",
    "        # cosphi,sinphi\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1) \n",
    "        cosphi = h[:, 0:d] #*0.99 could work\n",
    "        sinphi = h[:, d:2*d]\n",
    "        #phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "        phi = torch.acos(cosphi)*torch.sign(sinphi)\n",
    "        return phi\n",
    "    def encoder_torus(self, x):   \n",
    "        #This is a mapping to a feature space so it would be wrong to use it\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        return h\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        #h = self.non_linearity( math.pi*z + self.decoderBias ) # Expects 2pi periodic non-linearity to create torus topology\n",
    "        h = z\n",
    "        h = self.non_linearity( self.fc4(h))\n",
    "        h = self.non_linearity( self.fc5(h))\n",
    "        return self.non_linearity( self.fc6(h) )\n",
    "    def decoder_torus(self, z):\n",
    "        h = z\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1)\n",
    "        h = self.non_linearity( self.fc4(h))\n",
    "        h = self.non_linearity( self.fc5(h))\n",
    "        return self.non_linearity( self.fc6(h) )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x.view(-1, D))\n",
    "        return self.decoder(z), z\n",
    "\n",
    "# old model\n",
    "vae = VAE(x_dim=D, h_dim1= 512, h_dim2=256, z_dim=d)\n",
    "#changed model\n",
    "#vae = VAE(x_dim=D, h_dim1= 3, h_dim2=2, z_dim=d)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if weights_loaded == True:\n",
    "    PATH_vae = f'../nn_weights/exp{experiment_number}.pt'\n",
    "    vae.load_state_dict(torch.load(PATH_vae))\n",
    "    vae.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters(),lr=lr)\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_functionm_old(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='mean')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# MSE is computed with mean reduction in order for MSE and KLD to be of the same order\n",
    "# Inputs:\n",
    "#   recon_data: reconstructed data via decoder\n",
    "#   data: original data\n",
    "#   z: latent variable\n",
    "def loss_function_old2(recon_data, data, z, mu, Sigma):\n",
    "    MSE = F.mse_loss(recon_data, data.view(-1, D), reduction='mean')\n",
    "    KLD = 0.5 * ( torch.trace(Sigma) + mu.norm().pow(2) - d - Sigma.logdet() )\n",
    "    return (MSE + KLD)*1e4\n",
    "\n",
    "def curv_func(encoded_data, function):\n",
    "    metric_on_data = RR.metric_jacfwd_vmap(encoded_data,\n",
    "                                           function=function)\n",
    "    det_on_data = torch.det(metric_on_data)\n",
    "    Sc_on_data = RR.Sc_jacfwd_vmap(encoded_data,\n",
    "                                           function=function)\n",
    "    N = metric_on_data.shape[0]\n",
    "    Integral_of_Sc = (1/N)*(torch.sqrt(det_on_data)*torch.square(Sc_on_data)).sum()\n",
    "    return Integral_of_Sc\n",
    "    \n",
    "# Loss = MSE + Penalization + curv_loss\n",
    "#  where the penalization uses modulis of Fourier modes, of the empirical distribution.\n",
    "#  This requires batch size to be in the range of CLT.\n",
    "#\n",
    "# Inputs:\n",
    "#   recon_data: reconstructed data via decoder\n",
    "#   data: original data\n",
    "#   z: latent variable\n",
    "def loss_function(recon_data, data, z):\n",
    "    MSE = F.mse_loss(recon_data, data.view(-1, D), reduction='mean')\n",
    "    #\n",
    "    # Splits sines and cosines\n",
    "    z_sin = z[:, 0:d]\n",
    "    z_cos = z[:, d:2*d]\n",
    "    #\n",
    "    # Compute empirical first mode\n",
    "    mode1 = torch.mean( z, dim = 0)\n",
    "    mode1 = torch.sum( mode1*mode1 )\n",
    "    #\n",
    "    # Compute empirical second mode\n",
    "    mode2_1 = torch.mean( 2*z_cos*z_cos-1, dim = 0)\n",
    "    mode2_1 = torch.sum( mode2_1*mode2_1)\n",
    "    mode2_2 = torch.mean( 2*z_sin*z_cos, dim = 0)\n",
    "    mode2_2 = torch.sum( mode2_2*mode2_2 )\n",
    "    mode2 = mode2_1 + mode2_2\n",
    "    #\n",
    "    penalization = mode1 + mode2\n",
    "    #print(\"penalization: \", penalization)\n",
    "    if curv_w>0:\n",
    "        encoded_points = vae.encoder2lifting(data.view(-1, D)).detach()\n",
    "        curv_loss = curv_func(encoded_points,function=vae.decoder_torus)   \n",
    "    else:\n",
    "        if compute_curvature == True:\n",
    "            encoded_points = vae.encoder2lifting(data.view(-1, D)).detach()\n",
    "            curv_loss = curv_func(encoded_points,function=vae.decoder_torus)\n",
    "        else:\n",
    "            curv_loss = torch.zeros(1)\n",
    "    #print(\"curvature loss:\", curv_loss)\n",
    "    return MSE, penalization, curv_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_dataset[t_idx[i]][0].unsqueeze(0)\n",
    "      #encoder.eval()\n",
    "      #decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         #rec_img  = decoder(encoder(img))\n",
    "         rec_img  = decoder(encoder(img.reshape(1,D))).reshape(1,28,28)\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   \n",
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)\n",
    "def plot3losses(mse_train_list,uniform_train_list,curv_train_list):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(6,18))\n",
    "    \n",
    "    axes[0].semilogy(mse_train_list, color = 'tab:red')\n",
    "    axes[0].set_ylabel('MSE')\n",
    "    \n",
    "    axes[1].semilogy(uniform_train_list, color = 'tab:olive')\n",
    "    axes[1].set_ylabel('Uniform loss')\n",
    "    \n",
    "    axes[2].semilogy(curv_train_list, color = 'tab:blue')\n",
    "    axes[2].set_ylabel('Curvature')\n",
    "    for i in range(3):\n",
    "        axes[i].set_xlabel('Batches')\n",
    "    #fig.show()\n",
    "    plt.show()\n",
    "    return fig,axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://discuss.pytorch.org/t/covariance-and-gradient-support/16217/5\n",
    "def cov(m, rowvar=True, inplace=False):\n",
    "    '''Estimate a covariance matrix given data.\n",
    "\n",
    "    Covariance indicates the level to which two variables vary together.\n",
    "    If we examine N-dimensional samples, `X = [x_1, x_2, ... x_N]^T`,\n",
    "    then the covariance matrix element `C_{ij}` is the covariance of\n",
    "    `x_i` and `x_j`. The element `C_{ii}` is the variance of `x_i`.\n",
    "\n",
    "    Args:\n",
    "        m: A 1-D or 2-D array containing multiple variables and observations.\n",
    "            Each row of `m` represents a variable, and each column a single\n",
    "            observation of all those variables.\n",
    "        rowvar: If `rowvar` is True, then each row represents a\n",
    "            variable, with observations in the columns. Otherwise, the\n",
    "            relationship is transposed: each column represents a variable,\n",
    "            while the rows contain observations.\n",
    "\n",
    "    Returns:\n",
    "        The covariance matrix of the variables.\n",
    "    '''\n",
    "    if m.dim() > 2:\n",
    "        raise ValueError('m has more than 2 dimensions')\n",
    "    if m.dim() < 2:\n",
    "        m = m.view(1, -1)\n",
    "    if not rowvar and m.size(0) != 1:\n",
    "        m = m.t()\n",
    "    # m = m.type(torch.double)  # uncomment this line if desired\n",
    "    fact = 1.0 / (m.size(1) - 1)\n",
    "    if inplace:\n",
    "        m -= torch.mean(m, dim=1, keepdim=True)\n",
    "    else:\n",
    "        m = m - torch.mean(m, dim=1, keepdim=True)\n",
    "    mt = m.t()  # if complex: mt = m.t().conj()\n",
    "    return fact * m.matmul(mt).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x = torch.rand(1,784)\n",
    "vae = VAE(x_dim=D, h_dim1= 512, h_dim2=256, z_dim=d)\n",
    "optimizer = optim.Adam(vae.parameters(),lr=lr)\n",
    "vae.train()\n",
    "for (data,label) in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    data = data.view(-1, D).cpu()\n",
    "    recon_data = vae(data)[0]\n",
    "    #recon_data = vae.decoder_torus(vae.encoder2lifting(data))\n",
    "    mse_loss = F.mse_loss(recon_data, data, reduction='mean')\n",
    "    curv_loss = curv_func(vae.encoder2lifting(data).detach(),function=vae.decoder_torus) # use detach() to fix the points\n",
    "    \n",
    "    myloss = 1e4*mse_loss + 1e3*curv_loss\n",
    "    #myloss = 1e3*curv_func(vae.encoder2lifting(data.view(-1,D)).detach(),function=vae.decoder_torus)\n",
    "    #myloss = vae.encoder2lifting(data.view(-1,D)).norm()\n",
    "    #myloss = vae.encoder2lifting(x).norm()\n",
    "    #print(\"\\n 4d repr:\", vae.encoder(x))\n",
    "    #myloss = 1e3*curv_func(vae.encoder_torus(data.view(-1,D)),function=vae.decoder_torus)\n",
    "    \n",
    "    myloss.backward()\n",
    "    optimizer.step()\n",
    "    print(myloss)\n",
    "    plot_ae_outputs(vae.encoder2lifting,vae.decoder_torus)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, mse_loss_array=[], uniform_loss_array=[], curvatue_loss_array = []):\n",
    "    batch_idx = 0\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch %d\"%epoch)\n",
    "    t = tqdm( train_loader, position=0 )\n",
    "    for (data, labels) in t:\n",
    "        #data = data.cuda()\n",
    "        #print(data.shape)\n",
    "        data = data.cpu()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        recon_batch, z = vae(data)\n",
    "        mse_loss, uniform_loss, curvature_loss = loss_function(recon_batch, data, z)\n",
    "        loss = mse_w*mse_loss + unif_w*uniform_loss + curv_w*curvature_loss\n",
    "        #loss = mse_w*mse_loss + unif_w*uniform_loss \n",
    "        #loss = curv_w*curvature_loss\n",
    "        print(f\"batch:{batch_idx}, MSE:{mse_loss}, Uniform:{uniform_loss}, Curvature:{curvature_loss}.\\n\")\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "        mse_loss_array.append(mse_loss.item())\n",
    "        uniform_loss_array.append(uniform_loss.item())\n",
    "        curvatue_loss_array.append(curvature_loss.item())\n",
    "        #loss_array.append(loss.item())\n",
    "        # Progress bar\n",
    "        t.set_description_str(desc=\"Average train loss: %.6f\"% (train_loss / len(train_loader.dataset)) )\n",
    "        #if (batch_idx % 100 == 0):\n",
    "        #    plot3losses(mse_loss_array,uniform_loss_array,curvatue_loss_array)\n",
    "        batch_idx += 1\n",
    "    # end for \n",
    "    \n",
    "    \n",
    "    return mse_loss_array, uniform_loss_array, curvatue_loss_array\n",
    "\n",
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        t = tqdm( test_loader, desc=\"Test\", position=1 )\n",
    "        for data, _ in t:\n",
    "            #data = data.cuda()\n",
    "            data = data.cpu()\n",
    "            recon, z = vae(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, z).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Total test set loss: {:.4f}'.format(test_loss))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss_array=[]\n",
    "uniform_loss_array=[]\n",
    "curvatue_loss_array = []\n",
    "# Launch\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  mse_loss_array,uniform_loss_array,curvatue_loss_array = train(epoch, mse_loss_array, uniform_loss_array, curvatue_loss_array)\n",
    "  plot3losses(mse_loss_array,uniform_loss_array,curvatue_loss_array)\n",
    "  plot_ae_outputs(vae.encoder2lifting,vae.decoder_torus)\n",
    "  #test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_vae = f'../nn_weights/exp{experiment_number}.pt'\n",
    "torch.save(vae.state_dict(), PATH_vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "Path_pictures = f\"/home/alazarev/CodeProjects/Experiments/{experiment_name}/experiment{experiment_number}\"\n",
    "if os.path.exists(Path_pictures) == False:\n",
    "    os.mkdir(Path_pictures) # needs to be commented once the folder for plots is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss ploting\n",
    "fig,axes = plot3losses(mse_loss_array,uniform_loss_array,curvatue_loss_array)\n",
    "fig.savefig(f\"{Path_pictures}/losses_exp{experiment_number}.pdf\",bbox_inches='tight',format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspiration for vae.encoder2lifting\n",
    "\"\"\"\n",
    "def circle2anglevectorized(zLatentTensor,d = d):\n",
    "    cosphi = zLatentTensor[:, 0:d]\n",
    "    sinphi = zLatentTensor[:, d:2*d]\n",
    "    phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "    return phi\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zlist = []\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "#for (data, labels) in train_loader:\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(vae(data)[0])\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(vae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()\n",
    "#assert torch.equal(enc,enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#angleLatentviatorch = circle2anglevectorized(zLatent_tensor)/math.pi\n",
    "#plt.scatter(angleLatentviatorch[:,0],angleLatentviatorch[:,1], c=labels, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784).to(dtype = torch.float32)).detach()\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784)/256).detach() # this works!!!\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784)/256).detach()\n",
    "#enc = vae.encoder_torus(train_dataset.data.reshape(-1,784)/256).detach()\n",
    "#plt.scatter(enc[:,0],enc[:,1], c=train_dataset.targets, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap=discrete_cmap(k, 'jet'))\n",
    "plt.colorbar(ticks=range(k))\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{Path_pictures}/latent_space_exp{experiment_number}.pdf\",bbox_inches='tight',format=\"pdf\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RG = RR.RiemannianGeometry(latent_space_dim=4,function=vae.decoder,AD_method=jacfwd,eps=0.01)\n",
    "RG.Sc(torch.rand(1,4))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
