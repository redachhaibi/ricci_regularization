{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb61206",
   "metadata": {},
   "source": [
    "NB! This is an old notebook. It contains a wrong (very unprecise) way of computing Scalar curvature of the latent space with f.d. formulas used for computing derivatives. Has to be redone!\n",
    "\n",
    "The autoencoder (AE) consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi \\ ,  \n",
    "\\end{equation}.\n",
    "\n",
    "The notebook contains:\n",
    "1) Loading weights of a pre-trained convolutional AE and plotting its latent space: point plot and manifold plot. If \"violent_saving\" == True, plots are saved locally.\n",
    "2) Auxillary tensors involving higher order derivatives of the decoder $\\Psi$ are computed with f.d.: metric $g$ and its derivatives, Riemann tensor $R^{i}_{jkl}$, Ricci tensor $R_{ij}$ and scalar curvature.\n",
    "3) Geodesics shooting via Runge-Kutta approximation. A single plot with a scalar curvature heatmap and geodesics on it is constructed.\n",
    "4) Prototype of metric evolution by Ricci flow equation \n",
    "\n",
    "NB! by default the metric $g$ is the pull-back by the decoder as described above. But one can use any custom metric by manually setting it in \"specific_metric\" function, that computes the metric matrix at a point $u\\in \\mathbb{R}: \\ g(u)$ given the local coordinates of the point $u$ in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import ricci_regularization\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            #nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "d = 2\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "\n",
    "# Check if the GPU is available\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Force CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "#without curvature in Loss func\n",
    "PATH_enc = '../nn_weights/encoder_conv_autoenc.pt'\n",
    "PATH_dec = '../nn_weights/decoder_conv_autoenc.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_convAE_curv_0.1.pt'\n",
    "#PATH_dec = 'decoder_convAE_curv_0.1.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_curw_w=0.000001_10epoch.pt'\n",
    "#PATH_dec = 'decoder_curw_w=0.000001_10epoch.pt'\n",
    "\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "violent_saving = False # if False it will not save plots\n",
    "\n",
    "experiment_json = f'../experiments/MNIST_torus_AEexp34.json'\n",
    "mydict = ricci_regularization.get_dataloaders_tuned_nn(Path_experiment_json=experiment_json)\n",
    "\n",
    "torus_ae = mydict[\"tuned_neural_network\"]\n",
    "test_loader = mydict[\"test_loader\"]\n",
    "json_config = mydict[\"json_config\"]\n",
    "Path_pictures = json_config[\"Path_pictures\"]\n",
    "Path_experiments = json_config[\"Path_experiments\"]\n",
    "experiment_name = json_config[\"experiment_name\"]\n",
    "experiment_number = json_config[\"experiment_number\"]\n",
    "curv_w = json_config[\"losses\"][\"curv_w\"]\n",
    "# D is the dimension of the dataset\n",
    "D = 784\n",
    "# k from the JSON configuration file is the number of classes\n",
    "k = json_config[\"dataset\"][\"parameters\"][\"k\"]\n",
    "set_name = json_config[\"dataset\"][\"name\"]\n",
    "\n",
    "encoder = torus_ae.encoder\n",
    "decoder = torus_ae.decoder_torus\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from latnt code and calculate mean and std\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # calculate mean and std of latent code, generated takining in test images as inputs \n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    images = images.reshape(-1,D)\n",
    "    latent = encoder(images)\n",
    "    latent = latent.cpu()\n",
    "\n",
    "    mean = latent.mean(dim=0)\n",
    "    print(mean)\n",
    "    std = (latent - mean).pow(2).mean(dim=0).sqrt()\n",
    "    print(std)\n",
    "\n",
    "    # sample latent vectors from the normal distribution\n",
    "    latent = torch.randn(128, d)*std + mean\n",
    "    #print(latent)\n",
    "    #print(latent.shape)\n",
    "\n",
    "    # reconstruct images from the random latent vectors\n",
    "    latent = latent.to(device)\n",
    "    img_recon = decoder(latent)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    #show_image(torchvision.utils.make_grid(img_recon[:100],10,5))\n",
    "    #plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fa63741",
   "metadata": {},
   "source": [
    "Point plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf81ed4",
   "metadata": {},
   "source": [
    "Manifold plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "numsteps = 10\n",
    "#xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)\n",
    "#ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)\n",
    "xs = torch.linspace(-torch.pi, torch.pi, steps = numsteps)\n",
    "ys = torch.linspace(-torch.pi, torch.pi, steps = numsteps)\n",
    "uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "# True Manifold plot\n",
    "truegrid = torch.cartesian_prod(ys,- xs)\n",
    "latent = - truegrid.roll(1,1)\n",
    "latent = latent.to(device)\n",
    "img_recon = decoder(latent)\n",
    "img_recon = img_recon.cpu()\n",
    "\n",
    "fig, ax  = plt.subplots(figsize=(20, 20))\n",
    "img_grid = torchvision.utils.make_grid(img_recon[:100],10,10)\n",
    "show_image(img_grid.detach())\n",
    "plt.show()\n",
    "print(latent.shape)\n",
    "print(img_recon.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d57b3499",
   "metadata": {},
   "source": [
    "# Fast way to compute metric on a grid over the latent space (torch.roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the scale of the grid which is numsteps \\times numsteps points\n",
    "\n",
    "numsteps = 100\n",
    "zoom = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a863873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "\n",
    "# Centralized and scaled evaluation \n",
    "xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)/zoom\n",
    "ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)/zoom\n",
    "\n",
    "#fixed location of latent space evaluation\n",
    "#xs = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "#ys = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "\n",
    "#uniform_grid = torch.cartesian_prod(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357de2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alt grid\n",
    "#numsteps = 10\n",
    "\n",
    "#xs = torch.linspace(1.2-0.3, 1.2+0.3, steps = numsteps)\n",
    "#ys = torch.linspace(0.6-0.3, 0.6+0.3, steps = numsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2867e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true grid starts from left bottom corner. x is the first to increase\n",
    "tgrid = torch.cartesian_prod(ys, xs)\n",
    "tgrid = tgrid.roll(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ac818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latent = tgrid\n",
    "#latent = latent.to(device)\n",
    "#psi = decoder(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric on a grid\n",
    "def g(grid):\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    psi = decoder(latent)\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    \n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*hx)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*hy)\n",
    "    \n",
    "    metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    metric = metric.view(4, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperbolic metric and its derivatives on a grid\n",
    "R = 10\n",
    "def specific_metric (u): \n",
    "    # u is the vector of points\n",
    "    #R = 5 #Radius\n",
    "    phi = u[:,0]\n",
    "    theta = u[:, 1]\n",
    "    n = u.shape[0] #number of points\n",
    "    g = torch.zeros((n,2,2))\n",
    "\n",
    "    #Sphere\n",
    "    g11 = torch.cos(theta)**2\n",
    "    g12 = torch.zeros(n)\n",
    "    g21 = torch.zeros(n)\n",
    "    g22 = torch.ones(n)\n",
    "\n",
    "    #hyperbolic metric on a half plane\n",
    "    #g11 = 1/theta**2\n",
    "    #g12 = torch.zeros(n)\n",
    "    #g21 = torch.zeros(n)\n",
    "    #g22 = 1/theta**2\n",
    "\n",
    "    g = torch.cat((g11, g12, g21, g22)).view(4,n)\n",
    "    g = g.T\n",
    "    g = g.view(n, 2, 2)\n",
    "    g = (R**2)*g\n",
    "    #g = (R**2)*torch.tensor([[torch.cos(theta)**2, 0],[0, 1]])\n",
    "    return g\n",
    "def specific_metric_der (u): \n",
    "    #phi, theta = u\n",
    "    #think of x = phi, y = theta\n",
    "    # u is the vector of points\n",
    "    #R = 5 #Radius\n",
    "    phi = u[:,0]\n",
    "    theta = u[:, 1]\n",
    "    n = u.shape[0] #number of points\n",
    "    g = torch.zeros((n,2,2,2))\n",
    "    \n",
    "    #x derivatives of g\n",
    " \n",
    "    gx11 = torch.zeros(n)\n",
    "    gx12 = torch.zeros(n)\n",
    "    gx21 = torch.zeros(n)\n",
    "    gx22 = torch.zeros(n)\n",
    "\n",
    "    gx = torch.cat((gx11, gx12, gx21, gx22)).view(4,n)\n",
    "    gx = gx.T\n",
    "    gx = gx.view(n, 2, 2)\n",
    "    \n",
    "    #y derivatives of g\n",
    "\n",
    "    #sphere\n",
    "    gy11 = -R**2*torch.sin(2*theta)\n",
    "    gy12 = torch.zeros(n)\n",
    "    gy21 = torch.zeros(n)\n",
    "    gy22 = torch.zeros(n)\n",
    "\n",
    "\n",
    "\n",
    "    #hyperbolic metric\n",
    "    #gy11 = -2/theta**3\n",
    "    #gy12 = torch.zeros(n)\n",
    "    #gy21 = torch.zeros(n)\n",
    "    #gy22 = -2/theta**3\n",
    "    \n",
    "    gy = torch.cat((gy11, gy12, gy21, gy22)).view(4,n)\n",
    "    gy = gy.T\n",
    "    gy = gy.view(n, 2, 2)\n",
    "\n",
    "    dg = torch.cat((gx,gy),1).view(n,2,2,2)\n",
    "    #g = np.array([[[0, 0],\n",
    "    #               [0, 0]],\n",
    "    #              [[-R**2*np.sin(2*theta), 0],\n",
    "    #               [0, 0]]])\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the grid of metric\n",
    "with torch.no_grad():\n",
    "    metric = g(tgrid)\n",
    "    #metric = specific_metric(tgrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084965d9",
   "metadata": {},
   "source": [
    "## Heatmap of frobenius norm of metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast computation of Frobenious norm on the grid without borders\n",
    "Newfrob = metric.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "Newfrob = Newfrob[1:-1,1:-1].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map of the frobenius norm\n",
    "h = plt.contourf(xs[1:-1], ys[1:-1], Newfrob)\n",
    "plt.title('Heatmap of the Frobenius norm of the metric')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "plt.colorbar(label=\"Frobenius norm of the metric\")\n",
    "#plt.xlim(-1.5 + mean[0], 1.5 + mean[0])\n",
    "#plt.ylim(-1.5 + mean[1], 1.5 + mean[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80195e2b",
   "metadata": {},
   "source": [
    "### Derivatives of the metric and Christoffel symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simultaneous differentiation on a grid with torch.roll\n",
    "def diff_by_x(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*h)\n",
    "    return dpsidx\n",
    "def diff_by_y(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of the metric on a grid\n",
    "def dg_grid (grid): #dg\n",
    "    \n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    psi = decoder(latent)\n",
    "    \n",
    "    dpsidx = diff_by_x(psi, numsteps, hx)\n",
    "    dpsidy = diff_by_x(psi, numsteps, hy)\n",
    "    dpsidx_second = diff_by_x(dpsidx, numsteps, hx)\n",
    "    dpsidx_dy = diff_by_y(dpsidx, numsteps, hy)\n",
    "    dpsidy_second = diff_by_y(dpsidy, numsteps, hy)\n",
    "    \n",
    "    #metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),\n",
    "    #                  (dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    \n",
    "    dgdx = torch.cat((2*(dpsidx*dpsidx_second).sum((1,2,3)),(dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),2*(dpsidy * dpsidx_dy).sum((1,2,3))),0)\n",
    "    dgdy = torch.cat((2*(dpsidx*dpsidx_dy).sum((1,2,3)),(dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),2*(dpsidy*dpsidy_second).sum((1,2,3))),0)\n",
    "    metric_der = torch.cat((dgdx, dgdy), 0)\n",
    "    metric = metric_der\n",
    "    metric = metric.view(8, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 4)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the grid of metric derivatives\n",
    "with torch.no_grad():\n",
    "    metric_der = dg_grid(tgrid)\n",
    "    #metric_der = specific_metric_der(tgrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means that we can simultanuousely invert all the matrices over the grid\n",
    "torch.equal(torch.inverse(metric[0]),torch.inverse(metric)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the inverse of the metric on a grid\n",
    "metric_inv = torch.inverse(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56675209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols on a grid\n",
    "def Ch_grid(grid, metric_inv=metric_inv, metric_der=metric_der):\n",
    "    #x = grid[:,0]\n",
    "    #y = grid[:, 1]\n",
    "    n = grid.shape[0]\n",
    "    Ch = torch.zeros((n, 2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    #Ch^l_ij\n",
    "                    Ch[:,l,i,j] += 0.5 * metric_inv[:,l,k] * (metric_der[:,i,k,j] + metric_der[:,j,i,k] - metric_der[:,k,i,j]) \n",
    "                    \n",
    "                    #Ch[l,i,j] += 0.5 * g_inv(grid)[l,k] * (dg(grid)[i,k,j] + dg(grid)[j,i,k] - dg(grid)[k,i,j]) #Ch^l_ij\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Christoffel on a grid\n",
    "Ch_grid(tgrid).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65645bf0",
   "metadata": {},
   "source": [
    "Derivatives of Christoffel symbols on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e49507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of Christoffel symbols on a grid\n",
    "def Ch_der_grid(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    n = grid.shape[0]\n",
    "\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    Chdx = diff_by_x(Ch_grid(grid,metric_inv, metric_der), numsteps, hx)\n",
    "    Chdy = diff_by_y(Ch_grid(grid,metric_inv, metric_der), numsteps, hy)\n",
    "    Chder = torch.cat((Chdx, Chdy), -1)\n",
    "    Chder = Chder.view(n,2,2,2,2)\n",
    "    Chder = Chder.transpose(-1,-2)\n",
    "    return Chder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2545e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_der_grid(tgrid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem_old(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    n = grid.shape[0]\n",
    "    Ch = Ch_grid(grid,metric_inv, metric_der)\n",
    "    Ch_der = Ch_der_grid(grid,metric_inv, metric_der)\n",
    "\n",
    "    Riem = torch.zeros(n, 2, 2, 2, 2)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                for l in range(2):                    \n",
    "                    Riem[:, i, j, k, l] = Ch_der[:, i, l, j, k] - Ch_der[:, i, k, j, l] \n",
    "                    for p in range(2):\n",
    "                        Riem[:, i, j, k, l] += (Ch[:, i, k, p]*Ch[:, p, l, j] - Ch[:, i, l, p]*Ch[:, p, k, j])\n",
    "    return Riem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78da820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    Ch = Ch_grid(grid,metric_inv, metric_der)\n",
    "    Ch_der = Ch_der_grid(grid,metric_inv, metric_der)\n",
    "\n",
    "    Riem = torch.einsum(\"tiljk->tijkl\",Ch_der) - torch.einsum(\"tikjl->tijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"tikp,tplj->tijkl\", Ch, Ch) - torch.einsum(\"tilp,tpkj->tijkl\", Ch, Ch)\n",
    "    return Riem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb360de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Riem(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a27b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scew symmetry check\n",
    "torch.equal(Riem(tgrid)[:,0,0,0,1], - Riem(tgrid)[:,0,0,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "Riem_old(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SlowRiemann = Riem_old(tgrid)\n",
    "FastRiemann = Riem(tgrid)\n",
    "torch.equal(SlowRiemann, FastRiemann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(SlowRiemann-FastRiemann)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricci curvature tensor via Riemann\n",
    "# R_ab = Riem^c_acb\n",
    "def Ric_old(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    n = grid.shape[0]\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    Riemann = Riem(grid,metric_inv, metric_der)\n",
    "\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riemann[:, c, a, c, b]\n",
    "    return Ric\n",
    "    # takes 2.5 secs on 100 by 100 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da18865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ric(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    Riemann = Riem(grid,metric_inv, metric_der)\n",
    "    Ric = torch.einsum(\"tcacb->tab\",Riemann)\n",
    "    return Ric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastRicci = Ric(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6998a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SlowRicci = Ric_old(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296755db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(SlowRicci, FastRicci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar curvature tensor via Riemann and Ricci\n",
    "# R_ab = Riem^c_acb\n",
    "# R = g^ij * R_ij\n",
    "def Sc_old(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    Riemann = Riem_old(grid,metric_inv, metric_der)\n",
    "    n = grid.shape[0]\n",
    "    Sc = torch.zeros(n)\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    \n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riemann[:, c, a, c, b]\n",
    "    Sc = metric_inv*Ric\n",
    "    Sc = torch.sum(Sc,(1,2))\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32422a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sc(grid,metric_inv=metric_inv, metric_der=metric_der):\n",
    "    Ricci = Ric(grid,metric_inv, metric_der)\n",
    "    #Sc = metric_inv * Ricci\n",
    "    #Sc = torch.sum(Sc,(1,2))\n",
    "    Sc = torch.einsum(\"tij,tij->t\", metric_inv, Ricci)\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar_curvature_grid = Sc(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Scalar_curvature_grid_old = Sc_old(tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(Scalar_curvature_grid_old-Scalar_curvature_grid)).max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c074afa5",
   "metadata": {},
   "source": [
    "# Scalar curvature heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Sc_curv_plot (grid = tgrid):\n",
    "    Scalar_curvature_grid = Sc(tgrid)\n",
    "    # Fast computation of Frobenious norm on the grid without borders\n",
    "    Scalar_curv = Scalar_curvature_grid.view(numsteps,numsteps)\n",
    "    #Scalar_curv_check = Scalar_curv[30:-30,30:-30].transpose(0,1)\n",
    "    Scalar_curv = Scalar_curv[2:-2,2:-2].transpose(0,1)\n",
    "\n",
    "    \n",
    "    #Heat map of the Scalar curvature\n",
    "    h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "    #h = plt.contourf(xs[30:-30], ys[30:-30], Scalar_curv_check)\n",
    "    plt.title('Heat map of the Scalar curvature ')\n",
    "    plt.xlabel( \"x coordinate\")\n",
    "    plt.ylabel( \"y coordinate\")\n",
    "    plt.axis('scaled')\n",
    "    #plt.xlim(-1.5,1.5)\n",
    "    #plt.ylim(-1.5,1.5)\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dcb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_Sc_curv_plot(tgrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "def372d2",
   "metadata": {},
   "source": [
    "Simplified energy functional computation: $F_{new}(g) = \\int_{M}  R^{2} d\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ef7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curv_func(metric = metric, grid = tgrid):\n",
    "    metric_no_border = metric.reshape(numsteps, numsteps,2,2)[2:-2,2:-2]\n",
    "    det_metric_no_border = torch.det(metric_no_border)\n",
    "    det_sqrt = torch.sqrt(det_metric_no_border)\n",
    "    #grid = tgrid\n",
    "    Scalar_curvature_grid = Sc(grid)\n",
    "    # Fast computation of Frobenious norm on the grid without borders\n",
    "    Scalar_curv = Scalar_curvature_grid.view(numsteps,numsteps)\n",
    "    #Scalar_curv_check = Scalar_curv[30:-30,30:-30].transpose(0,1)\n",
    "    Scalar_curv = Scalar_curv[2:-2,2:-2].transpose(0,1)\n",
    "\n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    F_new = (det_sqrt*torch.square(Scalar_curv)*hx*hy).sum()\n",
    "    print(F_new)\n",
    "    return\n",
    "\n",
    "curv_func(metric, tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc148cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no curvature ~240\n",
    "#1 epoch with curvature ~66\n",
    "#10 epochs with curvature ~56"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5808c9e7",
   "metadata": {},
   "source": [
    "# Geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for making a piecewise constant metric from its evaluation on a grid\n",
    "def find_nearest_index (grid, u):\n",
    "    index = int(torch.min(abs(grid - u),0).indices.sum())\n",
    "    #index = int((((u - tgrid[0])*numsteps/size).floor()*torch.tensor([1.,numsteps])).sum()) #thisd could be faster\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y = [u , v]\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    u = y[0:2:]\n",
    "    v = y[2::]\n",
    "    dudt = v\n",
    "    #dvdt = torch.zeros(2)\n",
    "    dvdt = np.zeros(2)\n",
    "    u = torch.from_numpy(u)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[l] -= (Ch(u)[l,i,j]).numpy() * v[i] * v[j]\n",
    "    dydt = np.concatenate((dudt, dvdt))\n",
    "    #dydt = torch.cat((dudt, dvdt),0)\n",
    "    return dydt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be23691a",
   "metadata": {},
   "source": [
    "## Vectorized computation of geodesics (with a loop in find_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could be done faster\n",
    "def find_nearest_indices (grid, u):\n",
    "    #this could be done more efficiently\n",
    "    n = u.shape[0]\n",
    "    indices = torch.zeros(n)\n",
    "    for i in range(n):\n",
    "        indices[i] = find_nearest_index(grid, u[i])\n",
    "    indices = indices.to(torch.int64) # just some magic to make it work\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nearest_index(tgrid, torch.tensor([0.5,0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce73044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant inverse of g\n",
    "def g_inv_vect (grid, u): #inverse metric\n",
    "    #index = find_nearest_index(tgrid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    #A = metric[index]\n",
    "    A = torch.index_select(metric, 0, indices)\n",
    "    g_inv = torch.inverse(A)\n",
    "    return g_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869be7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_inv_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a52dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant derivatives of g\n",
    "def dg_vect (grid, u): #dg\n",
    "    #index = find_nearest_index(uniform_grid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    g = torch.index_select(metric_der, 0, indices)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6348ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dg_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8850891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols at a vector of n points. u has shape (n, x, y)\n",
    "def Ch_vect(grid, u):\n",
    "    n = u.shape[0]\n",
    "    Ch = torch.zeros((n,2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    Ch[:,l,i,j] += 0.5 * g_inv_vect(grid, u)[:,l,k] * (dg_vect(grid, u)[:,i,k,j] + dg_vect(grid, u)[:,j,i,k] - dg_vect(grid, u)[:,k,i,j]) #Ch^l_ij\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch(check[1])\n",
    "# just to check there is no mistake in vectorized vertion Ch_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ch_vect still exploits the loop in find_indices\n",
    "#Ch_vect(tgrid,tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b88601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y has shape num of points, u, v\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    n = y.shape[0]\n",
    "    u = y[: , 0:2:]\n",
    "    v = y[: , 2::]\n",
    "    dudt = v\n",
    "    dvdt = torch.zeros(n, 2)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[:, l] -= Ch_vect(tgrid, u)[:, l,i,j] * v[:, i] * v[:, j] #here we use Ch_vect instead od Ch\n",
    "    dydt = torch.cat((dudt.T, dvdt.T)).T\n",
    "    # dydt = np.concatenate((dudt, dvdt))\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rungekutta_new(f, y0, t, args=()):\n",
    "    nt = len(t) # number of steps in time\n",
    "    # len(y0[0]) is the number of initial conditions\n",
    "    # len(y0[1]) is the dimention of the state space. In our case it is 4 \n",
    "    y = torch.zeros((nt, y0.shape[0],y0.shape[1]))\n",
    "    y[0,:,:] = y0\n",
    "    for i in range(nt - 1):\n",
    "        y[i+1,:,:] = y[i,:,:] + (t[i+1] - t[i])*f(y[i,:,:], t[i], *args)\n",
    "        print(y[i,:,:])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at random points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 10\n",
    "v = torch.tensor([0.00, 0.00,1.00])/zoom\n",
    "v = v.repeat(m,1)\n",
    "u = torch.rand(m,1)/zoom\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed = torch.cat((u,v),1)\n",
    "RandStartComSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 21)\n",
    "sol3 = rungekutta_new(geod, RandStartComSpeed, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sol3[:15, :, 0], sol3[:15, :, 1]) #geodesics are shortened by step 15 because of border effects\n",
    "plt.title( \"Plots of geodesics with rnd ititial point and common initial speed\")\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79da24e3",
   "metadata": {},
   "source": [
    "# Scalar curvature and geodesics on one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at different initial points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 15 #number of geodesics\n",
    "#v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = torch.tensor([0.00, 0.00,1.00/zoom])\n",
    "v = v.repeat(m,1)\n",
    "#u = torch.rand(m,1)\n",
    "#u = torch.linspace(0.01,1.51,steps=m).reshape(15,1)\n",
    "u = torch.linspace(0.01,(m/10+0.01)/zoom,steps=m).reshape(15,1)\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed2 = torch.cat((u,v),1)\n",
    "RandStartComSpeed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7652a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 41)\n",
    "sol4 = rungekutta_new(geod, RandStartComSpeed2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96669dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalar curvature and geodesics\n",
    "h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "plt.plot(sol4[:, :, 0], sol4[:, :, 1]) #geodesics are shortened by step 30 because of border effects\n",
    "plt.title('Scalar curvature and geodesics')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "plt.xlim(0,1.75/zoom)\n",
    "plt.ylim(0,1.25/zoom)\n",
    "plt.colorbar(label=\"Scalar curvature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550767ae",
   "metadata": {},
   "source": [
    "# Evolution of the curvature under the discretization of the Ricci flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fa9fb",
   "metadata": {},
   "source": [
    "#### $g_{i+1} = g_i - 2Ric \\cdot dt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd014f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g(t_i+1)\n",
    "dt = 0.1 # size of one step\n",
    "steps = 10 # number of evolution steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34274c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_der_not_using_decoder(grid=tgrid,metric=metric):\n",
    "    # compute step sizes\n",
    "    grid = tgrid\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "        \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    dgdx = diff_by_x(metric, numsteps, hx)\n",
    "    dgdy = diff_by_y(metric, numsteps, hy)\n",
    "\n",
    "    metric_der = torch.cat((dgdx, dgdy), -1)\n",
    "    metric_der = metric_der.view(numsteps*numsteps, 2, 2, 2)\n",
    "    metric_der = metric_der.transpose(-1,-2)\n",
    "\n",
    "    #metric_der = torch.cat((dgdx, dgdy), 0)\n",
    "    #metric_der = metric_der.view(8, numsteps*numsteps)\n",
    "    #metric_der = metric_der.transpose(0, 1)\n",
    "    #metric_der = metric_der.view(numsteps*numsteps, 2, 4)\n",
    "    #metric_der = metric_der.view(numsteps*numsteps, 2, 2, 2)\n",
    "    return metric_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e873fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der_not_using_decoder().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f338f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46783e80",
   "metadata": {},
   "source": [
    "#### the computation of metric derivatives to be fixed!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(metric_der_not_using_decoder(), metric_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d371d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(metric_der_not_using_decoder() - metric_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the metric of the latent space and take it as initial condition\n",
    "with torch.no_grad():\n",
    "    metric = g(tgrid)\n",
    "g_array = []\n",
    "g_array.append(metric) # g_0 = metric\n",
    "# we need to recompute metric_der and metric after every evo step\n",
    "# let us compute evoluation of the metric\n",
    "for i in range(steps):\n",
    "    Ricci_tensor = Ric(tgrid, metric_inv, metric_der_not_using_decoder(tgrid,g_array[i]))\n",
    "    g_new = g_array[i] - 2*Ricci_tensor*dt\n",
    "    g_array.append(g_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems to blow up!\n",
    "# probably there is an error in metric_der computation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
