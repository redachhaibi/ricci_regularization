{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian K means\n",
    "Steps:\n",
    "\n",
    "1) Guess initial cluster centers (Euclidean K-means)\n",
    "2) Shift the local chart center to cluster basepoints\n",
    "3) Do log maps with base points\n",
    "4) Recompute cluster centers in log maps\n",
    "5) Return (only cluster centers) on the manifold by exp maps with corresponding \n",
    "base points\n",
    "6) unshift\n",
    "7) recluster\n",
    "8) check tolerance (cluster center shift):\n",
    "go to step 1. repeat until clusters are stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import stochman\n",
    "from stochman.manifold import EmbeddedManifold\n",
    "from stochman.curves import CubicSpline\n",
    "\n",
    "violent_saving = True\n",
    "\n",
    "#experiment_json = f'../experiments/MNIST_torus_AEexp34.json' # no curv_pen\n",
    "\n",
    "experiment_json = f'../experiments/MNIST01_torus_AEexp7.json'\n",
    "mydict = ricci_regularization.get_dataloaders_tuned_nn(Path_experiment_json=experiment_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_ae = mydict[\"tuned_neural_network\"]\n",
    "test_loader = mydict[\"test_loader\"]\n",
    "json_cofig = mydict[\"json_config\"]\n",
    "Path_pictures = json_cofig[\"Path_pictures\"]\n",
    "exp_number = json_cofig[\"experiment_number\"]\n",
    "curv_w = json_cofig[\"losses\"][\"curv_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 784\n",
    "k = json_cofig[\"dataset\"][\"parameters\"][\"k\"]\n",
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "feature_space_encoding_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( test_loader, position=0 ):\n",
    "#for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    feature_space_encoding_list.append(torus_ae.encoder_torus(data.view(-1,D)))\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "feature_space_encoding = torch.cat(feature_space_encoding_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1],c = color_array,cmap=ricci_regularization.discrete_cmap(k,\"jet\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Initial guess via Euclidean K-means via Geomstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this adds an environmental variable\n",
    "#%env GEOMSTATS_BACKEND=pytorch\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.visualization as visualization\n",
    "from geomstats.geometry.hypersphere import Hypersphere\n",
    "from geomstats.learning.kmeans import RiemannianKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circumference1 = Hypersphere(dim=1)\n",
    "circumference2 = Hypersphere(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building torus as a product $\\mathcal{T} = \\mathcal{S}^1 \\times \\mathcal{S}^1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomstats.geometry.product_manifold import ProductManifold\n",
    "torus = ProductManifold((circumference1,circumference2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading saved points and labels and plotting ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_angles = encoded_points_no_grad #torch.load(\"encoded_angles.pt\")\n",
    "gt_labels = color_array #torch.load(\"labels.pt\")\n",
    "#convert dt_labels into 0 and 1 array\n",
    "gt_labels = (gt_labels - min(gt_labels))/max((gt_labels - min(gt_labels))).to(torch.int)\n",
    "gt_labels = gt_labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting MNIST data on torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_1_coordinates = torus.factors[0].intrinsic_to_extrinsic_coords(encoded_angles[:,0]).reshape(2,-1).T\n",
    "circ_2_coordinates = torus.factors[1].intrinsic_to_extrinsic_coords(encoded_angles[:,1]).reshape(2,-1).T\n",
    "#print(\"1st\", circ_1_coordinates)\n",
    "#print(\"2nd\", circ_2_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data_on_torus_4d = np.concatenate((circ_1_coordinates,circ_2_coordinates),axis = 1).reshape(-1,2,2) # cos\\phi, sin \\phi, cos \\psi, sin \\psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = RiemannianKMeans(torus, k, tol=1e-3)\n",
    "kmeans.fit(MNIST_data_on_torus_4d)\n",
    "kmeans_latent_space_euclidean_labels = kmeans.labels_\n",
    "cluster_centers = kmeans.centroids_# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus.factors[0].extrinsic_to_angle(cluster_centers[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_in_local_chart = Hypersphere(dim=1).extrinsic_to_intrinsic_coords(cluster_centers).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(2,1,figsize=(8, 12))\n",
    "p1 = ax1.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=kmeans_latent_space_euclidean_labels, marker='o', edgecolor='none', cmap=ricci_regularization.discrete_cmap(k, 'jet'))\n",
    "plt.colorbar(p1,ticks=range(k))\n",
    "ax1.title.set_text(\"Latent space colored by K-means on Torus with Euclidean metric\")\n",
    "ax1.grid(True)\n",
    "ax1.scatter(cluster_centers_in_local_chart[:,0],cluster_centers_in_local_chart[:,1],marker = '*',s=150,c =\"orange\")\n",
    "\n",
    "correcltly_detected_labels = abs(kmeans_latent_space_euclidean_labels - gt_labels)\n",
    "if correcltly_detected_labels.sum() < len(gt_labels)//2:\n",
    "    correcltly_detected_labels = np.logical_not(correcltly_detected_labels)\n",
    "\n",
    "p2 = ax2.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=correcltly_detected_labels, marker='o', edgecolor='none', cmap=plt.cm.get_cmap(\"viridis\", k))\n",
    "cbar = plt.colorbar(p2,ticks=[0.25,0.75])\n",
    "cbar.ax.set_yticklabels([\"incorrect\",\"correct\"]) \n",
    "#if violent_saving == True:\n",
    "#    plt.savefig(f\"{Path_pictures}/Kmeans_latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means in input data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_clusters = 100\n",
    "\n",
    "clusters = []\n",
    "for i in range(k):\n",
    "    current_cluster = encoded_points_no_grad[np.where(kmeans_latent_space_euclidean_labels == i)]\n",
    "    current_cluster = current_cluster[:num_points_in_clusters]\n",
    "    clusters.append(current_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "for i in range(k):\n",
    "    plt.scatter(clusters[i][:,0],clusters[i][:,1],c = colors[i%len(colors)],s=30)\n",
    "    plt.scatter(cluster_centers_in_local_chart[i,0],cluster_centers_in_local_chart[i,1],marker = '*',s=250,c =colors[i%len(colors)],edgecolors=\"black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_clusters = []\n",
    "clusters_in_R2 = []\n",
    "for i in range(k):\n",
    "    # move center to (0,0)\n",
    "    shifted_cluster = clusters[i] - cluster_centers_in_local_chart[i]\n",
    "    # fit clusters into (-\\pi,\\pi)\\times (-\\pi,\\pi)\n",
    "    shifted_cluster = torch.remainder(shifted_cluster + torch.pi, 2 * torch.pi) - torch.pi\n",
    "    cluster_in_R2 = shifted_cluster + cluster_centers_in_local_chart[i]\n",
    "    clusters_in_R2.append(cluster_in_R2)\n",
    "    shifted_clusters.append(shifted_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=k,dpi=300,figsize = (6,k*6))\n",
    "axes[0].set_title(\"Clusters with centers shifted to 0\")\n",
    "for i in range(k):\n",
    "    axes[i].scatter(shifted_clusters[i][:,0],shifted_clusters[i][:,1],c = colors[i%len(colors)],label = f\"Points of cluster # {i}\")\n",
    "    axes[i].scatter(clusters_in_R2[i][:,0],clusters_in_R2[i][:,1],c = colors[i%len(colors)],label = f\"Points of cluster # {i} in the universal cover\",edgecolor =\"black\")\n",
    "    axes[i].scatter(cluster_centers_in_local_chart[i,0],cluster_centers_in_local_chart[i,1],marker = '*',s=250,c = \"magenta\", label = f\"Cluster # {i} center.\" )\n",
    "    axes[i].set_xlim(-3/2*torch.pi,3/2*torch.pi)\n",
    "    axes[i].set_ylim(-3/2*torch.pi,3/2*torch.pi)\n",
    "    axes[i].set_xticks(torch.linspace(-3/2*torch.pi,3/2*torch.pi,7))\n",
    "    axes[i].set_yticks(torch.linspace(-3/2*torch.pi,3/2*torch.pi,7))\n",
    "    axes[i].grid()\n",
    "    axes[i].legend(loc=\"lower left\")\n",
    "    #shifted_cluster = clusters[i] + cluster_centers_in_local_chart[i]\n",
    "    #shifted_clusters.append(shifted_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-4.Logarithmic maps and new baricenters in logmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric needs to be shifted!!!\n",
    "# for this we can compute logmaps wrt the periodic metric on the universal cover of the torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochman.manifold import EmbeddedManifold\n",
    "# geodesics are computed minimizing \"energy\" in the embedding of the manifold,\n",
    "# So no need to compute the Pullback metric. and thus the algorithm is fast\n",
    "class Autoencoder(EmbeddedManifold):\n",
    "    def embed(self, c, jacobian = False):\n",
    "        return torus_ae.decoder_torus(c)\n",
    "#selected_labels = json_cofig[\"dataset\"][\"selected_labels\"]\n",
    "model = Autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_logmaps = []\n",
    "# vectorize this!!!\n",
    "for i in range(k):\n",
    "    clusters_logmap = model.logmap(torch.from_numpy(cluster_centers_in_local_chart[i]).repeat(num_points_in_clusters,1),\n",
    "                                         clusters_in_R2[i])\n",
    "    clusters_logmaps.append(clusters_logmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baricenters_logmap = []\n",
    "#vectorize this\n",
    "for i in range(k):\n",
    "    baricenters_logmap.append(torch.mean(clusters_logmaps[i],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=k,dpi=300,figsize = (6,k*6))\n",
    "axes[0].set_title(\"Clusters after log maps with base points at cluster centers\")\n",
    "for i in range(k):\n",
    "    axes[i].scatter(clusters_logmaps[i][:,0],clusters_logmaps[i][:,1],c = colors[i%len(colors)],label = f\"Points of cluster # {i} in the logmaps cover\")\n",
    "    axes[i].scatter(baricenters_logmap[i][0],baricenters_logmap[i][1],marker = '*',s=150,c = \"magenta\", label = f\"New cluster # {i} baricenter:({baricenters_logmap[i][0]:.4f},{baricenters_logmap[i][1]:.4f}).\" )\n",
    "    axes[i].legend(loc=\"lower left\")\n",
    "    #shifted_cluster = clusters[i] + cluster_centers_in_local_chart[i]\n",
    "    #shifted_clusters.append(shifted_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-6.return baricenters via exp map + unshift\n",
    "i.e shoot a geodesic from the base point $p_i$ (old baricenter in the universal cover) and speed which is the new baricenter in logmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geodesic shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geod_vect(x,dxdt):\n",
    "    u = x\n",
    "    v = dxdt\n",
    "    dudt = v\n",
    "    n = v.shape[0]\n",
    "    dvdt = torch.zeros(n,2)\n",
    "    Ch_at_u = ricci_regularization.Ch_jacfwd_vmap(u,function=torus_ae.decoder_torus,device=torch.device(\"cpu\"))\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[:,l] -= Ch_at_u[:,l,i,j] * v[:,i] * v[:,j]\n",
    "    return dudt, dvdt\n",
    "\n",
    "def rungekutta_vect(f, initial_point_array, initial_speed_array, t, args=()):\n",
    "    n = len(t)\n",
    "    #num_geodesics = initial_point_array.shape[0]\n",
    "    x = torch.zeros((n, *tuple(initial_point_array.shape)))\n",
    "    dxdt = torch.zeros((n, *tuple(initial_speed_array.shape)))\n",
    "    x[0] = initial_point_array\n",
    "    dxdt[0] = initial_speed_array\n",
    "    #with torch.no_grad():\n",
    "    #    curve_length = torch.zeros(num_geodesics)\n",
    "    for i in range(n - 1):\n",
    "        dudt, dvdt = f(x[i], dxdt[i], *args)\n",
    "        \n",
    "        #print()\n",
    "        x[i+1] = x[i] + (t[i+1] - t[i])*dudt\n",
    "        dxdt[i+1] = dxdt[i] + (t[i+1] - t[i])*dvdt\n",
    "        \n",
    "        \n",
    "        #dxdt_length = torch.sqrt(((dxdt[i].unsqueeze(-2))@metric@(dxdt[i].unsqueeze(-1))).squeeze())\n",
    "        #curve_length =+ dxdt_length\n",
    "    return x, dxdt\n",
    "    #return x, dxdt,curve_length\n",
    "# x is of shape [num_grid_points,num_geodesics,dimension=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_approximation_points = 101 # how good the approximation is\n",
    "max_parameter_value = 1 #3 # how far to go\n",
    "time_array = torch.linspace(0, max_parameter_value, num_approximation_points)\n",
    "\n",
    "#starting_points = torch.tensor([-2.,0.]).repeat(num_geodesics,1) # common starting point\n",
    "starting_points = torch.from_numpy(cluster_centers_in_local_chart)\n",
    "starting_speeds = torch.cat(baricenters_logmap).reshape(k,2)\n",
    "geodesics2plot,_ = rungekutta_vect(f=geod_vect,initial_point_array=starting_points,\n",
    "                                   initial_speed_array=starting_speeds,t=time_array)\n",
    "geodesics2plot = geodesics2plot.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    plt.plot(geodesics2plot[:,i,0],geodesics2plot[:,i,1],c=\"black\")\n",
    "#plt.colorbar(label=\"scalar curvature along geodesics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.tensor(cluster_centers_in_local_chart)\n",
    "end = geodesics2plot[-1,:]\n",
    "(start-end).norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,success = model.connecting_geodesic(start,end)\n",
    "print(success.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = model.curve_length(c(time_array)).detach()\n",
    "print(f\"Geodesic length of cluster center shifts:\\n{length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
