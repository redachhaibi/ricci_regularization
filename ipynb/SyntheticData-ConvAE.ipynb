{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 784 #dimension\n",
    "k = 3 # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "#n = 10**3 # num of points in each plane"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "phi = [] #list of k ontonormal bases in k planes\n",
    "for j in range(k):\n",
    "    # creating random planes\n",
    "    rand_vectors = torch.rand(D, 2)\n",
    "    q, r = torch.linalg.qr(rand_vectors)\n",
    "    phi.append(q)\n",
    "#phi\n",
    "\n",
    "#creating samples from normal distributions via torch distributions\n",
    "data = []\n",
    "for i in range(k):\n",
    "    #m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2) + 10*i, torch.eye(2))\n",
    "    #m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2) + i, torch.eye(2))\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    samples = m.sample(sample_shape=(n,)).T\n",
    "    #samples = normalize(samples, p = 1, dim = 0)\n",
    "    #data.append(normalize(torch.matmul(phi[i], samples)))\n",
    "    data.append(torch.matmul(phi[i], samples))\n",
    "data_tensor = torch.cat(data, dim=1)\n",
    "\n",
    "data_tensor = data_tensor.T\n",
    "data_tensor = data_tensor.reshape(k*n, 1, 28, 28)\n",
    "\n",
    "labels_list = []\n",
    "for i in range(k):\n",
    "    labels_list.append(i*(torch.ones(n)))\n",
    "labels = torch.cat(labels_list)\n",
    "\n",
    "my_set = TensorDataset(data_tensor,labels)\n",
    "train_dataset = my_set\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, test_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=128\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "# test_data[:][0] will give the vectors of data without labels from the test part of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne check on test set\n",
    "#synthetic_set = data_tensor.reshape(-1,28*28)\n",
    "synthetic_set = test_data[:][0].view(-1,28*28)\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "z = tsne.fit_transform(synthetic_set.numpy())\n",
    "df = pd.DataFrame()\n",
    "#df[\"y\"] = labels.numpy()\n",
    "df[\"y\"] = test_data[:][1].numpy() #test_data[:][1] are labels\n",
    "df[\"comp-1\"] = z[:,0]\n",
    "df[\"comp-2\"] = z[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
    "                palette=sns.color_palette(\"hls\", 10),\n",
    "                data=df).set(title=\"Synthetic dataset data T-SNE projection\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        #self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, hidden_dim, bias=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = torch.sin(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        #out = F.leaky_relu(out)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        #self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(x)\n",
    "        #out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.0001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Autoencoder(hidden_dim=hidden_dim)\n",
    "encoder = Encoder(input_dim=784, hidden_dim=d)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=784)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.RMSprop(params_to_optimize, lr=lr, weight_decay=1e-03)\n",
    "\n",
    "# Check if the GPU is available\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(encoder, mydata):\n",
    "    import plotly.express as px\n",
    "    s = encoder(mydata[:][0].view(-1,1,28*28)).detach().numpy()\n",
    "    s = s.reshape(-1, 2)\n",
    "    l = mydata[:][1].numpy().reshape(-1,1)\n",
    "    s = np.concatenate((s,l),axis=1)\n",
    "    myplot = px.scatter(s, x = s[:,0], y = s[:,1], color=s[:,2].astype(str), opacity=0.5)\n",
    "    return myplot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(encoder, decoder, device, dataloader, loss_fn, optimizer, num_batches, batches_per_plot):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    mse_loss = []\n",
    "    batch_idx = 0\n",
    "    while (batch_idx < num_batches):\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "        for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "            #shaping the images properly\n",
    "            image_batch = image_batch.view(-1,28*28)\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Evaluate loss\n",
    "\n",
    "            loss = loss_fn(decoded_data, image_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Print batch loss\n",
    "            #print('\\t batch number: %f \\t partial train loss (single batch): %f' %(batch_idx) % (loss.data))\n",
    "            print('\\t batch number: {:} \\t partial train loss (single batch): {:.6}' .format(batch_idx, loss.data))\n",
    "            #print(batch_idx)\n",
    "\n",
    "            if (batch_idx % batches_per_plot == 0) & (batch_idx > 0):\n",
    "                plot = point_plot(encoder, test_data)\n",
    "                plot.show()\n",
    "\n",
    "        \n",
    "            mse_loss.append(float(loss.detach().cpu().numpy()))\n",
    "            batch_idx += 1\n",
    "            if batch_idx > num_batches:\n",
    "                break\n",
    "\n",
    "    return mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 300\n",
    "batches_per_plot = 50\n",
    "mse_loss = train_batch(encoder, decoder, device, train_loader, loss_fn, optim, num_batches,batches_per_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(mse_loss, label='Train_loss')\n",
    "#plt.semilogy(diz_loss['train_loss'], label='Train_loss')\n",
    "#plt.semilogy(diz_loss['train_loss'] - diz_loss['mse_loss'], label='Curv_loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "#plt.title('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = []\n",
    "for sample in tqdm(train_dataset):\n",
    "#for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        img = img.view(-1,28*28) # reshape the img\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples.label.astype(str), opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
