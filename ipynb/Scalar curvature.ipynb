{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "batch_size=256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            #nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "d = 2\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "\n",
    "# Check if the GPU is available\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Force CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "#without curvature in Loss func\n",
    "PATH_enc = '../nn_weights/encoder_conv_autoenc.pt'\n",
    "PATH_dec = '../nn_weights/decoder_conv_autoenc.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_convAE_curv_0.1.pt'\n",
    "#PATH_dec = 'decoder_convAE_curv_0.1.pt'\n",
    "\n",
    "#with curvature in Loss func\n",
    "#PATH_enc = 'encoder_curw_w=0.001_2epoch.pt'\n",
    "#PATH_dec = 'decoder_curw_w=0.001_2epoch.pt'\n",
    "\n",
    "encoder.load_state_dict(torch.load(PATH_enc))\n",
    "encoder.eval()\n",
    "decoder.load_state_dict(torch.load(PATH_dec))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from latnt code and calculate mean and std\n",
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # calculate mean and std of latent code, generated takining in test images as inputs \n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    latent = encoder(images)\n",
    "    latent = latent.cpu()\n",
    "\n",
    "    mean = latent.mean(dim=0)\n",
    "    print(mean)\n",
    "    std = (latent - mean).pow(2).mean(dim=0).sqrt()\n",
    "    print(std)\n",
    "\n",
    "    # sample latent vectors from the normal distribution\n",
    "    latent = torch.randn(128, d)*std + mean\n",
    "    #print(latent)\n",
    "    #print(latent.shape)\n",
    "\n",
    "    # reconstruct images from the random latent vectors\n",
    "    latent = latent.to(device)\n",
    "    img_recon = decoder(latent)\n",
    "    img_recon = img_recon.cpu()\n",
    "\n",
    "    #fig, ax = plt.subplots(figsize=(20, 8.5))\n",
    "    #show_image(torchvision.utils.make_grid(img_recon[:100],10,5))\n",
    "    #plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fa63741",
   "metadata": {},
   "source": [
    "Point plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d032b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf81ed4",
   "metadata": {},
   "source": [
    "Manifold plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c59ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "numsteps = 10\n",
    "xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)\n",
    "ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)\n",
    "uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "# True Manifold plot\n",
    "truegrid = torch.cartesian_prod(ys,- xs)\n",
    "latent = - truegrid.roll(1,1)\n",
    "latent = latent.to(device)\n",
    "img_recon = decoder(latent)\n",
    "img_recon = img_recon.cpu()\n",
    "\n",
    "fig, ax  = plt.subplots(figsize=(20, 8.5))\n",
    "img_grid = torchvision.utils.make_grid(img_recon[:100],10,5)\n",
    "show_image(img_grid.detach())\n",
    "plt.show()\n",
    "print(latent.shape)\n",
    "print(img_recon.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d57b3499",
   "metadata": {},
   "source": [
    "# Fast way to compute metric on a grid over the latent space (torch.roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a863873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. The bounds for the grid can be taken from 3 sigma rule. \n",
    "#We will take 2 sigmas however\n",
    "numsteps = 100\n",
    "zoom = 1\n",
    "\n",
    "# Centralized and scaled evaluation \n",
    "xs = torch.linspace(mean[0]-2*std[0], mean[0]+2*std[0], steps = numsteps)/zoom\n",
    "ys = torch.linspace(mean[1]-2*std[1], mean[1]+2*std[1], steps = numsteps)/zoom\n",
    "\n",
    "#fixed location of latent space evaluation\n",
    "#xs = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "#ys = torch.linspace(-1.5, 1.5, steps = numsteps)/zoom\n",
    "\n",
    "#uniform_grid = torch.cartesian_prod(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357de2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alt grid\n",
    "#numsteps = 10\n",
    "\n",
    "#xs = torch.linspace(1.2-0.3, 1.2+0.3, steps = numsteps)\n",
    "#ys = torch.linspace(0.6-0.3, 0.6+0.3, steps = numsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2867e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true grid starts from left bottom corner. x is the first to increase\n",
    "tgrid = torch.cartesian_prod(ys, xs)\n",
    "tgrid = tgrid.roll(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric on a grid\n",
    "def g(grid):\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    psi = decoder(latent)\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    \n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*hx)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*hy)\n",
    "    \n",
    "    metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    metric = metric.view(4, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperbolic metric and its derivatives on a grid\n",
    "R = 10\n",
    "def specific_metric (u): \n",
    "    # u is the vector of points\n",
    "    #R = 5 #Radius\n",
    "    phi = u[:,0]\n",
    "    theta = u[:, 1]\n",
    "    n = u.shape[0] #number of points\n",
    "    g = torch.zeros((n,2,2))\n",
    "\n",
    "    #Sphere\n",
    "    g11 = torch.cos(theta)**2\n",
    "    g12 = torch.zeros(n)\n",
    "    g21 = torch.zeros(n)\n",
    "    g22 = torch.ones(n)\n",
    "\n",
    "    #hyperbolic metric on a half plane\n",
    "    #g11 = 1/theta**2\n",
    "    #g12 = torch.zeros(n)\n",
    "    #g21 = torch.zeros(n)\n",
    "    #g22 = 1/theta**2\n",
    "\n",
    "    g = torch.cat((g11, g12, g21, g22)).view(4,n)\n",
    "    g = g.T\n",
    "    g = g.view(n, 2, 2)\n",
    "    g = (R**2)*g\n",
    "    #g = (R**2)*torch.tensor([[torch.cos(theta)**2, 0],[0, 1]])\n",
    "    return g\n",
    "def specific_metric_der (u): \n",
    "    #phi, theta = u\n",
    "    #think of x = phi, y = theta\n",
    "    # u is the vector of points\n",
    "    #R = 5 #Radius\n",
    "    phi = u[:,0]\n",
    "    theta = u[:, 1]\n",
    "    n = u.shape[0] #number of points\n",
    "    g = torch.zeros((n,2,2,2))\n",
    "    \n",
    "    #x derivatives of g\n",
    " \n",
    "    gx11 = torch.zeros(n)\n",
    "    gx12 = torch.zeros(n)\n",
    "    gx21 = torch.zeros(n)\n",
    "    gx22 = torch.zeros(n)\n",
    "\n",
    "    gx = torch.cat((gx11, gx12, gx21, gx22)).view(4,n)\n",
    "    gx = gx.T\n",
    "    gx = gx.view(n, 2, 2)\n",
    "    \n",
    "    #y derivatives of g\n",
    "\n",
    "    #sphere\n",
    "    gy11 = -R**2*torch.sin(2*theta)\n",
    "    gy12 = torch.zeros(n)\n",
    "    gy21 = torch.zeros(n)\n",
    "    gy22 = torch.zeros(n)\n",
    "\n",
    "\n",
    "\n",
    "    #hyperbolic metric\n",
    "    #gy11 = -2/theta**3\n",
    "    #gy12 = torch.zeros(n)\n",
    "    #gy21 = torch.zeros(n)\n",
    "    #gy22 = -2/theta**3\n",
    "    \n",
    "    gy = torch.cat((gy11, gy12, gy21, gy22)).view(4,n)\n",
    "    gy = gy.T\n",
    "    gy = gy.view(n, 2, 2)\n",
    "\n",
    "    dg = torch.cat((gx,gy),1).view(n,2,2,2)\n",
    "    #g = np.array([[[0, 0],\n",
    "    #               [0, 0]],\n",
    "    #              [[-R**2*np.sin(2*theta), 0],\n",
    "    #               [0, 0]]])\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the grid of metric\n",
    "with torch.no_grad():\n",
    "    metric = g(tgrid)\n",
    "    #metric = specific_metric(tgrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084965d9",
   "metadata": {},
   "source": [
    "## Heatmap of frobenius norm of metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast computation of Frobenious norm on the grid without borders\n",
    "Newfrob = metric.norm(dim=(1,2)).view(numsteps,numsteps)\n",
    "Newfrob = Newfrob[1:-1,1:-1].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map of the frobenius norm\n",
    "h = plt.contourf(xs[1:-1], ys[1:-1], Newfrob)\n",
    "plt.title('Heatmap of the Frobenius norm of the metric')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "plt.colorbar(label=\"Frobenius norm of the metric\")\n",
    "#plt.xlim(-1.5 + mean[0], 1.5 + mean[0])\n",
    "#plt.ylim(-1.5 + mean[1], 1.5 + mean[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80195e2b",
   "metadata": {},
   "source": [
    "### Derivatives of the metric and Christoffel symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simultaneous differentiation on a grid with torch.roll\n",
    "def diff_by_x(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_x =  psi.roll(-1,0)\n",
    "    psi_prev_x =  psi.roll(1,0)\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2*h)\n",
    "    return dpsidx\n",
    "def diff_by_y(tensor, numsteps, h):\n",
    "    psi = tensor\n",
    "    psi_next_y =  psi.roll(-numsteps,0)\n",
    "    psi_prev_y =  psi.roll(numsteps,0)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479da6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of the metric on a grid\n",
    "def dg_grid (grid): #dg\n",
    "    \n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    \n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "    latent = grid\n",
    "    latent = latent.to(device)\n",
    "    psi = decoder(latent)\n",
    "    \n",
    "    dpsidx = diff_by_x(psi, numsteps, hx)\n",
    "    dpsidy = diff_by_x(psi, numsteps, hy)\n",
    "    dpsidx_second = diff_by_x(dpsidx, numsteps, hx)\n",
    "    dpsidx_dy = diff_by_y(dpsidx, numsteps, hy)\n",
    "    dpsidy_second = diff_by_y(dpsidy, numsteps, hy)\n",
    "    \n",
    "    #metric = torch.cat(((dpsidx*dpsidx).sum((1,2,3)),(dpsidx*dpsidy).sum((1,2,3)),\n",
    "    #                  (dpsidx*dpsidy).sum((1,2,3)),(dpsidy*dpsidy).sum((1,2,3))),0)\n",
    "    \n",
    "    dgdx = torch.cat((2*(dpsidx*dpsidx_second).sum((1,2,3)),(dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidx_second * dpsidy + dpsidx * dpsidx_dy).sum((1,2,3)),2*(dpsidy * dpsidx_dy).sum((1,2,3))),0)\n",
    "    dgdy = torch.cat((2*(dpsidx*dpsidx_dy).sum((1,2,3)),(dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),\n",
    "                      (dpsidy_second * dpsidx + dpsidy * dpsidx_dy).sum((1,2,3)),2*(dpsidy*dpsidy_second).sum((1,2,3))),0)\n",
    "    metric_der = torch.cat((dgdx, dgdy), 0)\n",
    "    metric = metric_der\n",
    "    metric = metric.view(8, numsteps*numsteps)\n",
    "    metric = metric.transpose(0, 1)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 4)\n",
    "    metric = metric.view(numsteps*numsteps, 2, 2, 2)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the grid of metric derivatives\n",
    "with torch.no_grad():\n",
    "    metric_der = dg_grid(tgrid)\n",
    "    #metric_der = specific_metric_der(tgrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means that we can simultanuousely invert all the matrices over the grid\n",
    "torch.equal(torch.inverse(metric[0]),torch.inverse(metric)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the inverse of the metric on a grid\n",
    "metric_inv = torch.inverse(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56675209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols on a grid\n",
    "def Ch_grid(grid):\n",
    "    #x = grid[:,0]\n",
    "    #y = grid[:, 1]\n",
    "    n = grid.shape[0]\n",
    "    Ch = torch.zeros((n, 2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    #Ch^l_ij\n",
    "                    Ch[:,l,i,j] += 0.5 * metric_inv[:,l,k] * (metric_der[:,i,k,j] + metric_der[:,j,i,k] - metric_der[:,k,i,j]) \n",
    "                    \n",
    "                    #Ch[l,i,j] += 0.5 * g_inv(grid)[l,k] * (dg(grid)[i,k,j] + dg(grid)[j,i,k] - dg(grid)[k,i,j]) #Ch^l_ij\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking Christoffel on a grid\n",
    "Ch_grid(tgrid).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65645bf0",
   "metadata": {},
   "source": [
    "Derivatives of Christoffel symbols on a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e49507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derivatives of Christoffel symbols on a grid\n",
    "def Ch_der_grid(grid):\n",
    "    n = grid.shape[0]\n",
    "\n",
    "    numsteps = int(np.sqrt(grid.shape[0]))\n",
    "    hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "    hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "    \n",
    "    Chdx = diff_by_x(Ch_grid(grid), numsteps, hx)\n",
    "    Chdy = diff_by_y(Ch_grid(grid), numsteps, hy)\n",
    "    Chder = torch.cat((Chdx, Chdy), -1)\n",
    "    Chder = Chder.view(n,2,2,2,2)\n",
    "    Chder = Chder.transpose(-1,-2)\n",
    "    return Chder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2545e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_der_grid(tgrid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem(grid):\n",
    "    n = grid.shape[0]\n",
    "\n",
    "    Riem = torch.zeros(n, 2, 2, 2, 2)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(2):\n",
    "                for l in range(2):                    \n",
    "                    Riem[:, i, j, k, l] = Ch_der_grid(grid)[:, i, l, j, k] - Ch_der_grid(grid)[:, i, k, j, l] \n",
    "                    for p in range(2):\n",
    "                        Riem[:, i, j, k, l] += (Ch_grid(grid)[:, i, k, p]*Ch_grid(grid)[:, p, l, j] - Ch_grid(grid)[:, i, l, p]*Ch_grid(grid)[:, p, k, j])\n",
    "    return Riem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb360de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Riem(tgrid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a27b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scew symmetry check\n",
    "torch.equal(Riem(tgrid)[:,0,0,0,1], - Riem(tgrid)[:,0,0,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ricci curvature tensor via Riemann\n",
    "# R_ab = Riem^c_acb\n",
    "def Ric(grid):\n",
    "    n = grid.shape[0]\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riem(grid)[:, c, a, c, b]\n",
    "    return Ric\n",
    "    # takes 2.5 secs on 100 by 100 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a929a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ric(tgrid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar curvature tensor via Riemann and Ricci\n",
    "# R_ab = Riem^c_acb\n",
    "# R = g^ij * R_ij\n",
    "def Sc(grid):\n",
    "    n = grid.shape[0]\n",
    "    Sc = torch.zeros(n)\n",
    "    Ric = torch.zeros(n, 2, 2)\n",
    "    for a in range(2):\n",
    "        for b in range(2):\n",
    "            for c in range(2):\n",
    "                Ric[:, a, b] += Riem(grid)[:, c, a, c, b]\n",
    "    Sc = metric_inv*Ric\n",
    "    Sc = torch.sum(Sc,(1,2))\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar_curvature_grid = Sc(tgrid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c074afa5",
   "metadata": {},
   "source": [
    "# Scalar curvature heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast computation of Frobenious norm on the grid without borders\n",
    "Scalar_curv = Scalar_curvature_grid.view(numsteps,numsteps)\n",
    "#Scalar_curv_check = Scalar_curv[30:-30,30:-30].transpose(0,1)\n",
    "Scalar_curv = Scalar_curv[2:-2,2:-2].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heat map of the Scalar curvature\n",
    "h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "#h = plt.contourf(xs[30:-30], ys[30:-30], Scalar_curv_check)\n",
    "plt.title('Heat map of the Scalar curvature ')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "#plt.xlim(-1.5,1.5)\n",
    "#plt.ylim(-1.5,1.5)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "def372d2",
   "metadata": {},
   "source": [
    "Simplified energy functional computation: $F_{new}(g) = \\int_{M}  R^{2} d\\mu$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ef7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_no_border = metric.reshape(numsteps, numsteps,2,2)[2:-2,2:-2]\n",
    "det_metric_no_border = torch.det(metric_no_border)\n",
    "det_sqrt = torch.sqrt(det_metric_no_border)\n",
    "grid = tgrid\n",
    "hx = float(abs((grid[numsteps**2 - 1] - grid[0])[0]))/(numsteps - 1)\n",
    "hy = float(abs((grid[numsteps**2 - 1] - grid[0])[1]))/(numsteps - 1)\n",
    "\n",
    "F_new = (det_sqrt*torch.square(Scalar_curv)*hx*hy).sum()\n",
    "\n",
    "print(F_new)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5808c9e7",
   "metadata": {},
   "source": [
    "# Geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used for making a piecewise constant metric from its evaluation on a grid\n",
    "def find_nearest_index (grid, u):\n",
    "    index = int(torch.min(abs(grid - u),0).indices.sum())\n",
    "    #index = int((((u - tgrid[0])*numsteps/size).floor()*torch.tensor([1.,numsteps])).sum()) #thisd could be faster\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y = [u , v]\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    u = y[0:2:]\n",
    "    v = y[2::]\n",
    "    dudt = v\n",
    "    #dvdt = torch.zeros(2)\n",
    "    dvdt = np.zeros(2)\n",
    "    u = torch.from_numpy(u)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[l] -= (Ch(u)[l,i,j]).numpy() * v[i] * v[j]\n",
    "    dydt = np.concatenate((dudt, dvdt))\n",
    "    #dydt = torch.cat((dudt, dvdt),0)\n",
    "    return dydt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be23691a",
   "metadata": {},
   "source": [
    "## Vectorized computation of geodesics (with a loop in find_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could be done faster\n",
    "def find_nearest_indices (grid, u):\n",
    "    #this could be done more efficiently\n",
    "    n = u.shape[0]\n",
    "    indices = torch.zeros(n)\n",
    "    for i in range(n):\n",
    "        indices[i] = find_nearest_index(grid, u[i])\n",
    "    indices = indices.to(torch.int64) # just some magic to make it work\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_nearest_index(tgrid, torch.tensor([0.5,0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a0006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgrid[5563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ecddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce73044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant inverse of g\n",
    "def g_inv_vect (grid, u): #inverse metric\n",
    "    #index = find_nearest_index(tgrid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    #A = metric[index]\n",
    "    A = torch.index_select(metric, 0, indices)\n",
    "    g_inv = torch.inverse(A)\n",
    "    return g_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869be7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_inv_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a52dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of the piecewise constant derivatives of g\n",
    "def dg_vect (grid, u): #dg\n",
    "    #index = find_nearest_index(uniform_grid, u)\n",
    "    indices = find_nearest_indices(grid, u)\n",
    "    g = torch.index_select(metric_der, 0, indices)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6348ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dg_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8850891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Christoffel symbols at a vector of n points. u has shape (n, x, y)\n",
    "def Ch_vect(grid, u):\n",
    "    n = u.shape[0]\n",
    "    Ch = torch.zeros((n,2,2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for l in range(2):\n",
    "                for k in range(2):\n",
    "                    Ch[:,l,i,j] += 0.5 * g_inv_vect(grid, u)[:,l,k] * (dg_vect(grid, u)[:,i,k,j] + dg_vect(grid, u)[:,j,i,k] - dg_vect(grid, u)[:,k,i,j]) #Ch^l_ij\n",
    "    return Ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch_vect(tgrid, check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ch(check[1])\n",
    "# just to check there is no mistake in vectorized vertion Ch_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ch_vect still exploits the loop in find_indices\n",
    "#Ch_vect(tgrid,tgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b88601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing geodesics...\n",
    "# y has shape num of points, u, v\n",
    "# v := dot(u)\n",
    "# dot(v)^l = Ch^l_ij * v^i * v^j\n",
    "def geod(y, t):\n",
    "    #u, v = y\n",
    "    n = y.shape[0]\n",
    "    u = y[: , 0:2:]\n",
    "    v = y[: , 2::]\n",
    "    dudt = v\n",
    "    dvdt = torch.zeros(n, 2)\n",
    "    for l in range(2):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                dvdt[:, l] -= Ch_vect(tgrid, u)[:, l,i,j] * v[:, i] * v[:, j] #here we use Ch_vect instead od Ch\n",
    "    dydt = torch.cat((dudt.T, dvdt.T)).T\n",
    "    # dydt = np.concatenate((dudt, dvdt))\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ef082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rungekutta_new(f, y0, t, args=()):\n",
    "    nt = len(t) # number of steps in time\n",
    "    # len(y0[0]) is the number of initial conditions\n",
    "    # len(y0[1]) is the dimention of the state space. In our case it is 4 \n",
    "    y = torch.zeros((nt, y0.shape[0],y0.shape[1]))\n",
    "    y[0,:,:] = y0\n",
    "    for i in range(nt - 1):\n",
    "        y[i+1,:,:] = y[i,:,:] + (t[i+1] - t[i])*f(y[i,:,:], t[i], *args)\n",
    "        print(y[i,:,:])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at random points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 10\n",
    "v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = v.repeat(m,1)\n",
    "u = torch.rand(m,1)\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed = torch.cat((u,v),1)\n",
    "RandStartComSpeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 21)\n",
    "sol3 = rungekutta_new(geod, RandStartComSpeed, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec679b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sol3[:15, :, 0], sol3[:15, :, 1]) #geodesics are shortened by step 15 because of border effects\n",
    "plt.title( \"Plots of geodesics with rnd ititial point and common initial speed\")\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79da24e3",
   "metadata": {},
   "source": [
    "# Scalar curvature and geodesics on one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start at different initial points u with the same speed v\n",
    "# we want to draw m geodesics\n",
    "m = 15 #number of geodesics\n",
    "#v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = torch.tensor([0.00, 0.00,1.00])\n",
    "v = v.repeat(m,1)\n",
    "#u = torch.rand(m,1)\n",
    "#u = torch.linspace(0.01,1.51,steps=m).reshape(15,1)\n",
    "u = torch.linspace(0.01,1.51,steps=m).reshape(15,1)\n",
    "#unorm = u.norm(dim=1)\n",
    "#u = (u.T/unorm).T\n",
    "\n",
    "RandStartComSpeed2 = torch.cat((u,v),1)\n",
    "RandStartComSpeed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7652a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 1, steps = 41)\n",
    "sol4 = rungekutta_new(geod, RandStartComSpeed2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96669dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalar curvature and geodesics\n",
    "h = plt.contourf(xs[2:-2], ys[2:-2], Scalar_curv)\n",
    "plt.plot(sol4[:30, :, 0], sol4[:30, :, 1]) #geodesics are shortened by step 30 because of border effects\n",
    "plt.title('Scalar curvature and geodesics')\n",
    "plt.xlabel( \"x coordinate\")\n",
    "plt.ylabel( \"y coordinate\")\n",
    "plt.axis('scaled')\n",
    "plt.xlim(0,1.75)\n",
    "plt.ylim(0,1.25)\n",
    "plt.colorbar(label=\"Scalar curvature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scalar_curvature_grid[5563]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
