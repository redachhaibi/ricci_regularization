{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook builds a report for pretrained torus AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json file name\n",
    "#experiment_json = f'../experiments/Swissroll_torus_AEexp91.json'\n",
    "experiment_json = f'../experiments/MNIST01_torus_AEexp8.json'\n",
    "\n",
    "violent_saving = True # if False it will not save plots\n",
    "build_report = True\n",
    "\n",
    "# Loading JSON file\n",
    "import json\n",
    "with open(experiment_json) as json_file:\n",
    "    json_config = json.load(json_file)\n",
    "\n",
    "print( json.dumps(json_config, indent=2 ) )\n",
    "\n",
    "Path_experiments = json_config[\"Path_experiments\"]\n",
    "experiment_name = json_config[\"experiment_name\"]\n",
    "experiment_number = json_config[\"experiment_number\"]\n",
    "Path_pictures = json_config[\"Path_pictures\"]\n",
    "\n",
    "# # Number of workers in DataLoader\n",
    "# num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMP ONLY REPORTING PARTS\n",
    "import pdfkit\n",
    "\n",
    "keys2print = ['experiment_name','experiment_number','dataset',\n",
    " 'architecture', 'optimization_parameters', 'losses', 'OOD_parameters', 'training_results_on_test_data']\n",
    "json_config2print = {key : json_config[key] for key in keys2print}\n",
    "print(json_config2print)\n",
    "with open(f'{Path_experiments}/dummy_config.json', 'w') as json_file:\n",
    "    json.dump(json_config2print, json_file, indent=4)\n",
    "\n",
    "#pdfkit.from_string(json.dumps(json_config2print),output_path=f\"{Path_pictures}/hyperparameters_exp{experiment_number}.pdf\")\n",
    "pdfkit.from_file(f'{Path_experiments}/dummy_config.json',output_path=f\"{Path_pictures}/hyperparameters_exp{experiment_number}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name    = json_config[\"dataset\"][\"name\"]\n",
    "split_ratio = json_config[\"optimization_parameters\"][\"split_ratio\"]\n",
    "batch_size  = json_config[\"optimization_parameters\"][\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_name == \"MNIST\":\n",
    "    #MNIST_SIZE = 28\n",
    "    # MNIST Dataset\n",
    "    D = 784\n",
    "    train_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "elif set_name == \"MNIST01\":\n",
    "    D = 784\n",
    "    full_mnist_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "    \n",
    "    mask = (full_mnist_dataset.targets == -1) \n",
    "    selected_labels = json_config[\"dataset\"][\"selected_labels\"]\n",
    "    for label in selected_labels:\n",
    "        mask = mask | (full_mnist_dataset.targets == label)\n",
    "    indices01 = torch.where(mask)[0]\n",
    "    \n",
    "    from torch.utils.data import Subset\n",
    "    train_dataset = Subset(full_mnist_dataset, indices01) # MNIST only with 0,1 indices\n",
    "\n",
    "elif set_name == \"Synthetic\":\n",
    "    k = json_config[\"dataset\"][\"parameters\"][\"k\"]\n",
    "    n = json_config[\"dataset\"][\"parameters\"][\"n\"]\n",
    "    d = json_config[\"architecture\"][\"latent_dim\"]\n",
    "    D = json_config[\"architecture\"][\"input_dim\"]\n",
    "    shift_class = json_config[\"dataset\"][\"parameters\"][\"shift_class\"]\n",
    "    intercl_var = json_config[\"dataset\"][\"parameters\"][\"intercl_var\"]\n",
    "    var_class = json_config[\"dataset\"][\"parameters\"][\"var_class\"]\n",
    "    # Generate dataset\n",
    "    # via classes\n",
    "    torch.manual_seed(0) # reproducibility\n",
    "    my_dataset = ricci_regularization.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                        shift_class=shift_class, intercl_var=intercl_var, var_class=var_class)\n",
    "\n",
    "    train_dataset = my_dataset.create\n",
    "elif set_name == \"Swissroll\":\n",
    "    sr_noise = json_config[\"dataset\"][\"parameters\"][\"sr_noise\"]\n",
    "    sr_numpoints = json_config[\"dataset\"][\"parameters\"][\"sr_numpoints\"]\n",
    "\n",
    "    D = 3\n",
    "    train_dataset =  sklearn.datasets.make_swiss_roll(n_samples=sr_numpoints, noise=sr_noise)\n",
    "    sr_points = torch.from_numpy(train_dataset[0]).to(torch.float32)\n",
    "    #sr_points = torch.cat((sr_points,torch.zeros(sr_numpoints,D-3)),dim=1)\n",
    "    sr_colors = torch.from_numpy(train_dataset[1]).to(torch.float32)\n",
    "    from torch.utils.data import TensorDataset\n",
    "    train_dataset = TensorDataset(sr_points,sr_colors)\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [m-int(m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = json_config[\"architecture\"][\"latent_dim\"]\n",
    "input_dim  = json_config[\"architecture\"][\"input_dim\"]\n",
    "architecture_type = json_config[\"architecture\"][\"name\"]\n",
    "\n",
    "if architecture_type== \"TorusAE\":\n",
    "    torus_ae   = ricci_regularization.Architectures.TorusAE(x_dim=input_dim, h_dim1= 512, h_dim2=256, z_dim=latent_dim)\n",
    "elif architecture_type ==\"TorusConvAE\":\n",
    "    torus_ae   = ricci_regularization.Architectures.TorusConvAE(x_dim=input_dim, h_dim1= 512, h_dim2=256, z_dim=latent_dim,pixels=28)\n",
    "if torch.cuda.is_available():\n",
    "    torus_ae.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO! Use the path ../experiments/<Your experiment>/nn_weights/\n",
    "PATH_ae_wights = json_config[\"weights_saved_at\"]\n",
    "torus_ae.load_state_dict(torch.load(PATH_ae_wights))\n",
    "torus_ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#inspiration for torus_ae.encoder2lifting\n",
    "def circle2anglevectorized(zLatentTensor,Z_DIM = Z_DIM):\n",
    "    cosphi = zLatentTensor[:, 0:Z_DIM]\n",
    "    sinphi = zLatentTensor[:, Z_DIM:2*Z_DIM]\n",
    "    phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "    return phi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "N = json_config[\"dataset\"][\"parameters\"][\"k\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( test_loader, position=0 ):\n",
    "#for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()\n",
    "#assert torch.equal(enc,enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "if set_name == \"Swissroll\":\n",
    "    plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap= 'jet')\n",
    "else:\n",
    "    plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "    plt.colorbar(ticks=range(N))\n",
    "plt.grid(True)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f\"{Path_pictures}/latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error_tensor = input_dataset.view(-1,D) - recon_dataset\n",
    "mse_array = abs_error_tensor.norm(dim=1).detach()\n",
    "mse_array = mse_array**2/D\n",
    "#F.mse_loss(input_dataset.view(-1,D)[0],recon_dataset[0],reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric losses computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvature_array = ricci_regularization.Sc_jacfwd_vmap(encoded_points,device = torch.device(\"cpu\"),function=torus_ae.decoder_torus).detach()\n",
    "metric_array = ricci_regularization.metric_jacfwd_vmap(encoded_points,function=torus_ae.decoder_torus).detach()\n",
    "det_array = torch.det(metric_array)\n",
    "trace_array = torch.einsum('jii->j',metric_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent \\in [-\\pi,\\pi]. grid parameteres for evaluation.\n",
    "latent = encoded_points_no_grad\n",
    "left = latent[:,0].min()\n",
    "right = latent[:,0].max()\n",
    "bottom = latent[:,1].min()\n",
    "top = latent[:,1].max()\n",
    "\n",
    "xsize = right - left\n",
    "ysize = top - bottom\n",
    "xcenter = 0.5*(left + right)\n",
    "ycenter = 0.5*(bottom + top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsize = 200 #200\n",
    "\n",
    "import torch.func as TF\n",
    "grid_on_ls = ricci_regularization.make_grid(linsize,xsize=xsize,ysize=ysize,xcenter=xcenter,ycenter=ycenter)\n",
    "\n",
    "grid_numpoints = grid_on_ls.shape[0]\n",
    "bs = 4000\n",
    "metric_det_list = []\n",
    "metric_trace_list = []\n",
    "curv_list = []\n",
    "for i in range(grid_numpoints//bs):\n",
    "    batch_of_grid = grid_on_ls[i*bs:(i+1)*bs]\n",
    "    metric_on_batch_of_grid = ricci_regularization.metric_jacfwd_vmap(batch_of_grid,function=torus_ae.decoder_torus)\n",
    "    metric_det_on_batch_of_grid = torch.det(metric_on_batch_of_grid)\n",
    "    metric_trace_on_batch_of_grid = TF.vmap(torch.trace)(metric_on_batch_of_grid)\n",
    "    curv_on_batch_of_grid = ricci_regularization.Sc_jacfwd_vmap(batch_of_grid,device = torch.device(\"cpu\"), function = torus_ae.decoder_torus)\n",
    "    metric_det_list.append(metric_det_on_batch_of_grid.tolist())\n",
    "    metric_trace_list.append(metric_trace_on_batch_of_grid.tolist())\n",
    "    curv_list.append(curv_on_batch_of_grid.tolist())\n",
    "metric_det_on_grid = np.concatenate(metric_det_list)\n",
    "metric_trace_on_grid = np.concatenate(metric_trace_list)\n",
    "curv_on_the_grid = np.concatenate(curv_list)\n",
    "\"\"\"\n",
    "metric_on_grid = ricci_regularization.metric_jacfwd_vmap(grid_on_ls,function=torus_ae.decoder_torus)\n",
    "metric_det_on_grid = torch.det(metric_on_grid)\n",
    "metric_trace_on_grid = TF.vmap(torch.trace)(metric_on_grid)\n",
    "curv_on_the_grid = ricci_regularization.Sc_jacfwd_vmap(grid_on_ls,device = torch.device(\"cpu\"), function = torus_ae.decoder_torus)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent \\in [-1,1]. grid reparametrization for plotting\n",
    "encoded_points_no_grad = encoded_points_no_grad/math.pi\n",
    "latent = encoded_points_no_grad\n",
    "left = latent[:,0].min()\n",
    "right = latent[:,0].max()\n",
    "bottom = latent[:,1].min()\n",
    "top = latent[:,1].max()\n",
    "\n",
    "xsize = right - left\n",
    "ysize = top - bottom\n",
    "xcenter = 0.5*(left + right)\n",
    "ycenter = 0.5*(bottom + top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recon loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_dataset[t_idx[i]][0].unsqueeze(0)\n",
    "      #encoder.eval()\n",
    "      #decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         #rec_img  = decoder(encoder(img))\n",
    "         rec_img  = decoder(encoder(img.reshape(1,D))).reshape(1,28,28)\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_name == \"MNIST\":\n",
    "    plot_ae_outputs(torus_ae.encoder2lifting,torus_ae.decoder_torus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import ticker\n",
    "\n",
    "# (generate plot here)\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "size_of_points = 20\n",
    "fig, (ax00,ax0)= plt.subplots(ncols=2, nrows=1,figsize=(15,6),dpi=300)\n",
    "# (ax3,ax4) can  be added\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax00.title.set_text(\"AE latent space\")\n",
    "if set_name == \"Synthetic\" or set_name == \"MNIST\":\n",
    "    p00 = ax00.scatter( encoded_points_no_grad[:,0], encoded_points_no_grad[:,1], c=color_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap=discrete_cmap(N, \"jet\"))\n",
    "    fig.colorbar(p00,label=\"initial color\", ticks=(np.arange(N)))    \n",
    "else:\n",
    "    p00 = ax00.scatter( encoded_points_no_grad[:,0], encoded_points_no_grad[:,1], c=color_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet')\n",
    "    fig.colorbar(p00,label=\"initial color\")\n",
    "ax00.grid(True)\n",
    "ax0.title.set_text(\"Reconstruction loss\")\n",
    "p0 = ax0.scatter( encoded_points_no_grad[:,0], encoded_points_no_grad[:,1], c=mse_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet',norm=matplotlib.colors.LogNorm())\n",
    "ax0.grid(True)\n",
    "cb = fig.colorbar(p0,label=\"squared l2 norm errors\")\n",
    "#tick_locator = ticker.MaxNLocator(nbins=10)\n",
    "#cb.locator = tick_locator\n",
    "#cb.update_ticks()\n",
    "\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/init_colors_recon_loss.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curvature_array, bins = math.ceil(math.sqrt(curvature_array.shape[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curv_on_the_grid, bins = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantile((curvature_array**2*torch.sqrt(det_array)),.999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curvature_array**2*torch.sqrt(det_array).detach(),bins=math.ceil(math.sqrt(curvature_array.shape[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xcenter = 0.0 \n",
    "#ycenter = 0.0\n",
    "xshift = 0.0\n",
    "yshift = 0.0\n",
    "numticks = 5\n",
    "if set_name == \"Synthetic\":\n",
    "    tick_decimals = 2\n",
    "else:\n",
    "    tick_decimals = 1\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels ]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "im1 = ax1.imshow(abs(curv_on_the_grid.reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm())\n",
    "fig.colorbar(im1,ax = ax1, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "im2 = ax2.imshow(curv_on_the_grid.reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=abs(0.01*curv_on_the_grid.mean()).item()))\n",
    "fig.colorbar(im2,ax = ax2, shrink = 1, label = \"curvature\")\n",
    "ax2.set_title(\"Scalar curvature\")\n",
    "\n",
    "im3 = ax3.imshow((np.sqrt(metric_det_on_grid)).reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax1, ax2, ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/heatmaps_not_scaled.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scalar curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_curvature = curv_on_the_grid.max().item()\n",
    "min_curvature = curv_on_the_grid.min().item()\n",
    "linthresh_curvature = 0.01*abs(curv_on_the_grid.mean()).item()\n",
    "linthresh_curvature\n",
    "\n",
    "max_abs_curvature = abs(curv_on_the_grid).max().item()\n",
    "min_abs_curvature = 0.01*abs(curv_on_the_grid).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "\n",
    "ax1.title.set_text(\"Absolute value of scalar curvature\")\n",
    "p1 = ax1.scatter( latent[:,0], latent[:,1], c=abs(curvature_array), \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                vmax = max_abs_curvature))\n",
    "fig.colorbar(p1,label=\"curvature abs value\")\n",
    "\n",
    "ax2.title.set_text(\"Absolute value of scalar curvature overall\")\n",
    "im1 = ax2.imshow(abs(curv_on_the_grid.reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                  vmax = max_abs_curvature))\n",
    "fig.colorbar(im1,ax = ax2, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "ax3.title.set_text(\"Scalar curvature\")\n",
    "p2 = ax3.scatter( latent[:,0], latent[:,1], c=curvature_array, \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(p2,label=\"curvature\")\n",
    "\n",
    "ax4.title.set_text(\"Scalar curvature overall\")\n",
    "im2 = ax4.imshow(curv_on_the_grid.reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(im2,ax = ax4, shrink = 1, label = \"curvature\")\n",
    "ax4.set_title(\"Scalar curvature overall\")\n",
    "\n",
    "axs = (ax1, ax3)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "axs = (ax2, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/curvature_heatmaps.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobian of Encoder and Decoder norm heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev,jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_size = 4000\n",
    "metric_array_encoder = ricci_regularization.metric_jacrev_vmap(input_dataset[:validation_set_size],function=torus_ae.encoder2lifting,latent_space_dim=D).detach()\n",
    "trace_array_encoder = torch.einsum('jii->j',metric_array_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,nrows=1, figsize=(15,6))\n",
    "p0 = axes[1].scatter( latent[:,0], latent[:,1],\n",
    "                c=trace_array, alpha=1, s = size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet', norm= matplotlib.colors.LogNorm())\n",
    "cb0 = plt.colorbar(p0, label=r\"$\\|\\nabla \\Psi \\|_F = \\mathrm{tr} (G) $\")\n",
    "axes[1].set_title(\"Jacobian of the decoder\")\n",
    "\n",
    "p1 = axes[0].scatter( latent[:validation_set_size,0], latent[:validation_set_size,1],\n",
    "                c=trace_array_encoder, alpha=1, s = size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',norm= matplotlib.colors.LogNorm())\n",
    "cb1 = plt.colorbar(p1, label=r\"$\\|\\nabla \\Phi \\|_F$\")\n",
    "axes[0].set_title(\"Jacobian of the encoder\")\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/jac_norms_encoder_decoder.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax3),(ax2,ax4))= plt.subplots(ncols=2,nrows=2,figsize = (15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax1.title.set_text(\"$\\sqrt{det(G)}$\")\n",
    "p = ax1.scatter( latent[:,0], latent[:,1],\n",
    "                c=torch.sqrt(abs(det_array)), alpha=1, s = size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=np.sqrt(metric_det_on_grid.max()))\n",
    "fig.colorbar(p,label=\"$\\sqrt{det(G)}$\")\n",
    "ax2.title.set_text(\"0.5$\\cdot$tr(G)\")\n",
    "q = ax2.scatter( latent[:,0], latent[:,1], \n",
    "                c=0.5*(trace_array), alpha=1, s= size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(q,label=\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "im3 = ax3.imshow((np.sqrt(metric_det_on_grid)).reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None,\n",
    "                 vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "axs = (ax1, ax2)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    #plt.savefig(f'{Path_pictures}/metric_det_trace.eps',bbox_inches='tight',format='eps')\n",
    "    plt.savefig(f'{Path_pictures}/metric_det_trace.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if build_report == True:\n",
    "    pdfs = [f\"{Path_pictures}/hyperparameters_exp{experiment_number}.pdf\",f'{Path_pictures}/losses_exp{experiment_number}.pdf',f'{Path_pictures}/init_colors_recon_loss.pdf', f'{Path_pictures}/curvature_heatmaps.pdf', f'{Path_pictures}/metric_det_trace.pdf', f'{Path_pictures}/jac_norms_encoder_decoder.pdf']\n",
    "\n",
    "    merger = PdfWriter()\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    merger.write(f\"{Path_pictures}/report_{experiment_name}_exp_{experiment_number}.pdf\")\n",
    "    merger.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
