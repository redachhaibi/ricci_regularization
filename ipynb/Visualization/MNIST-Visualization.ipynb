{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Umap installation required. Type: 'pip install umap-learn'.\n",
    "\n",
    "This notebook visualises the Swissroll dataset and compares its embedding into a pre-trained AE latent space to standard dimensionality reduction techniques such as:\n",
    "\n",
    "0) PCA https://pytorch.org/docs/stable/generated/torch.pca_lowrank.html\n",
    "1) LLE https://cs.nyu.edu/~roweis/lle/papers/lleintroa4.pdf\n",
    "2) t-SNE https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding\n",
    "3) UMAP https://umap-learn.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import ricci_regularization\n",
    "import yaml\n",
    "from sklearn import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, manifold\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_pictures = f\"../../plots\"\n",
    "violent_saving = False\n",
    "alpha = 0.5 # point opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset and tuned AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_without_curvature_regularization_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "\n",
    "torus_ae = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path=\"../\")\n",
    "\n",
    "print(\"AE weights loaded successfully.\")\n",
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "    k = len ( selected_labels )\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose train or test loader\n",
    "loader = test_loader\n",
    "#loader = train_loader\n",
    "\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "\n",
    "for (data, labels) in tqdm( loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) \n",
    "\n",
    "input_dataset = torch.cat(input_dataset_list).reshape(-1, D)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()\n",
    "\n",
    "# latent \\in [-1,1]. grid reparametrization for plotting\n",
    "encoded_points_no_grad = encoded_points_no_grad/math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,v = torch.pca_lowrank(torch.tensor(input_dataset),q=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9),dpi=400)\n",
    "plt.rcParams.update({'font.size': 20}) # makes all fonts on the plot be 20\n",
    "plt.scatter( u[:,0], u[:,1], c=color_array, s= 40,alpha=alpha, cmap='jet',marker='o',edgecolors=None )\n",
    "#plt.title( \"PCA embedding of the swiss roll\")\n",
    "#plt.colorbar(orientation='vertical',shrink = 0.7)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_pca.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_lle, sr_err = manifold.locally_linear_embedding(\n",
    "    input_dataset, n_neighbors=12, n_components=2\n",
    ")\n",
    "\"\"\"\n",
    "fig, axs = plt.subplots(figsize=(8, 8), nrows=2)\n",
    "axs[0].scatter(sr_lle[:, 0], sr_lle[:, 1], c=color_array)\n",
    "axs[0].set_title(\"LLE Embedding of Swiss Roll\")\n",
    "axs[1].scatter(sr_tsne[:, 0], sr_tsne[:, 1], c=color_array)\n",
    "_ = axs[1].set_title(\"t-SNE Embedding of Swiss Roll\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "fig = plt.figure(figsize=(9,9),dpi=400)\n",
    "plt.scatter(sr_lle[:, 0], sr_lle[:, 1], c=color_array,cmap='jet',s=40,alpha=alpha)\n",
    "#plt.title(\"LLE Embedding of the swiss roll\")\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_lle.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_tsne = manifold.TSNE(n_components=2, perplexity=40, random_state=0).fit_transform(\n",
    "    input_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9),dpi=400)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.scatter(sr_tsne[:, 0], sr_tsne[:, 1], c=color_array,cmap='jet',s=40,alpha=alpha)\n",
    "#plt.title(\"t-SNE embedding of the swiss roll\")\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_tsne.pdf',bbox_inches='tight',format='pdf')\n",
    "#plt.savefig(f'{Path_pictures}/swissroll_tsne.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = umap.UMAP().fit(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_points = mapper.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9),dpi=400)\n",
    "plt.rcParams.update({'font.size': 20}) # makes all fonts on the plot be 20\n",
    "plt.scatter( encoded_points[:,0], encoded_points[:,1], c=color_array, s= 40,alpha=alpha, cmap='jet',marker='o',edgecolors=None )\n",
    "#plt.title( \"UMAP embedding of the swiss roll\")\n",
    "#plt.colorbar(orientation='vertical',shrink = 0.7)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_umap.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(9, 9),dpi=400)\n",
    "\n",
    "if dataset_name == \"Swissroll\":\n",
    "    plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o',s=40,alpha=alpha, edgecolor='none', cmap= 'jet')\n",
    "else:\n",
    "    plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap=ricci_regularization.discrete_cmap(k, 'jet'))\n",
    "    plt.colorbar(ticks=range(k))\n",
    "plt.xticks([-1.,-0.5,0.,0.5,1.])\n",
    "plt.yticks([-1.,-0.5,0.,0.5,1.])\n",
    "plt.ylim(-1., 1.)\n",
    "plt.xlim(-1., 1.)\n",
    "#plt.grid(True)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_not_regularized_Torus_AE_latent_space.pdf',format=\"pdf\",bbox_inches='tight')\n",
    "#plt.savefig(f\"{Path_pictures}/latent_space_{experiment_name}.jpg\",bbox_inches='tight', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold plot REDO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us take a uniform grid on the latent space. Note that here d=2. \n",
    "numsteps = 10\n",
    "xs = torch.linspace(-torch.pi, torch.pi, steps = numsteps)\n",
    "ys = torch.linspace(-torch.pi, torch.pi, steps = numsteps)\n",
    "uniform_grid = torch.cartesian_prod(xs,ys)\n",
    "\n",
    "# True Manifold plot\n",
    "truegrid = torch.cartesian_prod(ys,- xs)\n",
    "truegrid = - truegrid.roll(1,1)\n",
    "\n",
    "#img_recon = torus_ae.decoder_torus(torch.rand(100,2)).reshape(-1,1,28,28)\n",
    "img_recon = torus_ae.decoder_torus(truegrid).reshape(-1,1,28,28)\n",
    "fig, ax  = plt.subplots(figsize=(20, 20),dpi=400)\n",
    "ax.set_xticklabels([]) #no tick labels\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(img_recon[:100],10,10)\n",
    "show_image(img_grid.detach())\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/{dataset_name}_manifold_plot.pdf',format=\"pdf\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
