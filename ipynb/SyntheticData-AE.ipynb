{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for dataset\n",
    "D = 784       #dimension\n",
    "k = 3         # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "shift_class = 0\n",
    "\n",
    "\n",
    "# Hyperparameters for data loaders\n",
    "batch_size  = 16\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Set manual seed for reproducibility\n",
    "# torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ricci_regularization\n",
    "\n",
    "# Generate dataset\n",
    "train_dataset = ricci_regularization.generate_dataset(D, k, n, shift_class=shift_class)\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# test_data[:][0] will give the vectors of data without labels from the test part of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Declaration of AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is available\n",
    "cuda_on = torch.cuda.is_available()\n",
    "if cuda_on:\n",
    "    device  = torch.device(\"cuda\") \n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        #self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, hidden_dim, bias=True),\n",
    "        )\n",
    "        self.kl = 0 # For compatibility\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        # out = torch.relu(out)\n",
    "        #out = torch.sin(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        #out = F.leaky_relu(out)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        #self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, output_dim, bias=True),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(x)\n",
    "        #out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr  = 1e-3\n",
    "klw = 0.0\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical\n",
    "#model = Autoencoder(hidden_dim=hidden_dim)\n",
    "encoder = Encoder(input_dim=784, hidden_dim=d)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=784)\n",
    "\n",
    "# VAE\n",
    "#encoder = VariationalEncoder(input_dim=784, hidden_dim=d, cuda=cuda_on)\n",
    "#decoder = Decoder(hidden_dim=d, output_dim=784)\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.RMSprop(params_to_optimize, lr=lr, weight_decay=0.0)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(mydata):\n",
    "    s = encoder(mydata[:][0].view(-1,1,28*28)).detach().numpy()\n",
    "    s = s.reshape(-1, 2)\n",
    "    l = mydata[:][1].numpy().reshape(-1,1)\n",
    "    s = np.concatenate((s,l),axis=1)\n",
    "    myplot = px.scatter(s, x = s[:,0], y = s[:,1], color=s[:,2].astype(str), opacity=0.5)\n",
    "    return myplot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batches per epoch\n",
    "print( \"Reality check of batch splitting: \")\n",
    "print( \"-- Batches per epoch\", len(train_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(train_loader)*batch_size )\n",
    "print( \"-- To be compared to:\", (1.0-split_ratio)*n*k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    mse_loss = []\n",
    "    \n",
    "    batch_idx = 0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        #shaping the images properly\n",
    "        image_batch = image_batch.view(-1,28*28)\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "\n",
    "        # Evaluate loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(decoded_data, image_batch) + klw*encoder.kl\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        #print(batch_idx)\n",
    "\n",
    "        #print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "        \n",
    "        mse_loss.append(float(loss.detach().cpu().numpy()))\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    #return np.mean(train_loss), np.mean(mse_loss) \n",
    "    return mse_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "#diz_loss = {'train_loss':[],'mse_loss':[]}\n",
    "diz_loss = {'train_loss':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "   #old\n",
    "   #train_info = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "\n",
    "   # Set train mode for both the encoder and the decoder\n",
    "   encoder.train()\n",
    "   decoder.train()\n",
    "   mse_loss = []\n",
    "   \n",
    "   batch_idx = 0\n",
    "   # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "   for image_batch, _ in train_loader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "      #shaping the images properly\n",
    "      image_batch = image_batch.view(-1,28*28)\n",
    "      # Move tensor to the proper device\n",
    "      image_batch = image_batch.to(device)\n",
    "      # True batch size\n",
    "      true_batch_size = image_batch.shape[0]\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # Encode data\n",
    "      encoded_data = encoder(image_batch)\n",
    "      # Decode data\n",
    "      decoded_data = decoder(encoded_data)\n",
    "\n",
    "      # Evaluate loss\n",
    "      #loss = loss_fn(decoded_data, image_batch) + klw*encoder.kl\n",
    "      loss = torch.sum( (decoded_data-image_batch)**2 )/true_batch_size\n",
    "\n",
    "      # Backward pass\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # Print batch loss\n",
    "      print('\\t Partial train loss (single batch): %f' % (loss.data))\n",
    "      #print(batch_idx)\n",
    "\n",
    "      #print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "      \n",
    "      mse_loss.append(float(loss.detach().cpu().numpy()))\n",
    "\n",
    "      batch_idx += 1\n",
    "   # end for\n",
    "   \n",
    "   train_info = mse_loss\n",
    "   train_loss = np.mean(train_info)\n",
    "   \n",
    "   print('\\n EPOCH {}/{} \\t train loss {}'.format(epoch + 1, num_epochs, train_loss))\n",
    "   #plot = point_plot(test_data.cpu())\n",
    "   #plot.show()\n",
    "   \n",
    "   diz_loss['train_loss'].append(train_info)\n",
    "   \n",
    "diz_loss['train_loss'] = np.array(diz_loss['train_loss']).flatten()\n",
    "#diz_loss['mse_loss'] = np.array(diz_loss['mse_loss']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_loss['train_loss'], label='Train_loss')\n",
    "#plt.semilogy(diz_loss['train_loss'] - diz_loss['mse_loss'], label='Curv_loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "encoded_samples     = []\n",
    "encoded_samples_raw = []\n",
    "#for sample in tqdm(train_dataset):\n",
    "for sample in tqdm(test_data):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        img = img.view(-1,28*28) # reshape the img\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_sample_raw = np.array( [encoded_img[0], encoded_img[1], label] )\n",
    "    encoded_samples.append(encoded_sample)\n",
    "    encoded_samples_raw.append( encoded_sample_raw )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_array = np.array( encoded_samples_raw )\n",
    "plt.scatter( code_array[:,0], code_array[:,1], c=code_array[:,2], alpha=0.5 )\n",
    "plt.title( \"Latent space for VAE\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "encoded_samples_df = pd.DataFrame(encoded_samples)\n",
    "encoded_samples_df\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples_df, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples_df.label.astype(str), opacity=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
