{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal imports\n",
    "import torch, yaml\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from ricci_regularization.Schauder import NumericalGeodesics\n",
    "from ricci_regularization import RiemannianKmeansTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment setup\n",
    "K = 2 # number of clusters\n",
    "N = 10 # number of points to be clustered \n",
    "\n",
    "mode = \"Schauder\" # can be also \"Interpolation_points\"\n",
    "\n",
    "# specific parameters \n",
    "n_max = 3  # Schauder basis complexity (only for Schauder)\n",
    "step_count = 50  # Number of interpolation steps (for both methods)\n",
    "\n",
    "# optimization parameters\n",
    "beta = 1.e-3 # Frechet mean learning rate #beta is learning_rate_frechet_mean (outer loop)\n",
    "learning_rate = 1.e-3 # learning_rate_geodesics (inner loop)\n",
    "num_iter_outer = 10 # number of Frechet mean updates (outer loop)\n",
    "num_iter_inner = 15 # number of geodesics refinement interations per 1 Frechet mean update (inner loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the pretrained AE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_experiment = '../experiments/MNIST_Setting_3_config.yaml'\n",
    "with open(Path_experiment, 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print(\"Experiment results loaded successfully.\")\n",
    "# Loading data\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "print(\"Data loaders created successfully.\")\n",
    "\n",
    "# Loading the pre-tained AE\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config)\n",
    "print(\"AE weights loaded successfully.\")\n",
    "print(\"AE weights loaded from\", Path_ae_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking dataset to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting the dataset that we want to cluster\n",
    "# we use some random N points of the test dataset that we will cluster\n",
    "# This could be done differently, e.g. by simply picking random points\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "d = yaml_config[\"architecture\"][\"latent_dim\"]\n",
    "data = test_dataset.data\n",
    "\n",
    "# Limit dataset to the first N samples\n",
    "subset_indices = list(range(N))\n",
    "mnist_subset = torch.utils.data.Subset(data, subset_indices)\n",
    "dataset_batch_size = 128\n",
    "dataloader = torch.utils.data.DataLoader(mnist_subset, batch_size=dataset_batch_size, shuffle=False)\n",
    "# encoding into latent space\n",
    "torus_ae.cpu()\n",
    "torus_ae.eval()\n",
    "\n",
    "# Encode samples into latent space\n",
    "encoded_points = []\n",
    "with torch.no_grad():  # No need to compute gradients\n",
    "    for images in dataloader:\n",
    "#        print(images.shape)\n",
    "        latent = torus_ae.encoder2lifting( (images.reshape(-1, D)).to(torch.float32) )  # Pass images through the encoder\n",
    "        encoded_points.append(latent)\n",
    "encoded_points = torch.cat(encoded_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting parameters to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_centroids = RiemannianKmeansTools.initialize_centers(encoded_points, K, N) \n",
    "current_centroids = torch.clone(initial_centroids) \n",
    "\n",
    "if mode == \"Interpolation_points\":\n",
    "    geodesic_solver = None\n",
    "    # Initialize geodesic segments\n",
    "    parameters_of_geodesics = RiemannianKmeansTools.construct_interpolation_points_on_segments_connecting_centers2encoded_data(\n",
    "            encoded_points, \n",
    "            initial_centroids, \n",
    "            num_aux_points = step_count)\n",
    "elif mode == \"Schauder\":\n",
    "    geodesic_solver = NumericalGeodesics(n_max, step_count)\n",
    "    # Get Schauder basis\n",
    "    N_max = geodesic_solver.schauder_bases[\"zero_boundary\"][\"N_max\"]\n",
    "    basis = geodesic_solver.schauder_bases[\"zero_boundary\"][\"basis\"]\n",
    "    # Define parameters (batch_size × N_max × dim)\n",
    "    parameters_of_geodesics = torch.zeros((N, K, N_max, d), requires_grad=True)\n",
    "init_parameters = torch.clone(parameters_of_geodesics) # save initial segments\n",
    "# Set optimizer params\n",
    "parameters = torch.nn.Parameter(parameters_of_geodesics) # Wrap as a parameter\n",
    "\n",
    "optimizer = torch.optim.SGD([parameters], lr=learning_rate)\n",
    "\n",
    "cluster_index_of_each_point = None\n",
    "meaningful_geodesics = None\n",
    "\n",
    "#losses\n",
    "meaningful_geodesics_loss_history = []\n",
    "meaningful_geodesics_loss_history_by_cluster = []\n",
    "norm_Frechet_mean_gradient_history = []\n",
    "\n",
    "\"\"\"\n",
    "# visualizing initialization (optional)\n",
    "plt.scatter(encoded_points[:,0],encoded_points[:,1], label = \"encoded data\")\n",
    "plt.scatter(initial_centroids[:,0], initial_centroids[:,1], c=\"red\", label = \"initial_centroids\", marker='*', s = 60)\n",
    "plt.xlim(-torch.pi, torch.pi)\n",
    "plt.ylim(-torch.pi, torch.pi)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer loop \n",
    "for iter_outer in range(num_iter_outer):\n",
    "    # Inner loop (refining geodesics)\n",
    "    for iter_inner in range(num_iter_inner):\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        # Compute the loss\n",
    "        loss_geodesics = RiemannianKmeansTools.compute_energy(\n",
    "                mode = mode, \n",
    "                parameters_of_geodesics=parameters, \n",
    "                end_points = [encoded_points, current_centroids],\n",
    "                decoder = torus_ae.decoder_torus,\n",
    "                geodesic_solver = geodesic_solver)\n",
    "        # Backpropagation: compute gradients\n",
    "        loss_geodesics.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        # Store the loss value\n",
    "    # end inner loop\n",
    "\n",
    "    # compute a vector of length of all geodesics shape (N,K)\n",
    "    lengths_of_geodesics = RiemannianKmeansTools.compute_lengths(\n",
    "            mode = mode,\n",
    "            parameters_of_geodesics=parameters,\n",
    "            end_points = [encoded_points, current_centroids],\n",
    "            decoder = torus_ae.decoder_torus,\n",
    "            geodesic_solver = geodesic_solver) \n",
    "    \n",
    "    # retrieve the class membership of each point by finding the closest cluster centroid shape (N)\n",
    "    cluster_index_of_each_point = torch.argmin(lengths_of_geodesics, dim=1) \n",
    "    \n",
    "    batch_indices = torch.arange(N)\n",
    "    \n",
    "    if mode == \"Interpolation_points\":\n",
    "        geodesic_curve = RiemannianKmeansTools.geodesics_from_parameters_interpolation_points(\n",
    "                parameters_of_geodesics = parameters_of_geodesics, \n",
    "                end_points = [encoded_points, current_centroids])\n",
    "    elif mode == \"Schauder\":\n",
    "        #geodesic_solver = NumericalGeodesics(n_max, step_count)\n",
    "        geodesic_curve = RiemannianKmeansTools.geodesics_from_parameters_schauder(\n",
    "                geodesic_solver = geodesic_solver, \n",
    "                parameters_of_geodesics = parameters_of_geodesics, \n",
    "                end_points = [encoded_points, current_centroids])\n",
    "        \n",
    "    # pick only geodesics connecting points to cluster centroids where the points are assigned shape (N,m,d)\n",
    "    meaningful_geodesics = geodesic_curve[batch_indices, cluster_index_of_each_point, :, :].detach() \n",
    "\n",
    "    # v is the direction to move the cluster centroids\n",
    "    v = meaningful_geodesics[:,-1,:] - meaningful_geodesics[:,-2,:]\n",
    "    v = v / v.norm(dim=1).unsqueeze(-1) # find the last segments of the geod shape (N,d)\n",
    "    \n",
    "    #---------------------------------------------------------------    \n",
    "    # Update cluster centroids with weight beta:\n",
    "    #---------------------------------------------------------------\n",
    "    # Assuming cluster_index_of_each_point is a tensor of shape (N,) containing cluster indices\n",
    "    # and K is the number of clusters\n",
    "    # Expand cluster_index_of_each_point to index into v and lengths_of_geodesics\n",
    "    cluster_index_of_each_point_expanded = cluster_index_of_each_point.unsqueeze(-1).expand(-1, v.size(-1))\n",
    "    # Compute weighted Frechet mean gradient for each cluster\n",
    "    weighted_v = lengths_of_geodesics[:, 0].unsqueeze(-1) * v  # Shape: (N, d)\n",
    "\n",
    "    # Create a one-hot encoding of the cluster indices\n",
    "    one_hot_clusters = torch.nn.functional.one_hot(cluster_index_of_each_point, num_classes=K).float()  # Shape: (N, K)\n",
    "\n",
    "    # Compute the gradients for each cluster\n",
    "    Frechet_mean_gradient = one_hot_clusters.T @ weighted_v  # Shape: (K, d)\n",
    "    \n",
    "    # Update cluster centroids\n",
    "    with torch.no_grad():\n",
    "        current_centroids += - beta * Frechet_mean_gradient  # Update all centroids simultaneously\n",
    "\n",
    "    # Compute average Frechet mean gradient norm\n",
    "    average_Frechet_mean_gradient_norm = (Frechet_mean_gradient.norm(dim=1).mean()).item()\n",
    "    # Append to norm history\n",
    "    norm_Frechet_mean_gradient_history.append(average_Frechet_mean_gradient_norm)\n",
    "\n",
    "    # saving the lengths of meaningful geodesics\n",
    "    meaningful_geodesics_lengths = torch.gather(lengths_of_geodesics,1,cluster_index_of_each_point_expanded)[:,0]\n",
    "    meaningful_geodesics_loss_history.append( meaningful_geodesics_lengths.detach().sum().item() )\n",
    "\n",
    "    #compute the sum of geodesic length for each cluster\n",
    "    total_length_of_meaningful_geodesics_by_cluster = torch.zeros(K, dtype=meaningful_geodesics_lengths.dtype)\n",
    "    total_length_of_meaningful_geodesics_by_cluster.scatter_add_(0, cluster_index_of_each_point, meaningful_geodesics_lengths)    \n",
    "    meaningful_geodesics_loss_history_by_cluster.append(total_length_of_meaningful_geodesics_by_cluster.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming norm_Frechet_mean_gradient_history, meaningful_geodesics_loss_history, loss_history are arrays or tensors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(K*5, 5))  # Create a figure with 1 row and 3 columns\n",
    "\n",
    "# Plot norm_Frechet_mean_gradient_history\n",
    "axes[0].plot(norm_Frechet_mean_gradient_history, marker='o', markersize=3, label='Frechet mean update history')\n",
    "axes[0].set_title('Averege shift of centers (proxy of Fréchet mean gradient norm)')\n",
    "axes[0].set_xlabel('Outer loop iterations')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot meaningful geodesic lengths by cluster\n",
    "# Generate a color palette with distinct colors\n",
    "colors = plt.cm.jet(torch.linspace(0, 1, K))  # Use a colormap (e.g., 'viridis')\n",
    "\n",
    "lengths_of_meaningful_geodesics_concatenated = torch.cat((meaningful_geodesics_loss_history_by_cluster), dim=0).detach()\n",
    "for i in range(K):\n",
    "    axes[1].plot(lengths_of_meaningful_geodesics_concatenated[:, i],marker='o',markersize=3,\n",
    "                 label=f'Cluster {i} geodesics length', color=colors[i])\n",
    "    axes[1].set_title('Meaningful geodesics length by cluster')\n",
    "    axes[1].set_xlabel('Outer Loop Iterations')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "# Plot meaningful_geodesics_loss_history\n",
    "axes[1].plot(meaningful_geodesics_loss_history, marker='o', markersize=3, label='All clusters geodesics length', color='green')\n",
    "axes[1].set_title('Meaningfull geodesics length')\n",
    "axes[1].set_xlabel('Outer loop iterations')\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"Interpolation_points\":\n",
    "    geodesic_curve = RiemannianKmeansTools.geodesics_from_parameters_interpolation_points(\n",
    "        parameters_of_geodesics,\n",
    "        end_points = [encoded_points, current_centroids])\n",
    "elif mode == \"Schauder\":\n",
    "    geodesic_curve = RiemannianKmeansTools.geodesics_from_parameters_schauder(\n",
    "        geodesic_solver, \n",
    "        parameters_of_geodesics, \n",
    "        end_points = [encoded_points, current_centroids])\n",
    "\n",
    "RiemannianKmeansTools.plot_octopus(\n",
    "    geodesic_curve.detach(), \n",
    "    memberships = cluster_index_of_each_point,\n",
    "    meaningful_geodesics = meaningful_geodesics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"center shifts:\\n\", (initial_centroids -  current_centroids))\n",
    "average_cluster_center_shift_norm = (current_centroids - initial_centroids).detach().norm(dim = 1).mean()\n",
    "print(\"Average center's shift:\", average_cluster_center_shift_norm.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
