{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 784 #dimension\n",
    "k = 3 # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "#n = 10**3 # num of points in each plane\n",
    "\n",
    "batch_size  = 128\n",
    "split_ratio = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "phi = [] #list of k ontonormal bases in k planes\n",
    "for j in range(k):\n",
    "    # creating random planes\n",
    "    rand_vectors = torch.rand(D, 2)\n",
    "    q, r = torch.qr(rand_vectors)\n",
    "    phi.append(q)\n",
    "#phi\n",
    "\n",
    "#creating samples from normal distributions via torch distributions\n",
    "data = []\n",
    "for i in range(k):\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2) + 10*i, torch.eye(2))\n",
    "    #m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    samples = m.sample(sample_shape=(n,)).T\n",
    "    #samples = normalize(samples, p = 1, dim = 0)\n",
    "    #data.append(normalize(torch.matmul(phi[i], samples)))\n",
    "    data.append(torch.matmul(phi[i], samples))\n",
    "data_tensor = torch.cat(data, dim=1)\n",
    "\n",
    "data_tensor = data_tensor.T\n",
    "data_tensor = data_tensor.reshape(k*n, 1, 28, 28)\n",
    "\n",
    "labels_list = []\n",
    "for i in range(k):\n",
    "    labels_list.append(i*(torch.ones(n)))\n",
    "labels = torch.cat(labels_list)\n",
    "\n",
    "my_set = TensorDataset(data_tensor,labels)\n",
    "train_dataset = my_set\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, test_data = random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "# test_data[:][0] will give the vectors of data without labels from the test part of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne check on test set\n",
    "#synthetic_set = data_tensor.reshape(-1,28*28)\n",
    "synthetic_set = test_data[:][0].view(-1,28*28)\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "z = tsne.fit_transform(synthetic_set.numpy())\n",
    "df = pd.DataFrame()\n",
    "#df[\"y\"] = labels.numpy()\n",
    "df[\"y\"] = test_data[:][1].numpy() #test_data[:][1] are labels\n",
    "df[\"comp-1\"] = z[:,0]\n",
    "df[\"comp-2\"] = z[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
    "                palette=sns.color_palette(\"hls\", 10),\n",
    "                data=df).set(title=\"Synthetic dataset data T-SNE projection\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, cuda=False):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.linear2 = nn.Linear(512, hidden_dim)\n",
    "        self.linear3 = nn.Linear(512, hidden_dim)\n",
    "        \n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        if cuda:\n",
    "            self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "            self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu =  self.linear2(x)\n",
    "        sigma = torch.exp(self.linear3(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        #self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, hidden_dim, bias=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = torch.sin(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        #out = F.leaky_relu(out)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        #self.decoder = nn.Linear(hidden_dim, output_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(x)\n",
    "        #out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr  = 0.001\n",
    "klw = 0.0\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is available\n",
    "cuda_on = torch.cuda.is_available()\n",
    "if cuda_on:\n",
    "    device  = torch.device(\"cuda\") \n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical\n",
    "#model = Autoencoder(hidden_dim=hidden_dim)\n",
    "#encoder = Encoder(input_dim=784, hidden_dim=d)\n",
    "\n",
    "# VAE\n",
    "encoder = VariationalEncoder(input_dim=784, hidden_dim=d, cuda=cuda_on)\n",
    "decoder = Decoder(hidden_dim=d, output_dim=784)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.RMSprop(params_to_optimize, lr=lr, weight_decay=0.0)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    mse_loss = []\n",
    "    \n",
    "    batch_idx = 0\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        #shaping the images properly\n",
    "        image_batch = image_batch.view(-1,28*28)\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = loss_fn(decoded_data, image_batch) + klw*encoder.kl\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        #print(batch_idx)\n",
    "\n",
    "        #print('\\t partial train loss (single batch): {:.6} \\t curv_loss {:.6} \\t mse {:.6}'.format(loss.data, new_loss, only_mse.data))\n",
    "        \n",
    "        mse_loss.append(float(loss.detach().cpu().numpy()))\n",
    "\n",
    "        batch_idx += 1\n",
    "\n",
    "    #return np.mean(train_loss), np.mean(mse_loss) \n",
    "    return mse_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(mydata):\n",
    "    s = encoder(mydata[:][0].view(-1,1,28*28)).detach().numpy()\n",
    "    s = s.reshape(-1, 2)\n",
    "    l = mydata[:][1].numpy().reshape(-1,1)\n",
    "    s = np.concatenate((s,l),axis=1)\n",
    "    myplot = px.scatter(s, x = s[:,0], y = s[:,1], color=s[:,2].astype(str), opacity=0.5)\n",
    "    return myplot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches per epoch\n",
    "print( \"Reality check: \")\n",
    "print( \"-- Batches per epoch\", len(train_loader) )\n",
    "print( \"batch size:\", batch_size )\n",
    "print( \"product: \", len(train_loader)*batch_size )\n",
    "print( \"-- Compared to:\", (1.0-split_ratio)*n*k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "#diz_loss = {'train_loss':[],'mse_loss':[]}\n",
    "diz_loss = {'train_loss':[]}\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "   train_info = train_epoch(encoder,decoder,device,train_loader,loss_fn,optim)\n",
    "\n",
    "   train_loss = np.mean(train_info)\n",
    "   \n",
    "   print('\\n EPOCH {}/{} \\t train loss {}'.format(epoch + 1, num_epochs,train_loss))\n",
    "   #plot = point_plot(test_data.cpu())\n",
    "   #plot.show()\n",
    "   \n",
    "   diz_loss['train_loss'].append(train_info)\n",
    "   \n",
    "diz_loss['train_loss'] = np.array(diz_loss['train_loss']).flatten()\n",
    "#diz_loss['mse_loss'] = np.array(diz_loss['mse_loss']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.semilogy(diz_loss['train_loss'], label='Train_loss')\n",
    "#plt.semilogy(diz_loss['train_loss'] - diz_loss['mse_loss'], label='Curv_loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.grid()\n",
    "plt.legend()\n",
    "#plt.title('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "encoded_samples     = []\n",
    "encoded_samples_raw = []\n",
    "#for sample in tqdm(train_dataset):\n",
    "for sample in tqdm(test_data):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        img = img.view(-1,28*28) # reshape the img\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_sample_raw = np.array( [encoded_img[0], encoded_img[1], label] )\n",
    "    encoded_samples.append(encoded_sample)\n",
    "    encoded_samples_raw.append( encoded_sample_raw )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_array = np.array( encoded_samples_raw )\n",
    "plt.scatter( code_array[:,0], code_array[:,1], c=code_array[:,2], alpha=0.5 )\n",
    "plt.title( \"Latent space for VAE\")\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples_df = pd.DataFrame(encoded_samples)\n",
    "encoded_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples_df, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=encoded_samples_df.label.astype(str), opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
