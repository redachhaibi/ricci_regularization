{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the fast Frechet mean computation by combining the computation of geodesics and the mean itself into a single optimization problem with the help of 'Octopus' class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import stochman\n",
    "from stochman.manifold import EmbeddedManifold\n",
    "from stochman.curves import CubicSpline\n",
    "\n",
    "violent_saving = True\n",
    "\n",
    "#experiment_json = f'../experiments/MNIST_torus_AEexp34.json' # no curv_pen\n",
    "\n",
    "experiment_json = f'../experiments/MNIST01_torus_AEexp7.json'\n",
    "mydict = ricci_regularization.get_dataloaders_tuned_nn(Path_experiment_json=experiment_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_ae = mydict[\"tuned_neural_network\"]\n",
    "test_loader = mydict[\"test_loader\"]\n",
    "json_cofig = mydict[\"json_config\"]\n",
    "Path_pictures = json_cofig[\"Path_pictures\"]\n",
    "exp_number = json_cofig[\"experiment_number\"]\n",
    "curv_w = json_cofig[\"losses\"][\"curv_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 784\n",
    "k = json_cofig[\"dataset\"][\"parameters\"][\"k\"]\n",
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "feature_space_encoding_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( test_loader, position=0 ):\n",
    "#for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    feature_space_encoding_list.append(torus_ae.encoder_torus(data.view(-1,D)))\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "feature_space_encoding = torch.cat(feature_space_encoding_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1],c = color_array,cmap=ricci_regularization.discrete_cmap(k,\"jet\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochman.manifold import EmbeddedManifold\n",
    "# geodesics are computed minimizing \"energy\" in the embedding of the manifold,\n",
    "# So no need to compute the Pullback metric. and thus the algorithm is fast\n",
    "class Autoencoder(EmbeddedManifold):\n",
    "    def embed(self, c, jacobian = False):\n",
    "        return torus_ae.decoder_torus(c)\n",
    "#selected_labels = json_cofig[\"dataset\"][\"selected_labels\"]\n",
    "manifold = Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Octopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochman.curves import BasicCurve\n",
    "from typing import Optional, Tuple\n",
    "from torch import nn\n",
    "from abc import ABC\n",
    "\n",
    "class Octopus(BasicCurve):\n",
    "    def __init__(\n",
    "    self,\n",
    "    begin: torch.Tensor,\n",
    "    end: torch.Tensor,\n",
    "    num_nodes: int = 5,\n",
    "    requires_grad: bool = True,\n",
    "    basis: Optional[torch.Tensor] = None,\n",
    "    params: Optional[torch.Tensor] = None,\n",
    ") -> None:\n",
    "        super().__init__(begin, end, num_nodes, requires_grad, basis=basis, params=params)\n",
    "\n",
    "    def _init_params(self, basis, params) -> None:\n",
    "        if basis is None:\n",
    "            basis = self._compute_basis(num_edges=self._num_nodes - 1)\n",
    "        self.register_buffer(\"basis\", basis)\n",
    "\n",
    "        if params is None:\n",
    "            params = torch.zeros(\n",
    "                self.begin.shape[0], self.basis.shape[1], self.begin.shape[1], dtype=self.begin.dtype\n",
    "            )\n",
    "        else:\n",
    "            params = params.unsqueeze(0) if params.ndim == 2 else params\n",
    "\n",
    "        if self._requires_grad:\n",
    "            self.register_parameter(\"params\", nn.Parameter(params))\n",
    "        else:\n",
    "            self.register_buffer(\"params\", params)\n",
    "\n",
    "    # Compute cubic spline basis with end-points (0, 0) and (1, 0)\n",
    "    def _compute_basis(self, num_edges) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            # set up constraints\n",
    "            t = torch.linspace(0, 1, num_edges + 1, dtype=self.begin.dtype)[1:-1]\n",
    "\n",
    "            end_points = torch.zeros(2, 4 * num_edges, dtype=self.begin.dtype)\n",
    "            end_points[0, 0] = 1.0\n",
    "            #end_points[1, -4:] = 1.0\n",
    "\n",
    "            zeroth = torch.zeros(num_edges - 1, 4 * num_edges, dtype=self.begin.dtype)\n",
    "            for i in range(num_edges - 1):\n",
    "                si = 4 * i  # start index\n",
    "                fill = torch.tensor([1.0, t[i], t[i] ** 2, t[i] ** 3], dtype=self.begin.dtype)\n",
    "                zeroth[i, si : (si + 4)] = fill\n",
    "                zeroth[i, (si + 4) : (si + 8)] = -fill\n",
    "\n",
    "            first = torch.zeros(num_edges - 1, 4 * num_edges, dtype=self.begin.dtype)\n",
    "            for i in range(num_edges - 1):\n",
    "                si = 4 * i  # start index\n",
    "                fill = torch.tensor([0.0, 1.0, 2.0 * t[i], 3.0 * t[i] ** 2], dtype=self.begin.dtype)\n",
    "                first[i, si : (si + 4)] = fill\n",
    "                first[i, (si + 4) : (si + 8)] = -fill\n",
    "\n",
    "            second = torch.zeros(num_edges - 1, 4 * num_edges, dtype=self.begin.dtype)\n",
    "            for i in range(num_edges - 1):\n",
    "                si = 4 * i  # start index\n",
    "                fill = torch.tensor([0.0, 0.0, 6.0 * t[i], 2.0], dtype=self.begin.dtype)\n",
    "                second[i, si : (si + 4)] = fill\n",
    "                second[i, (si + 4) : (si + 8)] = -fill\n",
    "\n",
    "            constraints = torch.cat((end_points, zeroth, first, second))\n",
    "            self.constraints = constraints\n",
    "\n",
    "            # Compute null space, which forms our basis\n",
    "            _, S, V = torch.svd(constraints, some=False)\n",
    "            basis = V[:, S.numel() :]  # (num_coeffs)x(intr_dim)\n",
    "\n",
    "            return basis\n",
    "\n",
    "    def _get_coeffs(self) -> torch.Tensor:\n",
    "        coeffs = (\n",
    "            self.basis.unsqueeze(0).expand(self.params.shape[0], -1, -1).bmm(self.params)\n",
    "        )  # Bx(num_coeffs)xD\n",
    "        B, num_coeffs, D = coeffs.shape\n",
    "        degree = 4\n",
    "        num_edges = num_coeffs // degree\n",
    "        coeffs = coeffs.view(B, num_edges, degree, D)  # Bx(num_edges)x4xD\n",
    "        return coeffs\n",
    "    def _eval_polynomials(self, t: torch.Tensor, coeffs: torch.Tensor) -> torch.Tensor:\n",
    "        # each row of coeffs should be of the form c0, c1, c2, ... representing polynomials\n",
    "        # of the form c0 + c1*t + c2*t^2 + ...\n",
    "        # coeffs: Bx(num_edges)x(degree)xD\n",
    "        B, num_edges, degree, D = coeffs.shape\n",
    "        idx = torch.floor(t * num_edges).clamp(min=0, max=num_edges - 1).long()  # Bx|t|\n",
    "        power = (\n",
    "            torch.arange(0.0, degree, dtype=t.dtype, device=self.device).view(1, 1, -1).expand(B, -1, -1)\n",
    "        )  # Bx1x(degree)\n",
    "        tpow = t.view(B, -1, 1).pow(power)  # Bx|t|x(degree)\n",
    "        coeffs_idx = torch.cat([coeffs[k, idx[k]].unsqueeze(0) for k in range(B)])  # Bx|t|x(degree)xD\n",
    "        retval = torch.sum(tpow.unsqueeze(-1).expand(-1, -1, -1, D) * coeffs_idx, dim=2)  # Bx|t|xD\n",
    "        return retval\n",
    "\n",
    "    def _eval_straight_line(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = t.shape\n",
    "        tt = t.view(B, T, 1)  # Bx|t|x1\n",
    "        retval = (1 - tt).bmm(self.begin.unsqueeze(1)) + tt.bmm(self.end.unsqueeze(1))  # Bx|t|xD\n",
    "        return retval\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        coeffs = self._get_coeffs()  # Bx(num_edges)x4xD\n",
    "        no_batch = t.ndim == 1\n",
    "        if no_batch:\n",
    "            t = t.expand(coeffs.shape[0], -1)  # Bx|t|\n",
    "        retval = self._eval_polynomials(t, coeffs)  # Bx|t|xD\n",
    "        retval += self._eval_straight_line(t)\n",
    "        if no_batch and retval.shape[0] == 1:\n",
    "            retval.squeeze_(0)  # |t|xD\n",
    "        return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "p0 = torch.rand(n,2)\n",
    "p1 = torch.rand(n,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus = Octopus(p0,p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus._parameters['params'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus._parameters['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus.plot()\n",
    "plt.scatter(p0[:,0],p0[:,1],marker=\"*\",c=\"orange\")\n",
    "plt.scatter(p1[:,0],p1[:,1],marker=\"*\",c=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frechet_mean(octopus, manifold,optimizer=torch.optim.Adam, max_iter=150, eval_grid=20, lr=1e-2):\n",
    "    # Initialize optimizer and set up closure\n",
    "    alpha = torch.linspace(0, 1, eval_grid, dtype=octopus.begin.dtype, device=octopus.device)\n",
    "    opt = optimizer(octopus.parameters(), lr=lr,)   \n",
    "    lambda_centers = 1e3 # huge weight\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    " \n",
    "        loss_dist2center = manifold.curve_energy(octopus(alpha)).mean()\n",
    "        # this is euclidean distanses between points which are the starting points\n",
    "        # we want it to be zero! (same starting point)\n",
    "        loss_centers = (octopus(alpha)[:-1,-1] - octopus(alpha)[1:,-1]).norm().square()\n",
    "        loss = lambda_centers*loss_centers + loss_dist2center\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    thresh = 1e-3\n",
    "    for k in range(max_iter):\n",
    "        opt.step(closure=closure)\n",
    "        max_grad = max([p.grad.abs().max() for p in octopus.parameters()])\n",
    "        if max_grad < thresh:\n",
    "            break\n",
    "        # if k % (max_iter // 10) == 0:\n",
    "        #    curve.constant_speed(manifold)\n",
    "    # curve.constant_speed(manifold)\n",
    "    print(max_grad)\n",
    "    return max_grad < thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frechet_mean(octopus,manifold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus.plot()\n",
    "plt.scatter(p0[:,0],p0[:,1],marker=\"*\",c=\"orange\")\n",
    "#plt.scatter(p1[:,0],p1[:,1],marker=\"*\",c=\"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0,1,20)\n",
    "print(\"Frechet mean:\\n\", octopus(t)[:,-1][0].detach())\n",
    "FM = octopus(t)[:,-1][0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus(t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,_ = manifold.connecting_geodesic(p0[0],FM)\n",
    "c(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding optimization params to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octopus.constraints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=octopus.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    loss = manifold.curve_energy(octopus(t)).mean()\n",
    "    loss.backward()\n",
    "    return loss\n",
    "optimizer.step(closure=closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for param in octopus.parameters():\n",
    "    print(param.grad)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "        # Register a custom parameter\n",
    "        self.register_parameter(\"custom_param\", nn.Parameter(torch.randn(1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Use the custom parameter\n",
    "        return self.fc(x) + self.custom_param\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "\n",
    "# Accessing registered parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())\n",
    "\n",
    "\n",
    "#optimization loop example\n",
    "\n",
    "input = torch.rand(10)\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "num_steps = 50\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(input).norm()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(loss)\n",
    "new_param = nn.Parameter(torch.randn(7,7))\n",
    "model.register_parameter(\"hahaha_param\",nn.Parameter(torch.randn(7,7)))\n",
    "# Accessing registered parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Initial guess via Euclidean K-means via Geomstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this adds an environmental variable\n",
    "#%env GEOMSTATS_BACKEND=pytorch\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.visualization as visualization\n",
    "from geomstats.geometry.hypersphere import Hypersphere\n",
    "from geomstats.learning.kmeans import RiemannianKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circumference1 = Hypersphere(dim=1)\n",
    "circumference2 = Hypersphere(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building torus as a product $\\mathcal{T} = \\mathcal{S}^1 \\times \\mathcal{S}^1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomstats.geometry.product_manifold import ProductManifold\n",
    "torus = ProductManifold((circumference1,circumference2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading saved points and labels and plotting ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_angles = encoded_points_no_grad #torch.load(\"encoded_angles.pt\")\n",
    "gt_labels = color_array #torch.load(\"labels.pt\")\n",
    "#convert dt_labels into 0 and 1 array\n",
    "gt_labels = (gt_labels - min(gt_labels))/max((gt_labels - min(gt_labels))).to(torch.int)\n",
    "gt_labels = gt_labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting MNIST data on torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_1_coordinates = torus.factors[0].intrinsic_to_extrinsic_coords(encoded_angles[:,0]).reshape(2,-1).T\n",
    "circ_2_coordinates = torus.factors[1].intrinsic_to_extrinsic_coords(encoded_angles[:,1]).reshape(2,-1).T\n",
    "#print(\"1st\", circ_1_coordinates)\n",
    "#print(\"2nd\", circ_2_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data_on_torus_4d = np.concatenate((circ_1_coordinates,circ_2_coordinates),axis = 1).reshape(-1,2,2) # cos\\phi, sin \\phi, cos \\psi, sin \\psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = RiemannianKMeans(torus, k, tol=1e-3)\n",
    "kmeans.fit(MNIST_data_on_torus_4d)\n",
    "kmeans_latent_space_euclidean_labels = kmeans.labels_\n",
    "cluster_centers = kmeans.centroids_# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus.factors[0].extrinsic_to_angle(cluster_centers[:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers_in_local_chart = Hypersphere(dim=1).extrinsic_to_intrinsic_coords(cluster_centers).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(2,1,figsize=(8, 12))\n",
    "p1 = ax1.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=kmeans_latent_space_euclidean_labels, marker='o', edgecolor='none', cmap=ricci_regularization.discrete_cmap(k, 'jet'))\n",
    "plt.colorbar(p1,ticks=range(k))\n",
    "ax1.title.set_text(\"Latent space colored by K-means on Torus with Euclidean metric\")\n",
    "ax1.grid(True)\n",
    "ax1.scatter(cluster_centers_in_local_chart[:,0],cluster_centers_in_local_chart[:,1],marker = '*',s=150,c =\"orange\")\n",
    "\n",
    "correcltly_detected_labels = abs(kmeans_latent_space_euclidean_labels - gt_labels)\n",
    "if correcltly_detected_labels.sum() < len(gt_labels)//2:\n",
    "    correcltly_detected_labels = np.logical_not(correcltly_detected_labels)\n",
    "\n",
    "p2 = ax2.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=correcltly_detected_labels, marker='o', edgecolor='none', cmap=plt.cm.get_cmap(\"viridis\", k))\n",
    "cbar = plt.colorbar(p2,ticks=[0.25,0.75])\n",
    "cbar.ax.set_yticklabels([\"incorrect\",\"correct\"]) \n",
    "#if violent_saving == True:\n",
    "#    plt.savefig(f\"{Path_pictures}/Kmeans_latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means in input data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_in_clusters = 3\n",
    "\n",
    "clusters = []\n",
    "clusters_initial_labels = []\n",
    "for i in range(k):\n",
    "    current_cluster = encoded_points_no_grad[np.where(kmeans_latent_space_euclidean_labels == i)]\n",
    "    current_cluster = current_cluster[:num_points_in_clusters]\n",
    "    current_cluster_initial_labels = gt_labels[np.where(kmeans_latent_space_euclidean_labels == i)]\n",
    "    current_cluster_initial_labels = torch.tensor(current_cluster_initial_labels[:num_points_in_clusters])\n",
    "    clusters_initial_labels.append(current_cluster_initial_labels)\n",
    "    clusters.append(current_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "colors = list(mcolors.TABLEAU_COLORS.keys())\n",
    "for i in range(k):\n",
    "    plt.scatter(clusters[i][:,0],clusters[i][:,1],c = colors[i%len(colors)],s=30)\n",
    "    plt.scatter(cluster_centers_in_local_chart[i,0],cluster_centers_in_local_chart[i,1],marker = '*',s=250,c =colors[i%len(colors)],edgecolors=\"black\")\n",
    "plt.xlim(-torch.pi,torch.pi)\n",
    "plt.ylim(-torch.pi,torch.pi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multioctopus parameters setting\n",
    "N = num_points_in_clusters*k # # all points \n",
    "\n",
    "points = (torch.rand(N,2)-1/2)*2*torch.pi #random points\n",
    "\n",
    "#points = torch.cat(clusters)\n",
    "#cluster_centers_in_local_chart.repeat(k*num_points_in_clusters,1).T.shape\n",
    "init_centers = torch.tensor(cluster_centers_in_local_chart.T.repeat(N,1).T)\n",
    "#print(init_centers)\n",
    "# b1,b1,...,b2,b2,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_octopus = Octopus(points.repeat(k,1),init_centers)\n",
    "weights = nn.Parameter((1/k)*torch.ones(N,k))\n",
    "multi_octopus.register_parameter(\"leg_weights\",weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_octopus.plot()\n",
    "plt.scatter(cluster_centers_in_local_chart[:,0],cluster_centers_in_local_chart[:,1],marker = '*',s=250,c = \"orange\",edgecolors=\"black\",zorder=10)\n",
    "plt.xlim(-torch.pi,torch.pi)\n",
    "plt.ylim(-torch.pi,torch.pi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss centers\n",
    "#multi_octopus(t)[:N,-1] - multi_octopus(t)[:N,-1].roll(shifts=1,dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0,1,20)\n",
    "#t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = manifold.curve_energy(multi_octopus(t),reduction=None)\n",
    "print(energies)\n",
    "energies = energies.reshape(2,N).T # in i-th column j-th row is the energy of curve\n",
    "# connecting p_j and b_i \n",
    "print(weights)\n",
    "print(energies)\n",
    "(weights*energies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    lambda_centers = 2*energies.mean()\n",
    "\"\"\"\n",
    "lambda_centers = 1e4 # huge weight\n",
    "print(lambda_centers)\n",
    "#optimizer choice\n",
    "\n",
    "#opt = torch.optim.Adam(multi_octopus.parameters(), lr=0.2e-2)   \n",
    "opt = torch.optim.SGD(multi_octopus.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnostic\n",
    "opt.zero_grad()\n",
    "\n",
    "energies = manifold.curve_energy(multi_octopus(t),reduction=None)\n",
    "energies = energies.reshape(2,N).T # in i-th column j-th row is the energy of curve\n",
    "# connecting p_j and b_i \n",
    "loss_dist2center = (weights*energies).sum()\n",
    "\n",
    "#loss_dist2center = manifold.curve_energy(multi_octopus(t)).mean()\n",
    "\n",
    "# these are euclidean distanses between points which are the starting points\n",
    "# we want it to be zero! (same starting point)\n",
    "#loss_centers = (multi_octopus(t)[:-2,-1] - multi_octopus(t)[2:,-1]).norm().square() \n",
    "loss_centers = 0.\n",
    "for s in range(k):\n",
    "    # just compute values in the end points!!\n",
    "    loss_centers += (multi_octopus(t)[s*N:(s+1)*N,-1] - multi_octopus(t)[s*N:(s+1)*N,-1].roll(shifts=1,dims=0)).square().mean()\n",
    "# these are endpoints of pathes to same baricenters\n",
    "\n",
    "loss = lambda_centers*loss_centers + loss_dist2center\n",
    "\n",
    "loss.backward()\n",
    "print(f\"loss:{loss.item():.3f}, loss_centers:{loss_centers.item():.3f}, loss_dist2center:{loss_dist2center.item():.3f}\")\n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(multi_octopus.parameters(), 1e+1)\n",
    "torch.nn.utils.clip_grad_norm_(weights, 1e-1) #clip weights gradients harder\n",
    "\n",
    "opt.step()\n",
    "\n",
    "# weights clamp and renormalization\n",
    "\n",
    "with torch.no_grad():\n",
    "    weights.clamp_(min=0.,max=1.)\n",
    "    normalized_weights = torch.nn.functional.normalize(weights, p=1, dim=1)\n",
    "\n",
    "    # if weights become (0,0) make them (1/2,1/2)\n",
    "    normalized_weights += (1 - normalized_weights.norm(p=1,dim=1)).repeat(2,1).T\n",
    "    normalized_weights = torch.nn.functional.normalize(normalized_weights, p=1, dim=1)\n",
    "\n",
    "    weights.copy_(normalized_weights)\n",
    "    \n",
    "    # weights = torch.nn.functional.normalize(weights,p=1,dim=1) \n",
    "    \n",
    "    # this should not be used as it creats a new tensor and kills \n",
    "    # previous grad tracking as it is used under torch.no_grad()\n",
    "print(\"weights:\\n\",weights)\n",
    "print(\"weights gradients:\\n\",weights.grad)\n",
    "print(\"energies:\\n\",energies)\n",
    "multi_octopus.plot()\n",
    "plt.show()\n",
    "\n",
    "#training_loop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in multi_octopus.parameters():\n",
    "    print(\"lala\",param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def training_loop(num_epochs: int,d=2):\n",
    "    gradient_norms = []\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Compute energies\n",
    "        energies = manifold.curve_energy(multi_octopus(t), reduction=None)\n",
    "        energies = energies.reshape(k, N).T  # Shape adjustment\n",
    "        loss_dist2center = (weights * energies).norm()/(N*k) #was sqrt and grad was exploding!\n",
    "        #loss_dist2center = energies.mean()\n",
    "\n",
    "        # Compute loss for centers\n",
    "        loss_centers = 0.0\n",
    "        multi_octopus_leg_ends = multi_octopus(torch.ones(1))  # Compute once to avoid repetition\n",
    "        for s in range(k):\n",
    "            start_points = multi_octopus_leg_ends[s * N:(s + 1) * N]\n",
    "            rolled_start_points = start_points.roll(shifts=epoch, dims=0)\n",
    "            loss_centers += (start_points - rolled_start_points).square().mean()\n",
    "        \n",
    "        #weights sum up to 1\n",
    "       \n",
    "        #loss_weights_constraint = (weights.norm(p=1,dim=1)- torch.ones(N)).square().mean()\n",
    "        #loss_weights_constraint += (nn.ReLU()(torch.zeros(N,2) - weights) + nn.ReLU()(weights - torch.ones(N,2))).mean()\n",
    "\n",
    "        # Total loss\n",
    "        loss = lambda_centers * loss_centers + loss_dist2center \n",
    "        #+ loss_weights_constraint \n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect gradient norms\n",
    "        grad_norm = 0.0\n",
    "        for param in multi_octopus.parameters():\n",
    "            grad_norm += param.grad.norm().item()\n",
    "        gradient_norms.append(grad_norm)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Gradient clipping\n",
    "        # The algorithm results are very sensible to clipping parameters \n",
    "        #torch.nn.utils.clip_grad_norm_(multi_octopus.parameters(), 1e1)\n",
    "        torch.nn.utils.clip_grad_norm_(weights, 1e0)\n",
    "\n",
    "        # Optimization step\n",
    "        opt.step()\n",
    "\n",
    "        # Weights clamp and renormalization\n",
    "        with torch.no_grad():\n",
    "            weights.clamp_(min=0.0, max=1.0)\n",
    "            normalized_weights = torch.nn.functional.normalize(weights, p=1, dim=1)\n",
    "            \n",
    "            # if weights become (0,0) make them (1/2,1/2)\n",
    "            normalized_weights += (1 - normalized_weights.norm(p=1,dim=1)).repeat(d,1).T\n",
    "            #normalized_weights = torch.nn.functional.normalize(normalized_weights, p=1, dim=1)\n",
    "\n",
    "            weights.copy_(normalized_weights)  # Ensure weights retain gradients\n",
    "        \n",
    "        # Logging\n",
    "        print(\"frechet means:\", {multi_octopus_leg_ends[0]}, multi_octopus_leg_ends[N])\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - loss: {loss.item():.3f}, loss_centers: {loss_centers.item():.3f},loss_dist2center: {loss_dist2center.item():.3f},grad_norm: {grad_norm:.3f}\")\n",
    "\n",
    "    # Plot gradient norms\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_list, label='loss')\n",
    "    plt.plot(gradient_norms, label='Gradient Norms')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('losses')\n",
    "    plt.title('Gradient Norms During Training')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_octopus = Octopus(points.repeat(k,1),init_centers)\n",
    "#multi_octopus = CubicSpline(points.repeat(k,1),init_centers) # fixed means\n",
    "weights = nn.Parameter((1/k)*torch.ones(N,k))\n",
    "multi_octopus.register_parameter(\"leg_weights\",weights)\n",
    "\n",
    "lambda_centers = 1e3 # huge weight\n",
    "print(lambda_centers)\n",
    "#optimizer choice\n",
    "\n",
    "#opt = torch.optim.Adam(multi_octopus.parameters(), lr=0.2e-2)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(multi_octopus.parameters(), lr=1e-2)\n",
    "loss = training_loop(num_epochs=50)\n",
    "multi_octopus.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_octopus.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in multi_octopus.named_parameters():\n",
    "    print(name,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
