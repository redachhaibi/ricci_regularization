{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb61206",
   "metadata": {},
   "source": [
    "NB! This is an old notebook. It contains a wrong (very unprecise) way of computing Scalar curvature of the latent space with f.d. formulas used for computing derivatives. Has to be redone!\n",
    "\n",
    "The autoencoder (AE) consists of the encoder $\\Phi$ and the decoder $\\Psi$.\n",
    "The latent space of the AE is $R^d$. We define a Riemannian metric in a local chart of the latent space as the pull-back of the Euclidean metric in the output space $R^D$ by the decoder function $\\Psi$ of the AE:\n",
    "\\begin{equation*}\n",
    "    g = \\nabla \\Psi ^* \\nabla \\Psi   \n",
    "\\end{equation*}.\n",
    "\n",
    "The notebook contains:\n",
    "1) Loading weights of a pre-trained convolutional AE and plotting its latent space: point plot and manifold plot. If \"violent_saving\" == True, plots are saved locally.\n",
    "2) Auxillary tensors involving higher order derivatives of the decoder $\\Psi$ are computed with f.d.: metric $g$ and its derivatives, Riemann tensor $R^{i}_{jkl}$, Ricci tensor $R_{ij}$ and scalar curvature.\n",
    "3) Geodesics shooting via Runge-Kutta approximation. A single plot with a scalar curvature heatmap and geodesics on it is constructed.\n",
    "4) Prototype of metric evolution by Ricci flow equation \n",
    "\n",
    "NB! by default the metric $g$ is the pull-back by the decoder as described above. But one can use any custom metric by manually setting it in \"specific_metric\" function, that computes the metric matrix at a point $u\\in \\mathbb{R}: \\ g(u)$ given the local coordinates of the point $u$ in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import ricci_regularization\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e71c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../experiments/MNIST_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/MNIST01_exp7_config.yaml', 'r') as yaml_file:\n",
    "#with open('../../experiments/Swissroll_exp4_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "violent_saving = False # if False it will not save plots\n",
    "\n",
    "d = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0cee7",
   "metadata": {},
   "source": [
    "# Loading data and nn weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"]\n",
    ")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")\n",
    "additional_path=\"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ec95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = yaml_config[\"experiment\"][\"name\"]\n",
    "\n",
    "#Path_pictures = yaml_config[\"experiment\"][\"path\"]\n",
    "Path_pictures = additional_path + \"../experiments/\" + yaml_config[\"experiment\"][\"name\"]\n",
    "if violent_saving == True:\n",
    "    # Check and create directories based on configuration\n",
    "    if not os.path.exists(Path_pictures):  # Check if the picture path does not exist\n",
    "        os.mkdir(Path_pictures)  # Create the directory for plots if not yet created\n",
    "        print(f\"Created directory: {Path_pictures}\")  # Print directory creation feedback\n",
    "    else:\n",
    "        print(f\"Directiry already exists: {Path_pictures}\")\n",
    "\n",
    "curv_w = yaml_config[\"loss_settings\"][\"lambda_curv\"]\n",
    "\n",
    "dataset_name = yaml_config[\"dataset\"][\"name\"]\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "# D is the dimension of the dataset\n",
    "if dataset_name in [\"MNIST01\", \"Synthetic\"]:\n",
    "    # k from the JSON configuration file is the number of classes\n",
    "    #k = yaml_config[\"dataset\"][\"k\"]\n",
    "    k = len(yaml_config[\"dataset\"][\"selected_labels\"])\n",
    "    selected_labels = yaml_config[\"dataset\"][\"selected_labels\"]\n",
    "elif dataset_name == \"MNIST\":\n",
    "    k = 10\n",
    "print(\"Experiment name:\", experiment_name)\n",
    "print(\"Plots saved at:\", Path_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize the two networks\n",
    "\n",
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config, additional_path = additional_path)\n",
    "\n",
    "torus_ae = torus_ae.to(\"cpu\")\n",
    "\n",
    "print(f\"AE weights loaded successfully from {Path_ae_weights}.\")\n",
    "\n",
    "encoder = torus_ae.encoder_torus\n",
    "decoder = torus_ae.decoder_torus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d2eabc",
   "metadata": {},
   "source": [
    "# Using mini-grids + minimal verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f906d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_grid(center: torch.Tensor, h: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a 7x7 mini-grid around a given center tensor with step size h.\n",
    "\n",
    "    Args:\n",
    "        center (torch.Tensor): A tensor representing the center of the grid (2D point).\n",
    "        h (float): The step size between grid points. Default is 1.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 7x7 grid of shape (7, 7, 2) where each element is a coordinate.\n",
    "    \"\"\"\n",
    "    # Create a 7x7 grid of relative coordinates (i, j) scaled by step size h\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "    \n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    \n",
    "    # Add the center coordinate to every point in the grid\n",
    "    mini_grid = grid + center.unsqueeze(0).unsqueeze(0)  # Broadcasting center to grid shape\n",
    "    \n",
    "    return mini_grid\n",
    "\n",
    "def build_mini_grid_batch(centers: torch.Tensor, h: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a batch of mini-grids centered at the given batch of points.\n",
    "    \n",
    "    Args:\n",
    "        centers (torch.Tensor): A 2D tensor with shape (N, 2) representing N centers.\n",
    "        grid_size (int): The size of the mini-grid (grid_size x grid_size).\n",
    "        h (float): The step size for the grid.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A batch of mini-grids of shape (N, grid_size * grid_size, 2).\n",
    "    \"\"\"\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "\n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    mini_grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    mini_grid = mini_grid.reshape(49,2) # Shape: (49, 2)\n",
    "    # Expand dimensions to match the number of centers\n",
    "    mini_grid = mini_grid.unsqueeze(0)  # shape: (1, grid_size * grid_size, 2)\n",
    "\n",
    "    # Broadcast the centers to create the batch\n",
    "    centers = centers.unsqueeze(1)  # shape: (N, 1, 2)\n",
    "\n",
    "    # Add the centers to the mini-grid points\n",
    "    batch_minigrids = mini_grid + centers  # shape: (N, grid_size * grid_size, 2)\n",
    "    return batch_minigrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(10,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)   \n",
    "\n",
    "print(\"batch of grids built correctly:\",torch.equal( batch_minigrids[:,24,:], centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2292ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(batch_minigrids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07437d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fd_batch_minigrids(batch_minigrids, function):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "    psi = function(batch_minigrids)\n",
    "    psi_next_x =  psi.roll(-1,1)\n",
    "    psi_prev_x =  psi.roll(1,1)\n",
    "    psi_next_y =  psi.roll(-7,1)\n",
    "    psi_prev_y =  psi.roll(7,1)\n",
    "\n",
    "    dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "    E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "    F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "    G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "    metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "    metric = metric.view(-1, 7 * 7, 2, 2)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48237fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric_fd_batch_minigrids(batch_minigrids, decoder)\n",
    "metric[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_by_x_minigrids(tensor_on_batch_minigrids, h):\n",
    "    tensor_next_x =  tensor_on_batch_minigrids.roll(-7,1)\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids.roll(7,1)\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids(tensor_on_batch_minigrids, h):\n",
    "    psi_next_y =  tensor_on_batch_minigrids.roll(-1,1)\n",
    "    psi_prev_y =  tensor_on_batch_minigrids.roll(1,1)\n",
    "    dpsidy = (psi_next_y - psi_prev_y)/(2*h)\n",
    "    return dpsidy\n",
    "\n",
    "def metric_der_fd_batch_minigrids(batch_minigrids, function):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "    metric = metric_fd_batch_minigrids(batch_minigrids, \n",
    "                    function = function)\n",
    "    dg_dx_fd = diff_by_x_minigrids(metric, h = h)\n",
    "    dg_dy_fd = diff_by_y_minigrids(metric, h = h)\n",
    "    dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n",
    "    return dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der_fd_batch_minigrids(batch_minigrids, decoder)[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e89c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_der_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_inv_batch_minigrids(batch_minigrids, function, eps=0.0):\n",
    "    g = metric_fd_batch_minigrids(batch_minigrids, function)\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "    return g_inv\n",
    "\n",
    "#metric_inv_jacfd_vmap = torch.func.vmap(metric_inv_fd)\n",
    "\n",
    "def Ch_fd_batch_minigrids (batch_minigrids, function, eps = 0.0):\n",
    "    g_inv = metric_inv_batch_minigrids(batch_minigrids,function,\n",
    "                                       eps=eps)\n",
    "    dg = metric_der_fd_batch_minigrids(batch_minigrids,function)\n",
    "    Ch = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              )\n",
    "    return Ch\n",
    "#Ch_fd_vmap = torch.func.vmap(Ch_fd)\n",
    "\n",
    "def Ch_der_fd_batch_minigrids (grid, function, eps=0.0):\n",
    "    h = (batch_minigrids[0,1] - batch_minigrids[0,0]).norm()\n",
    "\n",
    "    Ch = Ch_fd_batch_minigrids(grid, function=function, eps=eps)\n",
    "    dChdx = diff_by_x_minigrids(Ch, h)\n",
    "    dChdy = diff_by_y_minigrids(Ch, h)\n",
    "    dCh = torch.cat((dChdx.unsqueeze(-1), dChdy.unsqueeze(-1)), dim = -1)\n",
    "    return dCh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_der_fd_batch_minigrids(batch_minigrids, decoder)[7][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af305a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Ch_der_jacfwd(centers[7],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemann curvature tensor (3,1)\n",
    "def Riem_fd_batch_minigrids(u, function,eps=0.0):\n",
    "    Ch = Ch_fd_batch_minigrids(u, function, eps=eps)\n",
    "    Ch_der = Ch_der_fd_batch_minigrids(u, function, eps=eps)\n",
    "\n",
    "    Riem = torch.einsum(\"bgiljk->bgijkl\",Ch_der) - torch.einsum(\"bgikjl->bgijkl\",Ch_der)\n",
    "    Riem += torch.einsum(\"bgikp,bgplj->bgijkl\", Ch, Ch) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Ch, Ch)\n",
    "    return Riem\n",
    "\n",
    "def Ric_fd_batch_minigrids(u, function, eps=0.0):\n",
    "    Riemann = Riem_fd_batch_minigrids(u, function, eps=eps)\n",
    "    Ric = torch.einsum(\"bgcscr->bgsr\",Riemann)\n",
    "    return Ric\n",
    "\n",
    "def Sc_fd_batch_minigrids_slow (u, function, eps = 0.0):\n",
    "    Ricci = Ric_fd_batch_minigrids(u, function=function,eps=eps)\n",
    "    metric_inv = metric_inv_batch_minigrids(u,function=function, eps=eps)\n",
    "    Sc = torch.einsum('bgsr,bgsr->bg',metric_inv,Ricci)\n",
    "    return Sc\n",
    "\n",
    "\n",
    "# REDO this\n",
    "\n",
    "def diff_by_x_minigrids_fast(tensor_on_batch_minigrids, h, minigrid_side):\n",
    "    shape = list(tensor_on_batch_minigrids.shape)\n",
    "    batch_size = shape[0]\n",
    "    tensor_on_batch_minigrids_matrix = tensor_on_batch_minigrids.reshape(batch_size, minigrid_side, minigrid_side,-1)\n",
    "    tensor_next_x =  tensor_on_batch_minigrids_matrix[:,2:,1:-1,:]\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids_matrix[:,:-2,1:-1,:]\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    #proper shaping\n",
    "    shape[1] = (minigrid_side - 2)**2\n",
    "    tensor_dx = tensor_dx.reshape(shape)\n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids_fast(tensor_on_batch_minigrids, h, minigrid_side):\n",
    "    # unflatten the minigrid grid\n",
    "    shape = list(tensor_on_batch_minigrids.shape)\n",
    "    batch_size = shape[0]\n",
    "    tensor_on_batch_minigrids_matrix = tensor_on_batch_minigrids.reshape(batch_size, minigrid_side, minigrid_side,-1)\n",
    "    # compute shifts\n",
    "    tensor_next_y =  tensor_on_batch_minigrids_matrix[:,1:-1,2:,:]\n",
    "    tensor_prev_y =  tensor_on_batch_minigrids_matrix[:,1:-1,:-2:]\n",
    "    tensor_dy = (tensor_next_y - tensor_prev_y)/(2*h)\n",
    "    #proper shaping\n",
    "    shape[1] = (minigrid_side - 2)**2\n",
    "    tensor_dy = tensor_dy.reshape(shape)\n",
    "    return tensor_dy\n",
    "\n",
    "\n",
    "def metric_fd_batch_minigrids(batch_minigrids, function, h=0.01):\n",
    "    \n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = ( psi.roll(-1,1) - psi.roll(1,1) )/(2 * h)\n",
    "    dpsidy = ( psi.roll(-7,1) - psi.roll(7,1) )/(2 * h)\n",
    "    \n",
    "    E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "    F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "    G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "    metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "    metric = metric.view(-1, 7 * 7, 2, 2)\n",
    "    return metric\n",
    "\n",
    "def metric_fd_batch_minigrids_fast(batch_minigrids, function, h=0.01):\n",
    "    \n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = diff_by_y_minigrids_fast(psi, h, minigrid_side=7)\n",
    "    dpsidy = diff_by_x_minigrids_fast(psi, h, minigrid_side=7)\n",
    "    \n",
    "    E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "    F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "    G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)\n",
    "\n",
    "    metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "    metric = metric.view(-1, 5 * 5, 2, 2)\n",
    "    return metric\n",
    "\n",
    "\n",
    "def Sc_fd_batch_minigrids (centers, function, h=0.01, eps = 0.0):\n",
    "    \n",
    "    #create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "    #compute metric\n",
    "    g = metric_fd_batch_minigrids(batch_minigrids, function, h)\n",
    "    #compute inverse\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps * torch.eye(d, device = device))\n",
    "    #compute metric derivatives\n",
    "    dg_dx_fd = diff_by_x_minigrids(g, h = h)\n",
    "    dg_dy_fd = diff_by_y_minigrids(g, h = h)\n",
    "    del g\n",
    "    dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n",
    "    del dg_dx_fd, dg_dy_fd\n",
    "    #compute Christoffel symbols\n",
    "    Christoffel = 0.5 * (torch.einsum('bgim,bgmkl->bgikl', g_inv, dg) +\n",
    "              torch.einsum('bgim,bgmlk->bgikl', g_inv, dg) -\n",
    "              torch.einsum('bgim,bgklm->bgikl', g_inv, dg)\n",
    "              )\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    #dChristoffel_dx = diff_by_x_minigrids_fast(Christoffel, h,minigrid_side=7)\n",
    "    #dChristoffel_dy = diff_by_y_minigrids_fast(Christoffel, h, minigrid_side=7)\n",
    "    \n",
    "    dChristoffel_dx = diff_by_x_minigrids(Christoffel, h)\n",
    "    dChristoffel_dy = diff_by_y_minigrids(Christoffel, h)\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1)\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    #Compute Riemann tensor\n",
    "    #here we only need christoffel at centers\n",
    "    Riemann = torch.einsum(\"bgiljk->bgijkl\", dChristoffel) - torch.einsum(\"bgikjl->bgijkl\", dChristoffel)\n",
    "    Riemann += torch.einsum(\"bgikp,bgplj->bgijkl\", Christoffel, Christoffel) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Christoffel, Christoffel)\n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    Ricci = torch.einsum(\"bgcscr->bgsr\", Riemann)\n",
    "    del Riemann, \n",
    "    #Scalar curvature\n",
    "    Sc = torch.einsum('bgsr,bgsr->bg', g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc\n",
    "\n",
    "def Sc_fd_batch_minigrids_fast (centers, function, h=0.01, eps = 0.0):\n",
    "    \n",
    "    #create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "    #compute metric\n",
    "    g = metric_fd_batch_minigrids_fast(batch_minigrids, function, h)\n",
    "    #compute inverse\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "    #compute metric derivatives\n",
    "    dg_dx_fd = diff_by_x_minigrids(g, h = h)\n",
    "    dg_dy_fd = diff_by_y_minigrids(g, h = h)\n",
    "    del g\n",
    "    dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n",
    "    del dg_dx_fd, dg_dy_fd\n",
    "    #compute Christoffel symbols\n",
    "    Christoffel = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "              torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "              torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "              )\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    \n",
    "    dChristoffel_dx = diff_by_x_minigrids(Christoffel, h)\n",
    "    dChristoffel_dy = diff_by_y_minigrids(Christoffel, h)\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1)\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    #Compute Riemann tensor\n",
    "    #here we only need christoffel at centers\n",
    "    Riemann = torch.einsum(\"bgiljk->bgijkl\",dChristoffel) - torch.einsum(\"bgikjl->bgijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bgikp,bgplj->bgijkl\", Christoffel, Christoffel) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Christoffel, Christoffel)\n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    Ricci = torch.einsum(\"bgcscr->bgsr\",Riemann)\n",
    "    del Riemann, \n",
    "    #Scalar curvature\n",
    "    Sc = torch.einsum('bgsr,bgsr->bg',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e298dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_grid_batch(centers: torch.Tensor, h: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Builds a batch of mini-grids centered at the given batch of points.\n",
    "    \n",
    "    Args:\n",
    "        centers (torch.Tensor): A 2D tensor with shape (N, 2) representing N centers.\n",
    "        grid_size (int): The size of the mini-grid (grid_size x grid_size).\n",
    "        h (float): The step size for the grid.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A batch of mini-grids of shape (N, grid_size * grid_size, 2).\n",
    "    \"\"\"\n",
    "    offset = torch.arange(-3, 4) * h  # Relative offsets from the center (-3h, -2h, ..., 3h)\n",
    "    grid_x, grid_y = torch.meshgrid(offset, offset, indexing='ij')  # 7x7 grid for x and y\n",
    "\n",
    "    # Stack the coordinates (x, y) together and add to the center\n",
    "    mini_grid = torch.stack([grid_x, grid_y], dim=-1).float()  # Shape: (7, 7, 2)\n",
    "    mini_grid = mini_grid.reshape(49,2) # Shape: (49, 2)\n",
    "    # Expand dimensions to match the number of centers\n",
    "    mini_grid = mini_grid.unsqueeze(0)  # shape: (1, grid_size * grid_size, 2)\n",
    "\n",
    "    # Broadcast the centers to create the batch\n",
    "    centers = centers.unsqueeze(1)  # shape: (N, 1, 2)\n",
    "\n",
    "    # Add the centers to the mini-grid points\n",
    "    batch_minigrids = mini_grid + centers  # shape: (N, grid_size * grid_size, 2)\n",
    "\n",
    "    d = centers.shape[-1]\n",
    "    batch_size = centers.shape[0]\n",
    "    batch_minigrids = batch_minigrids.reshape(batch_size, 7, 7, d) # shape batch_size * 7 * 7 * d\n",
    "    return batch_minigrids\n",
    "\n",
    "def diff_by_x_minigrids_optimal(tensor_on_batch_minigrids, h):\n",
    "    # entry of shape batch_size * minigrid_side * minigrid_side * something\n",
    "    tensor_next_x =  tensor_on_batch_minigrids[:,2:,1:-1]\n",
    "    tensor_prev_x =  tensor_on_batch_minigrids[:,:-2,1:-1]\n",
    "    tensor_dx = (tensor_next_x - tensor_prev_x)/(2*h)\n",
    "    return tensor_dx\n",
    "\n",
    "def diff_by_y_minigrids_optimal(tensor_on_batch_minigrids, h):\n",
    "    # entry of shape batch_size * minigrid_side * minigrid_side * something\n",
    "    tensor_next_y =  tensor_on_batch_minigrids[:,1:-1,2:]\n",
    "    tensor_prev_y =  tensor_on_batch_minigrids[:,1:-1,:-2]\n",
    "    tensor_dy = (tensor_next_y - tensor_prev_y)/(2*h)\n",
    "    return tensor_dy\n",
    "\n",
    "\n",
    "def metric_fd_batch_minigrids_optimal(centers, function, h=0.01):\n",
    "    \n",
    "    batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = diff_by_x_minigrids_optimal(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsidy = diff_by_y_minigrids_optimal(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) # shape batch_size * 5 * 5 * D * 2\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    metric = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi)\n",
    "    return metric\n",
    "\n",
    "def Sc_fd_batch_minigrids_optimal (centers, function, h=0.01, eps = 0.0):\n",
    "    # d is latent dimension\n",
    "    d = centers.shape[-1]\n",
    "    #create a batch of minigrids with given centers and step h\n",
    "    batch_minigrids = build_mini_grid_batch(centers, h) # shape batch_size * 7 * 7 * d\n",
    "#    batch_minigrids = batch_minigrids.reshape(batch_minigrids.shape[0], 7, 7, d) # shape batch_size * 7 * 7 * d\n",
    "    psi = function(batch_minigrids)\n",
    "    dpsidx = diff_by_x_minigrids_optimal(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsidy = diff_by_y_minigrids_optimal(psi, h) # shape batch_size * 5 * 5 * D\n",
    "    dpsi = torch.cat(( dpsidx.unsqueeze(-1), dpsidy.unsqueeze(-1) ), -1) # shape batch_size * 5 * 5 * D * d\n",
    "    \n",
    "    #compute metric\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, D is output of psi dimension, i,j are local coordinates\n",
    "    g = torch.einsum('bghDi,bghDj->bghij', dpsi,dpsi) # shape batch_size * 5 * 5 * d * d\n",
    "\n",
    "    #compute inverse\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device)) # shape batch_size * 5 * 5 * d * d\n",
    "    #cutting the shape of g_inv\n",
    "    g_inv = g_inv[:,1:-1,1:-1] # shape batch_size * 3 * 3 * d * d\n",
    "\n",
    "    #compute metric derivatives\n",
    "    dg_dx = diff_by_x_minigrids_optimal(g, h)\n",
    "    dg_dy = diff_by_y_minigrids_optimal(g, h)\n",
    "    del g\n",
    "    dg = torch.cat((dg_dx.unsqueeze(-1), dg_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg_dx, dg_dy\n",
    "\n",
    "    #compute Christoffel symbols\n",
    "    #b is batch_size, g,h are coordinates on the minigrid, i, m, k, l are local coordinates\n",
    "    Christoffel = 0.5*(torch.einsum('bghim,bghmkl->bghikl',g_inv,dg)+\n",
    "              torch.einsum('bghim,bghmlk->bghikl',g_inv,dg)-\n",
    "              torch.einsum('bghim,bghklm->bghikl',g_inv,dg)\n",
    "              ) # shape batch_size * 3 * 3 * d * d * d\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    \n",
    "    dChristoffel_dx = diff_by_x_minigrids_optimal(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "    dChristoffel_dy = diff_by_y_minigrids_optimal(Christoffel, h) # shape batch_size * 1 * 1 * d * d * d\n",
    "\n",
    "    dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                              dChristoffel_dy.unsqueeze(-1)), dim = -1) # shape batch_size * 1 * 1 * d * d * d * d\n",
    "    del dChristoffel_dx, dChristoffel_dy\n",
    "    # squeezing since we only have values at centers of minigrids (one point)\n",
    "    dChristoffel = dChristoffel.squeeze() # shape batch_size * d * d * d * d\n",
    "    \n",
    "    #Compute Riemann tensor\n",
    "    #here we only need christoffels and derivatives at centers\n",
    "    Christoffel = Christoffel[:,1:-1,1:-1].squeeze() # shape batch_size * d * d * d\n",
    "    #b is batch_size i, j, k, l, p are local coordinates\n",
    "    Riemann = torch.einsum(\"biljk->bijkl\",dChristoffel) - torch.einsum(\"bikjl->bijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"bikp,bplj->bijkl\", Christoffel, Christoffel) - torch.einsum(\"bilp,bpkj->bijkl\", Christoffel, Christoffel)\n",
    "    # Riemann shape: batch_size * d * d * d\n",
    "    \n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    #b is batch_size c, s, r are local coordinates\n",
    "    Ricci = torch.einsum(\"bcscr->bsr\",Riemann)\n",
    "    del Riemann\n",
    "\n",
    "    #Compute scalar curvature\n",
    "    #we only need inverse of the metric at one central point:\n",
    "    g_inv = g_inv[:,1:-1,1:-1].squeeze() # shape batch_size * d * d\n",
    "    #b is batch_size s, r are local coordinates\n",
    "    Sc = torch.einsum('bsr,bsr->b',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc = Sc_fd_batch_minigrids_optimal(centers, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50583fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Sc_jacfwd(centers[7], function = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd_batch_minigrids(batch_minigrids,decoder)[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd_batch_minigrids_fast(batch_minigrids,decoder)[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.\n",
    "#create a batch of minigrids with given centers and step h\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "#compute metric\n",
    "g = metric_fd_batch_minigrids_fast(batch_minigrids, decoder, h)\n",
    "#compute inverse\n",
    "d = g.shape[-1]\n",
    "device = g.device\n",
    "g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "#compute metric derivatives\n",
    "dg_dx_fd = diff_by_x_minigrids_fast(g, h = h, minigrid_side=5)\n",
    "dg_dy_fd = diff_by_y_minigrids_fast(g, h = h, minigrid_side=5)\n",
    "del g\n",
    "dg = torch.cat((dg_dx_fd.unsqueeze(-1), dg_dy_fd.unsqueeze(-1)), dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa957f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ababe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch = Ch_fd_batch_minigrids(batch_minigrids, decoder).reshape(10,7,7,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric_fd_batch_minigrids_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_by_x_minigrids_optimal(Ch,h)[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Ch_der_jacfwd_vmap(centers, function = decoder)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f762cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97905d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_der_fd_batch_minigrids( batch_minigrids, decoder)[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dg_dx_fd, dg_dy_fd\n",
    "#compute Christoffel symbols\n",
    "Christoffel = 0.5*(torch.einsum('bgim,bgmkl->bgikl',g_inv,dg)+\n",
    "            torch.einsum('bgim,bgmlk->bgikl',g_inv,dg)-\n",
    "            torch.einsum('bgim,bgklm->bgikl',g_inv,dg)\n",
    "            )\n",
    "del dg\n",
    "#compute Christoffel symbols' derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefa19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dChristoffel_dx = diff_by_x_minigrids(Christoffel, h)\n",
    "dChristoffel_dy = diff_by_y_minigrids(Christoffel, h)\n",
    "\n",
    "dChristoffel = torch.cat((dChristoffel_dx.unsqueeze(-1),\n",
    "                            dChristoffel_dy.unsqueeze(-1)), dim = -1)\n",
    "del dChristoffel_dx, dChristoffel_dy\n",
    "#Compute Riemann tensor\n",
    "#here we only need christoffel at centers\n",
    "Riemann = torch.einsum(\"bgiljk->bgijkl\",dChristoffel) - torch.einsum(\"bgikjl->bgijkl\",dChristoffel)\n",
    "Riemann += torch.einsum(\"bgikp,bgplj->bgijkl\", Christoffel, Christoffel) - torch.einsum(\"bgilp,bgpkj->bgijkl\", Christoffel, Christoffel)\n",
    "del dChristoffel, Christoffel\n",
    "#Compute Ricci\n",
    "Ricci = torch.einsum(\"bgcscr->bgsr\",Riemann)\n",
    "del Riemann, \n",
    "#Scalar curvature\n",
    "Sc = torch.einsum('bgsr,bgsr->bg',g_inv,Ricci)\n",
    "del Ricci, g_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ab186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b9686be",
   "metadata": {},
   "source": [
    "## Computational time code breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889782cb",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 10\n",
    "\n",
    "batch_sizes = [32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "    current_batch_minigrids = batch_minigrids[:batch_size]\n",
    "\n",
    "    # Timing for metric_fd_batch_minigrids\n",
    "    time_metric_fd = timeit.timeit(\n",
    "        stmt=\"metric_fd_batch_minigrids(current_batch_minigrids, decoder, h)\",\n",
    "        setup=\"from __main__ import metric_fd_batch_minigrids, current_batch_minigrids, decoder, h\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_fd_batch_minigrids\n",
    "    time_sc_fd = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids(current_centers, decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"metric_fd_avg_time\": time_metric_fd / iterations,\n",
    "        \"Sc_fd_avg_time\": time_sc_fd / iterations,\n",
    "    })\n",
    "\n",
    "# Output the timing results\n",
    "for result in timing_results:\n",
    "    print(f\"Batch Size: {result['batch_size']}, Metric_fd_avg_time: {result['metric_fd_avg_time']:.6f} sec, \"\n",
    "          f\"Sc_fd_avg_time: {result['Sc_fd_avg_time']:.6f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea471c8",
   "metadata": {},
   "source": [
    "plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9867b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the batch sizes, metric_fd times, and Sc_fd times\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "metric_fd_times = [result['metric_fd_avg_time'] for result in timing_results]\n",
    "sc_fd_times = [result['Sc_fd_avg_time'] for result in timing_results]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, metric_fd_times, label='Metric $g$', marker='o')\n",
    "plt.plot(batch_sizes, sc_fd_times, label='Scalar curvature $R$', marker='s')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.title('Timing metric $g$ vs scalar curvature $R$ computation with f.d. for different batch sizes')\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_metric_Sc_minigrids.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(current_batch_minigrids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b4ee44",
   "metadata": {},
   "source": [
    " metric computation breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import torch\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 100\n",
    "\n",
    "batch_sizes = [32, 64, 128, 256, 512]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "minigrid_side = 7\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust batch_minigrids to match the current batch_size\n",
    "    current_batch_minigrids = batch_minigrids[:batch_size]\n",
    "    psi = decoder(current_batch_minigrids)\n",
    "\n",
    "    # Step 1: Time for decoder(batch_minigrids)\n",
    "    time_decoder = timeit.timeit(\n",
    "        stmt=\"psi = decoder(current_batch_minigrids)\",\n",
    "        setup=\"from __main__ import decoder, current_batch_minigrids\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Step 2: Time for psi + gradient computation using .roll()\n",
    "    time_roll = timeit.timeit(\n",
    "        stmt=\"\"\"\n",
    "psi_next_x = psi.roll(-1, 1)\n",
    "psi_prev_x = psi.roll(1, 1)\n",
    "psi_next_y = psi.roll(-minigrid_side, 1)\n",
    "psi_prev_y = psi.roll(minigrid_side, 1)\n",
    "dpsidx = (psi_next_x - psi_prev_x) / (2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y) / (2 * h)\n",
    "        \"\"\",\n",
    "        setup=\"from __main__ import decoder, current_batch_minigrids, minigrid_side, h, psi\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Step 3: Time for diff_by_x_minigrids_fast and diff_by_y_minigrids_fast\n",
    "    time_diff_fast = timeit.timeit(\n",
    "        stmt=\"\"\"\n",
    "diff_by_x_minigrids_fast(psi, h, minigrid_side)\n",
    "diff_by_y_minigrids_fast(psi, h, minigrid_side)\n",
    "        \"\"\",\n",
    "        setup=\"from __main__ import decoder, current_batch_minigrids, diff_by_x_minigrids_fast, diff_by_y_minigrids_fast, h, minigrid_side, psi\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Step 4: Time for metric_fd_batch_minigrids\n",
    "    time_metric_fd = timeit.timeit(\n",
    "        stmt=\"metric_fd_batch_minigrids(current_batch_minigrids, decoder, h)\",\n",
    "        setup=\"from __main__ import metric_fd_batch_minigrids, current_batch_minigrids, decoder, h\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"decoder_time\": time_decoder / iterations,\n",
    "        \"roll_time\": time_roll / iterations,\n",
    "        \"diff_fast_time\": time_diff_fast / iterations,\n",
    "        \"metric_fd_time\": time_metric_fd / iterations,\n",
    "    })\n",
    "\n",
    "# Output the timing results\n",
    "for result in timing_results:\n",
    "    print(f\"Batch Size: {result['batch_size']}, Decoder Time: {result['decoder_time']:.6f} sec, \"\n",
    "          f\"Roll Time: {result['roll_time']:.6f} sec, \"\n",
    "          f\"Diff Fast Time: {result['diff_fast_time']:.6f} sec, \"\n",
    "          f\"Metric_fd Time: {result['metric_fd_time']:.6f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9be9e",
   "metadata": {},
   "source": [
    "plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3483a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the batch sizes and times for plotting\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "decoder_times = [result['decoder_time'] for result in timing_results]\n",
    "roll_times = [result['roll_time'] for result in timing_results]\n",
    "diff_fast_times = [result['diff_fast_time'] for result in timing_results]\n",
    "metric_fd_times = [result['metric_fd_time'] for result in timing_results]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, decoder_times, label='evaluate Decoder(batch_minigrids)', marker='o')\n",
    "plt.plot(batch_sizes, roll_times, label='derivatives with .roll()', marker='s')\n",
    "plt.plot(batch_sizes, diff_fast_times, label='derivatives by cutting indices', marker='^')\n",
    "plt.plot(batch_sizes, metric_fd_times, label='evaluate metric', marker='x')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.title('Comparison of Execution Times for Different Operations')\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_metric_computation_minigrids.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(2500,2)\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791222ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = decoder(batch_minigrids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_next_x =  psi.roll(-1,1)\n",
    "psi_prev_x =  psi.roll(1,1)\n",
    "psi_next_y =  psi.roll(-7,1)\n",
    "psi_prev_y =  psi.roll(7,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36878729",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y)/(2 * h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e976bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpsidy[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e692797",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_by_x_minigrids_fast(psi, h, minigrid_side=7)\n",
    "diff_by_y_minigrids_fast(psi, h, minigrid_side=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = torch.einsum('bgD,bgD->bg',dpsidx, dpsidx)\n",
    "F = torch.einsum('bgD,bgD->bg',dpsidx, dpsidy)\n",
    "G = torch.einsum('bgD,bgD->bg',dpsidy, dpsidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "metric = metric.view(-1, 7 * 7, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05882a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd_batch_minigrids(batch_minigrids, decoder, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd_batch_minigrids(centers, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(5000,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)\n",
    "Ch = Ch_fd_batch_minigrids(batch_minigrids,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_by_y_minigrids_fast(Ch, h = 0.01,minigrid_side=7)[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f78672",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_by_y_minigrids(Ch, h = 0.01)[0][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = decoder(batch_minigrids)\n",
    "psi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959089b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ch_fd_batch_minigrids(batch_minigrids,decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4bf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_matrix = psi.reshape(-1,7,7,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd_batch_minigrids(batch_minigrids,decoder)[0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3380d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#psi_next_x = psi_matrix[:,:,1:,:]\n",
    "#print(psi_next_x)\n",
    "\n",
    "minigrid_side = 5\n",
    "psi = decoder(batch_minigrids)\n",
    "psi_matrix = psi.reshape(-1,7,7,D)\n",
    "#psi_next_x =  psi_matrix[:,:,2:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_x =  psi_matrix[:,:,:-2,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_next_y =  psi_matrix[:,2:,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "#psi_prev_y =  psi_matrix[:,:-2,:,:].reshape(-1, minigrid_side * minigrid_side, D)\n",
    "psi_next_x =  psi_matrix[:,1:-1,2:,:]\n",
    "psi_prev_x =  psi_matrix[:,1:-1,:-2,:]\n",
    "psi_next_y =  psi_matrix[:,2:,1:-1,:]\n",
    "psi_prev_y =  psi_matrix[:,:-2,1:-1,:]\n",
    "\n",
    "\n",
    "dpsidx = (psi_next_x - psi_prev_x)/(2 * h)\n",
    "dpsidy = (psi_next_y - psi_prev_y)/(2 * h)\n",
    "E = torch.einsum('bghD,bghD->bgh',dpsidx, dpsidx)\n",
    "F = torch.einsum('bghD,bghD->bgh',dpsidx, dpsidy)\n",
    "G = torch.einsum('bghD,bghD->bgh',dpsidy, dpsidy)\n",
    "\n",
    "metric = torch.cat((G.unsqueeze(-1), F.unsqueeze(-1), F.unsqueeze(-1), E.unsqueeze(-1)),-1)\n",
    "metric = metric.view(-1, minigrid_side * minigrid_side, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bde86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(psi[:,2:,:] - psi[:,:-2,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "psi[:,:-14,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7839bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.metric_jacfwd(centers[0], decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97256f3d",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c09f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(100,2)\n",
    "h = 0.01\n",
    "batch_minigrids = build_mini_grid_batch(centers, h)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_fd = Sc_fd_batch_minigrids(batch_minigrids, function=decoder)\n",
    "Sc_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers, function=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4130746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "\n",
    "# Define the number of iterations for averaging\n",
    "iterations = 10\n",
    "\n",
    "batch_sizes = [16, 32, 64, 128, 256]  # Different batch sizes to test\n",
    "\n",
    "# Initialize a list to hold timing results\n",
    "timing_results = []\n",
    "\n",
    "# Generate grid and centers based on the fixed numsteps\n",
    "h = 0.01  # Step size (arbitrary)\n",
    "centers = torch.randn(max(batch_sizes), 2)  # Example centers, random values\n",
    "# Generate batch mini-grids for the current numsteps\n",
    "batch_minigrids = build_mini_grid_batch(centers, h=h)\n",
    "\n",
    "# Loop through different batch sizes\n",
    "for batch_size in batch_sizes:\n",
    "    # Adjust centers and batch_minigrids to match the current batch_size\n",
    "    current_centers = centers[:batch_size]\n",
    "    current_batch_minigrids = batch_minigrids[:batch_size]\n",
    "\n",
    "    # Timing for Sc_fd\n",
    "    time_fd = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids_slow(current_batch_minigrids, function=decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids_slow, current_batch_minigrids, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_fd_fast\n",
    "    time_fd_fast = timeit.timeit(\n",
    "        stmt=\"Sc_fd_batch_minigrids_fast(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import Sc_fd_batch_minigrids_fast, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Timing for Sc_jacfwd\n",
    "    time_jacfwd = timeit.timeit(\n",
    "        stmt=\"ricci_regularization.Sc_jacfwd_vmap(current_centers, function=decoder)\",\n",
    "        setup=\"from __main__ import ricci_regularization, current_centers, decoder\",\n",
    "        number=iterations\n",
    "    )\n",
    "\n",
    "    # Append the results to the timing_results list\n",
    "    timing_results.append({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"Sc_fd_avg_time\": time_fd / iterations,\n",
    "        \"Sc_fd_fast_avg_time\": time_fd_fast / iterations,\n",
    "        \"Sc_jacfwd_avg_time\": time_jacfwd / iterations,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file\n",
    "with open(Path_pictures+'/timing_results_batch_minigrids.json', 'w') as f:\n",
    "    json.dump(timing_results, f, indent=4)\n",
    "\n",
    "# Print the timing results\n",
    "for result in timing_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "batch_sizes = [result['batch_size'] for result in timing_results]\n",
    "sc_fd_times = [result['Sc_fd_avg_time'] for result in timing_results]\n",
    "sc_fd_fast_times = [result['Sc_fd_fast_avg_time'] for result in timing_results]\n",
    "sc_jacfwd_times = [result['Sc_jacfwd_avg_time'] for result in timing_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average times for Sc_fd and Sc_jacfwd_vmap\n",
    "plt.plot(batch_sizes, sc_fd_times, marker='o', label='fd on mini_grids', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_fd_fast_times, marker='o', label='fd fast on mini_grids', linestyle='-')\n",
    "plt.plot(batch_sizes, sc_jacfwd_times, marker='s', label='jacfwd', linestyle='-')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.ylabel('Average Time (seconds)')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.title(f'Timing scalar curvature $R$ computation: fd on minigrids vs jacfwd')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Set x-ticks to be the actual batch size values\n",
    "plt.xticks(batch_sizes)  # Setting the x-ticks to match batch sizes\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(Path_pictures+'/timing_results_batch_minigrids.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb563d09",
   "metadata": {},
   "source": [
    "# faster jacfwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def Sc_jacfwd_fast (point, function, eps = 0.0):\n",
    "    \n",
    "    #compute metric\n",
    "    g = ricci_regularization.metric_jacfwd(point, function)\n",
    "    #compute inverse\n",
    "    d = g.shape[-1]\n",
    "    device = g.device\n",
    "    g_inv = torch.inverse(g + eps*torch.eye(d,device=device))\n",
    "    del g\n",
    "    \n",
    "    #compute metric derivatives\n",
    "\n",
    "    metric = functools.partial(ricci_regularization.metric_jacfwd, function=function)\n",
    "    dg = torch.func.jacfwd(metric)(point).squeeze()\n",
    "    # squeezing is needed to get rid of 1-dimentions \n",
    "    # occuring when using torch.func.jacfwd\n",
    "\n",
    "    #compute Christoffel symbols\n",
    "    Christoffel = 0.5*(torch.einsum('im,mkl->ikl',g_inv,dg)+\n",
    "              torch.einsum('im,mlk->ikl',g_inv,dg)-\n",
    "              torch.einsum('im,klm->ikl',g_inv,dg)\n",
    "              )\n",
    "    del dg\n",
    "    #compute Christoffel symbols' derivatives\n",
    "    \n",
    "    dChristoffel = torch.func.jacfwd( functools.partial(ricci_regularization.Ch_jacfwd, function=function,eps=eps) )(point).squeeze()\n",
    "\n",
    "    #Compute Riemann tensor\n",
    "    Riemann = torch.einsum(\"iljk->ijkl\",dChristoffel) - torch.einsum(\"ikjl->ijkl\",dChristoffel)\n",
    "    Riemann += torch.einsum(\"ikp,plj->ijkl\", Christoffel, Christoffel) - torch.einsum(\"ilp,pkj->ijkl\", Christoffel, Christoffel)\n",
    "    del dChristoffel, Christoffel\n",
    "    #Compute Ricci\n",
    "    Ricci = torch.einsum(\"cscr->sr\",Riemann)\n",
    "    del Riemann\n",
    "    #Scalar curvature\n",
    "    Sc = torch.einsum('sr,sr->',g_inv,Ricci)\n",
    "    del Ricci, g_inv\n",
    "    return Sc\n",
    "Sc_jacfwd_fast_vmap = torch.func.vmap(Sc_jacfwd_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.rand(10000,2)\n",
    "u = torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sc_jacfwd_fast_vmap(centers, function = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed21ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Sc_jacfwd_vmap(centers,function = decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f56535",
   "metadata": {},
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e960d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_fd_jacfwd_batch_minigrids(tensor_fd, tensor_jacfwd):\n",
    "    batch_size = tensor_fd.shape[0]\n",
    "    #finite differences\n",
    "    tensor_fd_central = tensor_fd[:, 24]\n",
    "\n",
    "    error = torch.functional.F.mse_loss(tensor_fd_central, tensor_jacfwd)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09672424",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fd = metric_fd_batch_minigrids(batch_minigrids, function=decoder)\n",
    "metric_jacfwd = ricci_regularization.metric_jacfwd_vmap(centers, function=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fd_jacfwd_batch_minigrids(metric_fd, metric_jacfwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fd_jacfwd_batch_minigrids(metric_fd, metric_jacfwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec825b0",
   "metadata": {},
   "source": [
    "# Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b221c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_values = np.logspace(-4, -1, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor_fd = Sc_fd_batch_minigrids(batch_minigrids, function= decoder)  # Simulate FD grid\n",
    "#tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(batch_minigrids,function= decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d70015",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "batch_size = 64  # Just as an example\n",
    "centers = torch.rand(batch_size, 2)\n",
    "batch_minigrids = build_mini_grid_batch(centers = centers, h = h)\n",
    "Sc_fd_batch_minigrids(batch_minigrids, function= decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# Assume tensor_jacfwd is some precomputed tensor (ground truth)\n",
    "batch_size = 128  # Just as an example\n",
    "centers = torch.rand(batch_size, 2)  # Simulated ground truth\n",
    "\n",
    "# We will compute tensor_fd with varying h\n",
    "h_values = np.logspace(-4, -1, 10)  # Step sizes in logarithmic scale from 1e-5 to 1e-1\n",
    "errors = []\n",
    "\n",
    "for h in h_values:\n",
    "    batch_minigrids = build_mini_grid_batch(centers = centers, h = h)\n",
    "    # Simulate tensor_fd by perturbing tensor_jacfwd with some finite difference approximation\n",
    "    tensor_fd = Sc_fd_batch_minigrids(batch_minigrids, function= decoder)  # Simulate FD grid\n",
    "    tensor_jacfwd = ricci_regularization.Sc_jacfwd_vmap(centers,function= decoder)\n",
    "    # Compute the error for this step size\n",
    "    error = error_fd_jacfwd_batch_minigrids(tensor_fd, tensor_jacfwd)\n",
    "    errors.append(error.item())  # Store the error as a scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot the error vs. h\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.loglog(h_values, errors, marker='o', label=\"MSE Error\")\n",
    "plt.xlabel('Step size (h)')\n",
    "plt.ylabel('Error (MSE)')\n",
    "plt.title('Error vs. Step Size for Finite Differences on minigrid for scalar curvature computation')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.savefig(Path_pictures+\"/fd_minigrid_error.pdf\", bbox_inches='tight', format = \"pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ed7132e93bf674294a86d7471c251a64840a87e0582b5a68a7249a63cee1cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
