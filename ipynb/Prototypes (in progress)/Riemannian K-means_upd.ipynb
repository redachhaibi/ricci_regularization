{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, yaml, os\n",
    "import ricci_regularization\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 #to make videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_experiment = '../../experiments/MNIST_Setting_3_config.yaml'\n",
    "with open(Path_experiment, 'r') as yaml_file:\n",
    "#with open('../experiments/Synthetic_Setting_1/Synthetic_Setting_1_config.yaml', 'r') as yaml_file:\n",
    "#with open('../experiments/Swissroll_exp5_config.yaml', 'r') as yaml_file:\n",
    "    yaml_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "# Load data loaders based on YAML configuration\n",
    "# Load data loaders based on YAML configuration\n",
    "dict = ricci_regularization.DataLoaders.get_dataloaders(\n",
    "    dataset_config=yaml_config[\"dataset\"],\n",
    "    data_loader_config=yaml_config[\"data_loader_settings\"],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print(\"Experiment results loaded successfully.\")\n",
    "train_loader = dict[\"train_loader\"]\n",
    "test_loader = dict[\"test_loader\"]\n",
    "test_dataset = dict.get(\"test_dataset\")  # Assuming 'test_dataset' is a key returned by get_dataloaders\n",
    "\n",
    "print(\"Data loaders created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torus_ae, Path_ae_weights = ricci_regularization.DataLoaders.get_tuned_nn(config=yaml_config,additional_path='../')\n",
    "\n",
    "print(\"AE weights loaded successfully.\")\n",
    "print(\"AE weights loaded from\", Path_ae_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder to store the PNG images\n",
    "shots_folder_name = \"/generated_pics\"\n",
    "shots_folder_adress = '../../experiments/'+yaml_config[\"experiment\"][\"name\"]+ shots_folder_name\n",
    "if not os.path.exists(shots_folder_adress):\n",
    "    os.makedirs(shots_folder_adress)\n",
    "    print(\"A folder created for saved images to create a gif at:\", shots_folder_adress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "K = 2#3 # number of clusters\n",
    "data = test_dataset.data\n",
    "N = 10#15 #len(data)\n",
    "m = 10 # intermediate points on every geodesic\n",
    "D = yaml_config[\"architecture\"][\"input_dim\"]\n",
    "d = yaml_config[\"architecture\"][\"latent_dim\"]\n",
    "\n",
    "# Limit dataset to the first n samples\n",
    "subset_indices = list(range(N))\n",
    "mnist_subset = torch.utils.data.Subset(data, subset_indices)\n",
    "dataloader = torch.utils.data.DataLoader(mnist_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# encoding into latent space\n",
    "torus_ae.cpu()\n",
    "torus_ae.eval()\n",
    "\n",
    "# Encode samples into latent space\n",
    "encoded_points = []\n",
    "with torch.no_grad():  # No need to compute gradients\n",
    "    for images in dataloader:\n",
    "#        print(images.shape)\n",
    "        latent = torus_ae.encoder2lifting( (images.reshape(-1, D)).to(torch.float32) )  # Pass images through the encoder\n",
    "        encoded_points.append(latent)\n",
    "encoded_points = torch.cat(encoded_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing initialization\n",
    "centers = ricci_regularization.initialize_centers(encoded_points, K, N)\n",
    "\n",
    "plt.scatter(encoded_points[:,0],encoded_points[:,1], label = \"encoded data\")\n",
    "plt.scatter(centers[:,0], centers[:,1], c=\"red\", label = \"centers\", marker='*', s = 60)\n",
    "plt.xlim(-torch.pi, torch.pi)\n",
    "plt.ylim(-torch.pi, torch.pi)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function and optimizer parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_interpolation_points_on_segments_connecting_centers2encoded_data(starting_points, final_points, num_aux_points =10):\n",
    "    \"\"\"\n",
    "    Connect every point in `starting_points` to every point in `final_points` with intermediate points.\n",
    "\n",
    "    Args:\n",
    "        starting_points (torch.Tensor): Tensor of shape (num_data_points, latent_dim) representing points.\n",
    "        final_points (torch.Tensor): Tensor of shape (num_clusters, latent_dim) representing center points.\n",
    "        num_aux_points (int): Number of intermediate points (including endpoints) per segment.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (num_data_points * num_clusters * num_aux_points, latent_dim) containing all intermediate points.\n",
    "    \"\"\"\n",
    "    # Check that the final dimensions of inputs match\n",
    "    if starting_points.shape[-1] != final_points.shape[-1] or final_points.shape[-1] != starting_points.shape[-1]:\n",
    "        raise ValueError(\n",
    "            f\"Mismatch in dimensions: 'starting_points' and 'final_points' must have the same final dimension. \"\n",
    "            f\"Got starting_points with shape {starting_points.shape}, final_points with shape {final_points.shape}. \"\n",
    "        )\n",
    "\n",
    "    # Generate interpolation parameters (num_aux_points values between 0 and 1)\n",
    "    t = torch.linspace(0, 1, steps=num_aux_points).to(starting_points.device).view(1, 1, num_aux_points, 1)  # Shape: (1, 1, num_aux_points, 1)\n",
    "\n",
    "    # Reshape starting_points and final_points for broadcasting\n",
    "    starting_points_expanded = starting_points.unsqueeze(1).unsqueeze(2)  # Shape: (num_starting_points, 1, 1, points_dim)\n",
    "    final_points_expanded = final_points.unsqueeze(0).unsqueeze(2)        # Shape: (1, num_final_points, 1, points_dim)\n",
    "\n",
    "    # Compute all intermediate points using linear interpolation\n",
    "    all_points_on_geodesics = starting_points_expanded + t * (final_points_expanded - starting_points_expanded)  # Shape: (num_data_points, num_clusters, num_aux_points, latent_dim)\n",
    "\n",
    "    # Select interpolation_points cutting of the starting and the final point for every segment\n",
    "    interpolation_points = all_points_on_geodesics[:,:,1:-1,:]\n",
    "    return interpolation_points\n",
    "\n",
    "def geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points):\n",
    "    \"\"\"\n",
    "    Constructs geodesics from parameters of the geodesics and end points. \n",
    "\n",
    "    Parameters:\n",
    "    - parameters_of_geodesics (torch.Tensor): Interpolation parameters with shape \n",
    "      (num_starting_points, num_clusters, num_interpolation_points, latent_dim).\n",
    "    - end_points (list of torch.Tensor): [starting_points, final_points], where:\n",
    "      - starting_points: Shape (num_starting_points, latent_dim).\n",
    "      - final_points: Shape (num_clusters, latent_dim).\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Complete geodesics with shape \n",
    "      (num_starting_points, num_clusters, num_interpolation_points + 2, latent_dim).\n",
    "    \"\"\"\n",
    "    # reading the shapes of the parameters\n",
    "    num_starting_points, num_clusters, num_interpolation_points, latent_dim = parameters_of_geodesics.shape\n",
    "    starting_points, final_points = end_points\n",
    "    # starting_points are usually encoded data\n",
    "    # final_points are usually cluster centers  \n",
    "\n",
    "    #expand starting_points\n",
    "    starting_points_expanded = starting_points.unsqueeze(1).unsqueeze(2) # Shape: (num_starting_points, 1, 1, latent_dim)\n",
    "    starting_points_expanded = starting_points_expanded.expand(num_starting_points, num_clusters , 1, latent_dim)\n",
    "    #expand final_points\n",
    "    final_points_expanded = final_points.unsqueeze(0).unsqueeze(2)  # Shape: (1, num_clusters, 1, latent_dim)\n",
    "    final_points_expanded = final_points_expanded.expand(num_starting_points, num_clusters , 1, latent_dim)\n",
    "    # concatenate the starting points, the interpolation_points and final_points  along the dimention associated interpolation_points\n",
    "    all_points_on_geodesics = torch.cat((starting_points_expanded, parameters_of_geodesics, final_points_expanded),dim=2) \n",
    "    return all_points_on_geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_of_geodesics = construct_interpolation_points_on_segments_connecting_centers2encoded_data(encoded_points, centers, num_aux_points=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points=[encoded_points, centers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.plot_octopus(geodesics, saving_folder=shots_folder_adress, suffix=0,verbose=True) \n",
    "# silent -> show_plot; verbose_mode aka -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite compute_energy(parameters_of_geodesics, end_points, decoder ) #seperate params from endpoints because the first are updated the second are not\n",
    "# geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points)\n",
    "# geodesics_from_parameters_schauder(parameters_of_geodesics, end_points)\n",
    "# keep the information about the geodesics parametrization mode as a parameter of all the functions: interpolating_points, schauder\n",
    "def compute_energy(parameters_of_geodesics, end_points, decoder=torus_ae.decoder_torus):\n",
    "    points_on_geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points)\n",
    "    # add option of schauder basis\n",
    "    decoded_points = decoder(points_on_geodesics)\n",
    "    computed_energy = (( decoded_points[:,:,1:,:] - decoded_points[:,:,:-1,:] ) ** 2 ).sum() # comute sum of Euclidean energies of all the curves in R^D\n",
    "    # make sure that optimization is parallelized\n",
    "    # Warning! the outpiut is the single scalar, i.e the sum of all the energies\n",
    "    return computed_energy\n",
    "\n",
    "def compute_lengths(parameters_of_geodesics, end_points, decoder=torus_ae.decoder_torus):\n",
    "    points_on_geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points)\n",
    "    # add option of schauder basis\n",
    "    #if points_on_geodesics.shape != torch.Size([num_data_points, num_classes, num_aux_points, latent_dim]):\n",
    "    #    points_on_geodesics = points_on_geodesics.unsqueeze(0)\n",
    "    decoded_points = decoder(points_on_geodesics)\n",
    "    tangent_vectors = decoded_points[:,:,1:,:] - decoded_points[:,:,:-1,:]\n",
    "    computed_lengths = torch.sqrt((tangent_vectors**2).sum(dim=(-2,-1))) # comute Euclidean compute_lengths of the curves in R^D\n",
    "    return computed_lengths\n",
    "loss_geodesics = compute_energy(parameters_of_geodesics=parameters_of_geodesics, end_points=[encoded_points, centers],decoder=torus_ae.decoder_torus)\n",
    "loss_geodesics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# version 0 without local charts update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.e-3 # Frechet mean learning rate #beta is learning_rate_frechet_mean\n",
    "learning_rate = 1.e-3 # learning_rate_geodesics\n",
    "num_iter_outer = 100 #10\n",
    "num_iter_inner = 15 # number of geodesics refinement interations per 1 Frechet mean update\n",
    "cluster_index_of_each_point = None\n",
    "meaningful_geodesics = None\n",
    "\n",
    "#loss_history = []\n",
    "meaningful_geodesics_loss_history = []\n",
    "meaningful_geodesics_loss_history_by_cluster = []\n",
    "norm_Frechet_mean_gradient_history = []\n",
    "\n",
    "# Initialize geodesic segments\n",
    "centers = ricci_regularization.initialize_centers(encoded_points, K, N) #centers -> initial_centers\n",
    "new_centers = torch.clone(centers) #-> current_centers\n",
    "parameters_of_geodesics = construct_interpolation_points_on_segments_connecting_centers2encoded_data(encoded_points, centers, num_aux_points=m)\n",
    "\n",
    "#segments = ricci_regularization.connect_centers2encoded_data_with_segments(encoded_points, centers, m) #initialize the segents between centers and data points\n",
    "init_parameters = torch.clone(parameters_of_geodesics) # save initial segments\n",
    "# Set optimizer params\n",
    "parameters = torch.nn.Parameter(parameters_of_geodesics) # Wrap as a parameter\n",
    "\n",
    "optimizer = torch.optim.SGD([parameters], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_on_geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points=[encoded_points, centers])\n",
    "ricci_regularization.plot_octopus(points_on_geodesics.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopping criterium e.g. delta of energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer loop \n",
    "for iter_outer in range(num_iter_outer):\n",
    "    # Inner loop (refining geodesics)\n",
    "    for iter_inner in range(num_iter_inner):\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        # Compute the loss\n",
    "        loss_geodesics = compute_energy(parameters_of_geodesics=parameters, end_points=[encoded_points, new_centers],decoder=torus_ae.decoder_torus)\n",
    "        # Backpropagation: compute gradients\n",
    "        loss_geodesics.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        # Store the loss value\n",
    "        #loss_history.append(loss_geodesics.item())\n",
    "        # saving plots. NB! It slows down the training as it contains loops. It serves to make the video afterwards\n",
    "        #ricci_regularization.plot_octopus(points_on_geodesics,memberships=cluster_index_of_each_point,meaningful_geodesics=meaningful_geodesics, \n",
    "        #             saving_folder=shots_folder_adress, suffix=iter_outer*num_iter_inner + iter_inner,verbose=False)\n",
    "        #print(f\"Iteration #{iter_inner + 1}, loss: {loss_geodesics.item():.3f}\")    \n",
    "    # end inner loop\n",
    "\n",
    "    # compute a vector of length of all geodesics shape (N,K)\n",
    "    lengths_of_geodesics = compute_lengths(parameters_of_geodesics=parameters_of_geodesics, end_points=[encoded_points, new_centers],decoder=torus_ae.decoder_torus) \n",
    "    \n",
    "    # retrieve the class membership of each point by finding the closest cluster center shape (N)\n",
    "    cluster_index_of_each_point = torch.argmin(lengths_of_geodesics, dim=1) \n",
    "    \n",
    "    batch_indices = torch.arange(N)\n",
    "    points_on_geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points=[encoded_points, new_centers])\n",
    "\n",
    "    # pick only geodesics connecting points to cluster centers where the points are assigned shape (N,m,d)\n",
    "    meaningful_geodesics = points_on_geodesics[batch_indices, cluster_index_of_each_point, :, :].detach() \n",
    "\n",
    "    # v is the direction to move the cluster centers\n",
    "    v = meaningful_geodesics[:,-1,:] - meaningful_geodesics[:,-2,:]\n",
    "    v = v / v.norm(dim=1).unsqueeze(-1) # find the last segments of the geod shape (N,d)\n",
    "    \n",
    "    #---------------------------------------------------------------    \n",
    "    # Update cluster centers with weight beta:\n",
    "    #---------------------------------------------------------------\n",
    "    # Assuming cluster_index_of_each_point is a tensor of shape (N,) containing cluster indices\n",
    "    # and K is the number of clusters\n",
    "    # Expand cluster_index_of_each_point to index into v and lengths_of_geodesics\n",
    "    cluster_index_of_each_point_expanded = cluster_index_of_each_point.unsqueeze(-1).expand(-1, v.size(-1))\n",
    "    # Compute weighted Frechet mean gradient for each cluster\n",
    "    weighted_v = lengths_of_geodesics[:, 0].unsqueeze(-1) * v  # Shape: (N, d)\n",
    "\n",
    "    # Create a one-hot encoding of the cluster indices\n",
    "    one_hot_clusters = torch.nn.functional.one_hot(cluster_index_of_each_point, num_classes=K).float()  # Shape: (N, K)\n",
    "\n",
    "    # Compute the gradients for each cluster\n",
    "    Frechet_mean_gradient = one_hot_clusters.T @ weighted_v  # Shape: (K, d)\n",
    "    \"\"\"\n",
    "    # Initialize gradients accumulator for all clusters\n",
    "    Frechet_mean_gradient = torch.zeros((K, v.size(-1)), device=v.device)\n",
    "    # Accumulate Frechet mean gradients for each cluster using scatter_add\n",
    "    Frechet_mean_gradient.scatter_add_(0, cluster_index_of_each_point_expanded, weighted_v) #rewrite it with gather so that it is clearer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Update cluster centers\n",
    "    with torch.no_grad():\n",
    "        new_centers += - beta * Frechet_mean_gradient  # Update all centers simultaneously\n",
    "\n",
    "    # Compute average Frechet mean gradient norm\n",
    "    average_Frechet_mean_gradient_norm = (Frechet_mean_gradient.norm(dim=1).mean()).item()\n",
    "    # Append to norm history\n",
    "    norm_Frechet_mean_gradient_history.append(average_Frechet_mean_gradient_norm)\n",
    "\n",
    "    # saving the lengths of meaningful geodesics\n",
    "    meaningful_geodesics_lengths = torch.gather(lengths_of_geodesics,1,cluster_index_of_each_point_expanded)[:,0]\n",
    "    meaningful_geodesics_loss_history.append( meaningful_geodesics_lengths.detach().sum().item() )\n",
    "\n",
    "    #compute the sum of geodesic length for each cluster\n",
    "    total_length_of_meaningful_geodesics_by_cluster = torch.zeros(K, dtype=meaningful_geodesics_lengths.dtype)\n",
    "    total_length_of_meaningful_geodesics_by_cluster.scatter_add_(0, cluster_index_of_each_point, meaningful_geodesics_lengths)    \n",
    "    meaningful_geodesics_loss_history_by_cluster.append(total_length_of_meaningful_geodesics_by_cluster.unsqueeze(0))\n",
    "    \"\"\"\n",
    "    # use gather instead of masks and the loop\n",
    "    for i in range(K):\n",
    "        average_Frechet_mean_gradient_norm = 0.\n",
    "        cluster_mask = cluster_index_of_each_point == i \n",
    "        v_i = v[cluster_mask] \n",
    "        l_i = lengths_of_geodesics[cluster_mask][:,0]\n",
    "        with torch.no_grad():\n",
    "            FM_gradient = torch.sum( l_i.unsqueeze(-1) * v_i, dim=0 )\n",
    "            new_centers[i] += - beta * FM_gradient # update i-th cluster center ( only moving the very last point on a geodesic)\n",
    "            #print(f\"\\nNorm of gradient of Frechet mean lossfor {i}-th cluster\", FM_gradient.norm().item())\n",
    "        average_Frechet_mean_gradient_norm += FM_gradient.norm().item()/K\n",
    "        # !save all of cluster Frechet mean gradients seperately\n",
    "    norm_Frechet_mean_gradient_history.append(average_Frechet_mean_gradient_norm)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do\n",
    "# two curves one plot\n",
    "# 1. meaningful geodesics lenght for cluster 1\n",
    "# 2. meaningful geodesics lenght for cluster 2\n",
    "# all meaningful geodesics\n",
    "# !!! add the plot of conditional variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming norm_Frechet_mean_gradient_history, meaningful_geodesics_loss_history, loss_history are arrays or tensors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(K*5, 5))  # Create a figure with 1 row and 3 columns\n",
    "\n",
    "# Plot norm_Frechet_mean_gradient_history\n",
    "axes[0].plot(norm_Frechet_mean_gradient_history, marker='o', markersize=3, label='Frechet mean update history')\n",
    "axes[0].set_title('Averege shift of centers (proxy of Fréchet mean gradient norm)')\n",
    "axes[0].set_xlabel('Outer loop iterations')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot meaningful geodesic lengths by cluster\n",
    "# Generate a color palette with distinct colors\n",
    "colors = plt.cm.jet(torch.linspace(0, 1, K))  # Use a colormap (e.g., 'viridis')\n",
    "\n",
    "lengths_of_meaningful_geodesics_concatenated = torch.cat((meaningful_geodesics_loss_history_by_cluster), dim=0).detach()\n",
    "for i in range(K):\n",
    "    axes[1].plot(lengths_of_meaningful_geodesics_concatenated[:, i],marker='o',markersize=3,\n",
    "                 label=f'Cluster {i} geodesics length', color=colors[i])\n",
    "    axes[1].set_title('Meaningful geodesics length by cluster')\n",
    "    axes[1].set_xlabel('Outer Loop Iterations')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "# Plot meaningful_geodesics_loss_history\n",
    "axes[1].plot(meaningful_geodesics_loss_history, marker='o', markersize=3, label='All clusters geodesics length', color='green')\n",
    "axes[1].set_title('Meaningfull geodesics length')\n",
    "axes[1].set_xlabel('Outer loop iterations')\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesics = geodesics_from_parameters_interpolation_points(parameters_of_geodesics, end_points=[encoded_points, new_centers])\n",
    "ricci_regularization.plot_octopus(geodesics.detach(), memberships=cluster_index_of_each_point,meaningful_geodesics=meaningful_geodesics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"center shifts:\\n\", (centers -  new_centers))\n",
    "average_cluster_center_shift_norm = (new_centers - centers).detach().norm(dim = 1).mean()\n",
    "print(\"Average center's shift:\", average_cluster_center_shift_norm.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop here\n",
    "raise Exception(\"Stopping point: Review output before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory containing PNGs and the output video name\n",
    "images_folder = shots_folder_adress\n",
    "output_video = \"output_video.avi\"\n",
    "\n",
    "# Set video parameters\n",
    "frame_rate = 30\n",
    "images = sorted([img for img in os.listdir(images_folder) if img.endswith(\".png\")])\n",
    "if not images:\n",
    "    raise ValueError(\"No PNG images found in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the first image to get dimensions\n",
    "first_image_path = os.path.join(images_folder, images[0])\n",
    "frame = cv2.imread(first_image_path)\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can use other codecs like 'mp4v'\n",
    "video = cv2.VideoWriter(output_video, fourcc, frame_rate, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    img_path = os.path.join(images_folder, image)\n",
    "    frame = cv2.imread(img_path)\n",
    "    video.write(frame)\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Video saved as {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recentering local charts (to be done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_centers = torch.tensor([[ 2., -2.5]])\n",
    "#        [-2.5458,  2.2106],\n",
    "#        [-1.0967,  2.2219]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_segments = ricci_regularization.connect_centers2encoded_data_with_segments(encoded_points, centers=new_centers, num_aux_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.plot_octopus(segments=new_segments)#, xlim=None, ylim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_updated_segments(segments):\n",
    "    # recognize the shape of segments:\n",
    "    N = segments.shape[0] # num data points\n",
    "    K = segments.shape[1] # num clusters\n",
    "    m = segments.shape[2] # num auxilliary points\n",
    "    d = segments.shape[3] # latent dimension\n",
    "    updated_segments = segments.clone()\n",
    "    # adapting segments to their local charts\n",
    "    for i in range(N): # this is very bad! REDO with a mask\n",
    "        for j in range(K):\n",
    "            for dim in range(d):\n",
    "                if torch.abs( segments[i,j,-1,dim] - segments[i,j,0,dim] ) > torch.pi:\n",
    "                    # choose direction of the point shift\n",
    "                    sign = torch.sgn( segments[i,j,-1,dim] - segments[i,j,0,dim] )\n",
    "                    shift = sign * 2 * torch.pi\n",
    "                    # shift the point \n",
    "                    updated_segments[i,j,0,dim] += shift\n",
    "    # Generate interpolation parameters (m values between 0 and 1)\n",
    "    t = torch.linspace(0, 1, steps=m).to(encoded_points.device).view(1, 1, m, 1)  # Shape: (1, 1, m, 1)\n",
    "\n",
    "    new_centers = segments[:,:,-1,:]\n",
    "    # Reshape encoded_points and centers for broadcasting\n",
    "    new_start_points = updated_segments[:,0,0,:].unsqueeze(1).unsqueeze(2)   # Shape: (n, 1, 1, d)\n",
    "    centers_expanded = new_centers.unsqueeze(2)        # Shape: (1, k, 1, d)\n",
    "\n",
    "    # Compute all intermediate points using linear interpolation\n",
    "    updated_segments = new_start_points + t * (centers_expanded - new_start_points)  # Shape: (n, k, m, d)\n",
    "    return updated_segments\n",
    "def mod_pi(segments): # only for plotting, local chart quiting has to be fixed\n",
    "    # Returns the coordinates of points in the initial local chart\n",
    "    return torch.remainder(segments + torch.pi, 2*torch.pi) - torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_segments = compute_updated_segments(new_segments).detach()\n",
    "#updated_segments_mod_pi = mod_pi(updated_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(new_segments[:,:,0,0], new_segments[:,:,0,1], c = 'green',zorder = 10, label = \"before shift\")\n",
    "plt.scatter(updated_segments[:,:,0,0], updated_segments[:,:,0,1], c = 'magenta', s = 100, label = \"after shift\")\n",
    "# add an arrow from not upd to upd segments\n",
    "plt.xlim(-2*torch.pi, 2*torch.pi)\n",
    "plt.ylim(-2*torch.pi, 2*torch.pi)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.plot_octopus(new_segments, xlim=2*torch.pi,ylim=2*torch.pi)\n",
    "# add the grid plotting option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricci_regularization.plot_octopus(updated_segments,xlim=2*torch.pi, ylim=2*torch.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_energy(new_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_energy(updated_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ricci_regularization.plot_octopus(updated_segments_mod_pi,xlim= torch.pi, ylim=torch.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_energy(updated_segments_mod_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_array = [ -2 * torch.pi, 0., 2 * torch.pi]\n",
    "segments_array = []\n",
    "for shift_x in shift_array:\n",
    "    for shift_y in shift_array:\n",
    "        segments_array.append(updated_segments + shift_x * torch.tensor([1.,0.]) + shift_y * torch.tensor([0.,1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segments in segments_array:\n",
    "    for i in range(N):\n",
    "            for j in range(K):\n",
    "                #if j == 0:\n",
    "                #    color = \"blue\"\n",
    "                #else:\n",
    "                color = \"orange\"\n",
    "                plt.plot(segments[i,j,:,0], segments[i,j,:,1],'-',marker='o', c = color, markersize=3)\n",
    "        # plot centers\n",
    "    centers = segments[0,:,-1,:]\n",
    "    # plot the datapoints (the starting points on all the geodesics, colored by memberships if specified):\n",
    "    plt.scatter(centers[:,0], centers[:,1], c=\"red\", label = \"centers\", marker='*', edgecolor='black', s = 170,zorder = 10)\n",
    "    plt.scatter(segments[:,0,0,0], segments[:,0,0,1], c=\"green\", label = \"centers\", marker='o', s = 30,zorder = 10)\n",
    "plt.xlim(-torch.pi, torch.pi)\n",
    "plt.ylim(-torch.pi, torch.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
