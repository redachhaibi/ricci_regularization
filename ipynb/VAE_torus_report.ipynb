{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook builds a report for pretrained torus AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_number = 0\n",
    "experiment_name = \"MNIST_torus_AE\"\n",
    "violent_saving = True # if False it will not save plots\n",
    "build_report = True\n",
    "Path_experiments = \"/home/alazarev/CodeProjects/Experiments/\"\n",
    "Path_pictures = f\"/home/alazarev/CodeProjects/Experiments/{experiment_name}/experiment{experiment_number}\"\n",
    "if os.path.exists(Path_pictures) == False:\n",
    "    os.mkdir(Path_pictures) # needs to be commented once the folder for plots is created\n",
    "\n",
    "# Hyperparameters for dataset\n",
    "D = 784       #dimension\n",
    "d = 2         # latent space dimension\n",
    "k = 3         # num of 2d planes in dim D\n",
    "n = 6*(10**3) # num of points in each plane\n",
    "shift_class = 0.0\n",
    "var_class = 1.0\n",
    "intercl_var = 0.1 # this has to be greater than 0.04\n",
    "# this creates a gaussian, \n",
    "# i.e.random shift \n",
    "# proportional to the value of intercl_var\n",
    "# Dimension of latent variables\n",
    "\n",
    "# Number of workers in DataLoader\n",
    "num_workers = 10\n",
    "sr_noise = 1e-6\n",
    "sr_numpoints = 18000 #k*n\n",
    "\n",
    "Z_DIM = d\n",
    "split_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfkit\n",
    "import json\n",
    "with open(f'{Path_experiments}json_files/hyperparameters_exp{experiment_number}.json') as json_file:\n",
    "    hyperparameters = json.load(json_file)\n",
    "    del hyperparameters['Path_pictures'], hyperparameters['Path_weights']\n",
    "pdfkit.from_string(json.dumps(hyperparameters),output_path=f\"{Path_pictures}/hyperparameters_exp{experiment_number}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_name = hyperparameters[\"set_name\"]\n",
    "batch_size = hyperparameters[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization as RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_name == \"MNIST\":\n",
    "    #MNIST_SIZE = 28\n",
    "    # MNIST Dataset\n",
    "    train_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    #train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    #test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "elif set_name == \"Synthetic\":\n",
    "    # Generate dataset\n",
    "    # via classes\n",
    "    torch.manual_seed(0) # reproducibility\n",
    "    my_dataset = RR.SyntheticDataset(k=k,n=n,d=d,D=D,\n",
    "                                        shift_class=shift_class, intercl_var=intercl_var, var_class=var_class)\n",
    "\n",
    "    train_dataset = my_dataset.create\n",
    "elif set_name == \"Swissroll\":\n",
    "    D = 3\n",
    "    train_dataset =  sklearn.datasets.make_swiss_roll(n_samples=sr_numpoints, noise=sr_noise)\n",
    "    sr_points = torch.from_numpy(train_dataset[0]).to(torch.float32)\n",
    "    #sr_points = torch.cat((sr_points,torch.zeros(sr_numpoints,D-3)),dim=1)\n",
    "    sr_colors = torch.from_numpy(train_dataset[1]).to(torch.float32)\n",
    "    from torch.utils.data import TensorDataset\n",
    "    train_dataset = TensorDataset(sr_points,sr_colors)\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [int(m-m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        # Non-linearity\n",
    "        self.non_linearity = torch.sin\n",
    "        self.non_linearity2 = torch.cos # should this not be vice versa??\n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc3 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        # Double dimension as circle is mimicked using sin and cos charts\n",
    "        self.fc4 = nn.Linear(2*z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        # Concatenate sin and cos non-linearities\n",
    "        # Warning: Done along dimension 1, as dimension 0 is the batch dimension\n",
    "        #h = torch.cat( (self.non_linearity(h), self.non_linearity2(h)), 1)\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1)\n",
    "        return h # Latent variable z, Wannabe uniform on the circle\n",
    "    def encoder2lifting(self, x):\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        # Concatenate sin and cos non-linearities\n",
    "        # Warning: Done along dimension 1, as dimension 0 is the batch dimension\n",
    "        #h = torch.cat( (self.non_linearity(h), self.non_linearity2(h)), 1)\n",
    "        # cosphi,sinphi\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1) \n",
    "        cosphi = h[:, 0:Z_DIM]\n",
    "        sinphi = h[:, Z_DIM:2*Z_DIM]\n",
    "        phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "        return phi\n",
    "    def encoder_torus(self, x):   \n",
    "        #This is a mapping to a feature space so it would be wrong to use it\n",
    "        h = self.non_linearity(self.fc1(x))\n",
    "        h = self.non_linearity(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        return h\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        #h = self.non_linearity( math.pi*z + self.decoderBias ) # Expects 2pi periodic non-linearity to create torus topology\n",
    "        h = z\n",
    "        h = self.non_linearity( self.fc4(h))\n",
    "        h = self.non_linearity( self.fc5(h))\n",
    "        return self.non_linearity( self.fc6(h) )\n",
    "    def decoder_torus(self, z):\n",
    "        h = z\n",
    "        h = torch.cat( (self.non_linearity2(h), self.non_linearity(h)), 1)\n",
    "        h = self.non_linearity( self.fc4(h))\n",
    "        h = self.non_linearity( self.fc5(h))\n",
    "        return self.non_linearity( self.fc6(h) )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x.view(-1, D))\n",
    "        return self.decoder(z), z\n",
    "\n",
    "# old model\n",
    "vae = VAE(x_dim=D, h_dim1= 512, h_dim2=256, z_dim=Z_DIM)\n",
    "#changed model\n",
    "#vae = VAE(x_dim=D, h_dim1= 3, h_dim2=2, z_dim=Z_DIM)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_vae = f'../nn_weights/exp{experiment_number}.pt'\n",
    "vae.load_state_dict(torch.load(PATH_vae))\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#inspiration for vae.encoder2lifting\n",
    "def circle2anglevectorized(zLatentTensor,Z_DIM = Z_DIM):\n",
    "    cosphi = zLatentTensor[:, 0:Z_DIM]\n",
    "    sinphi = zLatentTensor[:, Z_DIM:2*Z_DIM]\n",
    "    phi = torch.acos(cosphi)*torch.sgn(torch.asin(sinphi))\n",
    "    return phi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "if set_name == \"Synthetic\":\n",
    "    N = k\n",
    "elif set_name == \"MNIST\":\n",
    "    N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zlist = []\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "#for (data, labels) in train_loader:\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(vae(data)[0])\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(vae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()\n",
    "#assert torch.equal(enc,enc_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#angleLatentviatorch = circle2anglevectorized(zLatent_tensor)/math.pi\n",
    "#plt.scatter(angleLatentviatorch[:,0],angleLatentviatorch[:,1], c=labels, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784).to(dtype = torch.float32)).detach()\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784)/256).detach() # this works!!!\n",
    "#enc = vae.encoder2lifting(train_dataset.data.reshape(-1,784)/256).detach()\n",
    "#enc = vae.encoder_torus(train_dataset.data.reshape(-1,784)/256).detach()\n",
    "#plt.scatter(enc[:,0],enc[:,1], c=train_dataset.targets, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.colorbar(ticks=range(N))\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{Path_pictures}/latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_error_tensor = input_dataset.view(-1,D) - recon_dataset\n",
    "mse_array = abs_error_tensor.norm(dim=1).detach()\n",
    "mse_array = mse_array**2/D\n",
    "#F.mse_loss(input_dataset.view(-1,D)[0],recon_dataset[0],reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric losses computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curvature_array = RR.Sc_jacfwd_vmap(encoded_points,function=vae.decoder_torus).detach()\n",
    "metric_array = RR.metric_jacfwd_vmap(encoded_points,function=vae.decoder_torus).detach()\n",
    "det_array = torch.det(metric_array)\n",
    "trace_array = torch.einsum('jii->j',metric_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = encoded_points_no_grad\n",
    "left = latent[:,0].min()\n",
    "right = latent[:,0].max()\n",
    "bottom = latent[:,1].min()\n",
    "top = latent[:,1].max()\n",
    "\n",
    "xsize = right - left\n",
    "ysize = top - bottom\n",
    "xcenter = 0.5*(left + right)\n",
    "ycenter = 0.5*(bottom + top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linsize = 200\n",
    "\n",
    "import torch.func as TF\n",
    "grid_on_ls = RR.make_grid(linsize,xsize=xsize,ysize=ysize,xcenter=xcenter,ycenter=ycenter)\n",
    "metric_on_grid = RR.metric_jacfwd_vmap(grid_on_ls,function=vae.decoder_torus)\n",
    "metric_det_on_grid = torch.det(metric_on_grid)\n",
    "metric_trace_on_grid = TF.vmap(torch.trace)(metric_on_grid)\n",
    "curv_on_the_grid = RR.Sc_jacfwd_vmap(grid_on_ls, function = vae.decoder_torus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recon loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(encoder,decoder,n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_dataset.targets.numpy()\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_dataset[t_idx[i]][0].unsqueeze(0)\n",
    "      #encoder.eval()\n",
    "      #decoder.eval()\n",
    "      with torch.no_grad():\n",
    "         #rec_img  = decoder(encoder(img))\n",
    "         rec_img  = decoder(encoder(img.reshape(1,D))).reshape(1,28,28)\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ae_outputs(vae.encoder2lifting,vae.decoder_torus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import ticker\n",
    "\n",
    "# (generate plot here)\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "size_of_points = 20\n",
    "fig, (ax00,ax0)= plt.subplots(ncols=2, nrows=1,figsize=(15,6),dpi=300)\n",
    "# (ax3,ax4) can  be added\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax00.title.set_text(\"AE latent space\")\n",
    "if set_name == \"Synthetic\" or set_name == \"MNIST\":\n",
    "    p00 = ax00.scatter( encoded_points_no_grad[:,0], encoded_points_no_grad[:,1], c=color_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap=discrete_cmap(N, \"jet\"))\n",
    "    fig.colorbar(p00,label=\"initial color\", ticks=(np.arange(N)))    \n",
    "else:\n",
    "    p00 = ax00.scatter( encoded_points[:,0], encoded_points[:,1], c=labels, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet')\n",
    "    fig.colorbar(p00,label=\"initial color\")\n",
    "\n",
    "ax0.title.set_text(\"Reconstruction loss\")\n",
    "p0 = ax0.scatter( encoded_points_no_grad[:,0], encoded_points_no_grad[:,1], c=mse_array, alpha=0.5, s = size_of_points, marker='o', edgecolor='none', cmap='jet')#,norm=matplotlib.colors.LogNorm())\n",
    "cb = fig.colorbar(p0,label=\"squared l2 norm errors\")\n",
    "tick_locator = ticker.MaxNLocator(nbins=10)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "\n",
    "if violent_saving == True:\n",
    "    fig.savefig(f'{Path_pictures}/init_colors_recon_loss.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.scatter(torch.rand(5),torch.rand(5),c = torch.rand(5),norm=matplotlib.colors.LogNorm())\n",
    "cb = plt.colorbar(p)\n",
    "tick_locator = ticker.MaxNLocator(nbins=5)\n",
    "cb.locator = tick_locator\n",
    "cb.update_ticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curvature_array, bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(curv_on_the_grid.detach(), bins = 200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xcenter = 0.0 \n",
    "#ycenter = 0.0\n",
    "xshift = 0.0\n",
    "yshift = 0.0\n",
    "numticks = 5\n",
    "if set_name == \"Synthetic\":\n",
    "    tick_decimals = 2\n",
    "else:\n",
    "    tick_decimals = 1\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels ]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "im1 = ax1.imshow(abs(curv_on_the_grid.detach().reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm())\n",
    "fig.colorbar(im1,ax = ax1, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "im2 = ax2.imshow(curv_on_the_grid.detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=abs(0.01*curv_on_the_grid.mean()).item()))\n",
    "fig.colorbar(im2,ax = ax2, shrink = 1, label = \"curvature\")\n",
    "ax2.set_title(\"Scalar curvature\")\n",
    "\n",
    "im3 = ax3.imshow((torch.sqrt(metric_det_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax1, ax2, ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/heatmaps_not_scaled.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scalar curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_curvature = curv_on_the_grid.max().item()\n",
    "min_curvature = curv_on_the_grid.min().item()\n",
    "linthresh_curvature = 0.01*abs(curv_on_the_grid.mean()).item()\n",
    "linthresh_curvature\n",
    "\n",
    "max_abs_curvature = abs(curv_on_the_grid).max().item()\n",
    "min_abs_curvature = 0.01*abs(curv_on_the_grid).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(ncols=2, nrows=2, figsize=(15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "xticks = np.linspace(xcenter - 0.5*xsize, xcenter + 0.5*xsize, numticks) \n",
    "yticks = np.linspace(ycenter - 0.5*ysize, ycenter + 0.5*ysize, numticks)\n",
    "\n",
    "xtick_labels = (xticks+xshift).tolist()\n",
    "ytick_labels = (yticks+yshift).tolist()\n",
    "\n",
    "xtick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in xtick_labels]\n",
    "ytick_labels = [ '%.{0}f'.format(tick_decimals) % elem for elem in ytick_labels]\n",
    "\n",
    "ticks_places = np.linspace(0, 1, numticks)*(linsize-1)\n",
    "\n",
    "\n",
    "ax1.title.set_text(\"Absolute value of scalar curvature\")\n",
    "p1 = ax1.scatter( latent[:,0], latent[:,1], c=abs(curvature_array), \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                vmax = max_abs_curvature))\n",
    "fig.colorbar(p1,label=\"curvature abs value\")\n",
    "\n",
    "ax2.title.set_text(\"Absolute value of scalar curvature overall\")\n",
    "im1 = ax2.imshow(abs(curv_on_the_grid.detach().reshape(linsize,linsize)),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.LogNorm(vmin = min_abs_curvature, \n",
    "                                                  vmax = max_abs_curvature))\n",
    "fig.colorbar(im1,ax = ax2, shrink = 1, label = \"curvature abs value\")\n",
    "ax1.set_title(\"Absolute value of scalar curvature\")\n",
    "\n",
    "ax3.title.set_text(\"Scalar curvature\")\n",
    "p2 = ax3.scatter( latent[:,0], latent[:,1], c=curvature_array, \n",
    "                 alpha=1, s = size_of_points, marker='o', \n",
    "                 edgecolor='none', cmap='jet',\n",
    "                 norm=matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(p2,label=\"curvature\")\n",
    "\n",
    "ax4.title.set_text(\"Scalar curvature overall\")\n",
    "im2 = ax4.imshow(curv_on_the_grid.detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",\n",
    "                 norm = matplotlib.colors.SymLogNorm(linthresh=linthresh_curvature,\n",
    "                                                   vmin = min_curvature, \n",
    "                                                   vmax = max_curvature))\n",
    "fig.colorbar(im2,ax = ax4, shrink = 1, label = \"curvature\")\n",
    "ax4.set_title(\"Scalar curvature overall\")\n",
    "\n",
    "axs = (ax1, ax3)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "axs = (ax2, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f'{Path_pictures}/curvature_heatmaps.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax3),(ax2,ax4))= plt.subplots(ncols=2,nrows=2,figsize = (15,12),dpi=300)\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "\n",
    "ax1.title.set_text(\"$\\sqrt{det(G)}$\")\n",
    "p = ax1.scatter( latent[:,0], latent[:,1],\n",
    "                c=torch.sqrt(abs(det_array)), alpha=1, s = size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=metric_det_on_grid.max().sqrt().item())\n",
    "fig.colorbar(p,label=\"$\\sqrt{det(G)}$\")\n",
    "ax2.title.set_text(\"0.5$\\cdot$tr(G)\")\n",
    "q = ax2.scatter( latent[:,0], latent[:,1], \n",
    "                c=0.5*(trace_array), alpha=1, s= size_of_points, \n",
    "                marker='o', edgecolor='none', cmap='jet',\n",
    "                vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(q,label=\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "im3 = ax3.imshow((torch.sqrt(metric_det_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None)\n",
    "fig.colorbar(im3,ax = ax3, shrink = 1, label = \"$\\sqrt{det(G)}$\")\n",
    "ax3.set_title(\"$\\sqrt{det(G)}$\")\n",
    "\n",
    "im4 = ax4.imshow((0.5*(metric_trace_on_grid)).detach().reshape(linsize,linsize),\n",
    "                 origin=\"lower\",cmap=\"jet\",norm = None,\n",
    "                 vmax=0.5*metric_trace_on_grid.max().item())\n",
    "fig.colorbar(im4, ax = ax4, shrink = 1, label = \"0.5$\\cdot$tr(G)\")\n",
    "ax4.set_title(\"0.5$\\cdot$tr(G)\")\n",
    "\n",
    "axs = (ax3, ax4)\n",
    "for ax in axs:\n",
    "    ax.set_xticks(ticks_places,labels = xtick_labels)\n",
    "    ax.set_yticks(ticks_places,labels = ytick_labels)\n",
    "\n",
    "axs = (ax1, ax2)\n",
    "for ax in axs:\n",
    "    ax.set_ylim(bottom,top)\n",
    "    ax.set_xlim(left,right)\n",
    "    ax.set_xticks(list(map(float, xtick_labels)), labels = xtick_labels)\n",
    "    ax.set_yticks(list(map(float, ytick_labels)), labels = ytick_labels)\n",
    "\n",
    "if violent_saving == True:\n",
    "    #plt.savefig(f'{Path_pictures}/metric_det_trace.eps',bbox_inches='tight',format='eps')\n",
    "    plt.savefig(f'{Path_pictures}/metric_det_trace.pdf',bbox_inches='tight',format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_report = True\n",
    "#experiment_number = 1\n",
    "#Path_pictures = f\"/home/alazarev/CodeProjects/Experiments/{experiment_name}/experiment{experiment_number}\"\n",
    "if build_report == True:\n",
    "    pdfs = [f\"{Path_pictures}/hyperparameters_exp{experiment_number}.pdf\",f'{Path_pictures}/losses_exp{experiment_number}.pdf',f'{Path_pictures}/init_colors_recon_loss.pdf', f'{Path_pictures}/curvature_heatmaps.pdf', f'{Path_pictures}/metric_det_trace.pdf']\n",
    "    #pdfs = [f'{Path_pictures}/losses.pdf', f'{Path_pictures}/9losses.pdf', f'{Path_pictures}/init_colors_recon_loss.pdf', f'{Path_pictures}/curvature_heatmaps.pdf', f'{Path_pictures}/metric_det_trace.pdf']\n",
    "\n",
    "    merger = PdfMerger()\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        merger.append(pdf)\n",
    "\n",
    "    merger.write(f\"{Path_pictures}/report_{experiment_name}_exp_{experiment_number}.pdf\")\n",
    "    merger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
