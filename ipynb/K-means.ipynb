{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Geomstats package is required.\n",
    "\n",
    "The latent space of the AE is topologically a $d-$ dimensional torus $\\mathcal{T}^d$, i.e. it can be considered as a periodic box $[-\\pi, \\pi]^d$. \n",
    "\n",
    "The notebook includes 3 K-means clustering applications.\n",
    "1) For input data (uses skit.learn K-means see https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "2) For output data of the AE (also uses skit.learn K-means)\n",
    "3) The torus latent space of the AE with Euclidean metric (uses geomstats package, see https://geomstats.github.io/notebooks/07_practical_methods__riemannian_kmeans.html#)\n",
    "\n",
    "In this notebook data is the part of MNIST dataset with 2 selected labels (5 and 8).\n",
    "\n",
    "F-scores (see https://en.wikipedia.org/wiki/F-score) of clusterizations vs ground truth labels are comuted. The efficiency of clusterization are computed.\n",
    "\n",
    "The contents of the notebook are:\n",
    "\n",
    "1) Setting hyperparameters, dataset loading, plotting embedded data for a pre-trained AE.\n",
    "2) Geomstats K-means: Euclidean metric on torus latent space\n",
    "3) K-means in input data space\n",
    "4) K-means in a output data space\n",
    "5) F-scores comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting hyperparameters, dataset loading, plotting embedded data for a pre-trained AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json file name\n",
    "experiment_json = f'../experiments/MNIST01_torus_AEexp8.json'\n",
    "\n",
    "violent_saving = True # if False it will not save plots\n",
    "build_report = True\n",
    "\n",
    "# Loading JSON file\n",
    "import json\n",
    "with open(experiment_json) as json_file:\n",
    "    json_config = json.load(json_file)\n",
    "\n",
    "print( json.dumps(json_config, indent=2 ) )\n",
    "\n",
    "Path_experiments = json_config[\"Path_experiments\"]\n",
    "experiment_name = json_config[\"experiment_name\"]\n",
    "experiment_number = json_config[\"experiment_number\"]\n",
    "Path_pictures = json_config[\"Path_pictures\"]\n",
    "\n",
    "# # Number of workers in DataLoader\n",
    "# num_workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name    = json_config[\"dataset\"][\"name\"]\n",
    "split_ratio = json_config[\"optimization_parameters\"][\"split_ratio\"]\n",
    "batch_size  = json_config[\"optimization_parameters\"][\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset uploading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('../') # have to go 1 level up\n",
    "import ricci_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"MNIST\":\n",
    "    #MNIST_SIZE = 28\n",
    "    # MNIST Dataset\n",
    "    D = 784\n",
    "    train_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "elif dataset_name == \"MNIST01\":\n",
    "    D = 784\n",
    "    full_mnist_dataset = datasets.MNIST(root='../datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset  = datasets.MNIST(root='../datasets/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "    mask = (full_mnist_dataset.targets == -1) \n",
    "    selected_labels = json_config[\"dataset\"][\"selected_labels\"]\n",
    "    for label in selected_labels:\n",
    "        mask = mask | (full_mnist_dataset.targets == label)\n",
    "    indices01 = torch.where(mask)[0]\n",
    "    \n",
    "    from torch.utils.data import Subset\n",
    "    train_dataset = Subset(full_mnist_dataset, indices01) # MNIST only with 0,1 indices\n",
    "\n",
    "m = len(train_dataset)\n",
    "train_data, test_data = torch.utils.data.random_split(train_dataset, [m-int(m*split_ratio), int(m*split_ratio)])\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(test_data , batch_size=batch_size)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = json_config[\"architecture\"][\"latent_dim\"]\n",
    "input_dim  = json_config[\"architecture\"][\"input_dim\"]\n",
    "architecture_type = json_config[\"architecture\"][\"name\"]\n",
    "\n",
    "if architecture_type== \"TorusAE\":\n",
    "    torus_ae   = ricci_regularization.Architectures.TorusAE(x_dim=input_dim, h_dim1= 512, h_dim2=256, z_dim=latent_dim)\n",
    "elif architecture_type ==\"TorusConvAE\":\n",
    "    torus_ae   = ricci_regularization.Architectures.TorusConvAE(x_dim=input_dim, h_dim1= 512, h_dim2=256, z_dim=latent_dim,pixels=28)\n",
    "if torch.cuda.is_available():\n",
    "    torus_ae.cuda()\n",
    "else:\n",
    "    torus_ae.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO! Use the path ../experiments/<Your experiment>/nn_weights/\n",
    "PATH_ae_wights = json_config[\"weights_saved_at\"]\n",
    "torus_ae.load_state_dict(torch.load(PATH_ae_wights))\n",
    "torus_ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "N = json_config[\"dataset\"][\"parameters\"][\"k\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zlist = []\n",
    "torus_ae.cpu()\n",
    "colorlist = []\n",
    "enc_list = []\n",
    "feature_space_encoding_list = []\n",
    "input_dataset_list = []\n",
    "recon_dataset_list = []\n",
    "for (data, labels) in tqdm( test_loader, position=0 ):\n",
    "#for (data, labels) in tqdm( train_loader, position=0 ):\n",
    "    input_dataset_list.append(data)\n",
    "    recon_dataset_list.append(torus_ae(data)[0])\n",
    "    feature_space_encoding_list.append(torus_ae.encoder_torus(data.view(-1,D)))\n",
    "    #zlist.append(vae(data)[1])\n",
    "    enc_list.append(torus_ae.encoder2lifting(data.view(-1,D)))\n",
    "    colorlist.append(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.cat(zlist)\n",
    "#enc = circle2anglevectorized(x).detach()\n",
    "input_dataset = torch.cat(input_dataset_list)\n",
    "recon_dataset = torch.cat(recon_dataset_list)\n",
    "encoded_points = torch.cat(enc_list)\n",
    "feature_space_encoding = torch.cat(feature_space_encoding_list)\n",
    "encoded_points_no_grad = encoded_points.detach()\n",
    "color_array = torch.cat(colorlist).detach()\n",
    "#assert torch.equal(enc,enc_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"Latent space colored by ground truth labels\")\n",
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=color_array, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.colorbar(ticks=range(N))\n",
    "plt.grid(True)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f\"{Path_pictures}/latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Geomstats K-means: Euclidean metric on torus latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this adds an environmental variable\n",
    "#%env GEOMSTATS_BACKEND=pytorch\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.visualization as visualization\n",
    "from geomstats.geometry.hypersphere import Hypersphere\n",
    "from geomstats.learning.kmeans import RiemannianKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circumference1 = Hypersphere(dim=1)\n",
    "circumference2 = Hypersphere(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building torus as a product $\\mathcal{T} = \\mathcal{S}^1 \\times \\mathcal{S}^1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geomstats.geometry.product_manifold import ProductManifold\n",
    "torus = ProductManifold((circumference1,circumference2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading saved points and labels and plotting ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_angles = encoded_points_no_grad #torch.load(\"encoded_angles.pt\")\n",
    "gt_labels = color_array #torch.load(\"labels.pt\")\n",
    "#convert dt_labels into 0 and 1 array\n",
    "gt_labels = (gt_labels - min(gt_labels))/max((gt_labels - min(gt_labels))).to(torch.int)\n",
    "gt_labels = gt_labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting MNIST data on torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_1_coordinates = torus.factors[0].intrinsic_to_extrinsic_coords(encoded_angles[:,0]).reshape(2,-1).T\n",
    "circ_2_coordinates = torus.factors[1].intrinsic_to_extrinsic_coords(encoded_angles[:,1]).reshape(2,-1).T\n",
    "#print(\"1st\", circ_1_coordinates)\n",
    "#print(\"2nd\", circ_2_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_data_on_torus_4d = np.concatenate((circ_1_coordinates,circ_2_coordinates),axis = 1).reshape(-1,2,2) # cos\\phi, sin \\phi, cos \\psi, sin \\psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = RiemannianKMeans(torus, N, tol=1e-3)\n",
    "kmeans.fit(MNIST_data_on_torus_4d)\n",
    "kmeans_latent_space_euclidean_labels = kmeans.labels_\n",
    "cluster_centers = kmeans.centroids_# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(2,1,figsize=(8, 12))\n",
    "p1 = ax1.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=kmeans_latent_space_euclidean_labels, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.colorbar(p1,ticks=range(N))\n",
    "ax1.title.set_text(\"Latent space colored by K-means on Torus with Euclidean metric\")\n",
    "ax1.grid(True)\n",
    "\n",
    "correcltly_detected_labels = abs(kmeans_latent_space_euclidean_labels - gt_labels)\n",
    "if correcltly_detected_labels.sum() < len(gt_labels)//2:\n",
    "    correcltly_detected_labels = np.logical_not(correcltly_detected_labels)\n",
    "\n",
    "p2 = ax2.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=correcltly_detected_labels, marker='o', edgecolor='none', cmap=plt.cm.get_cmap(\"viridis\", N))\n",
    "cbar = plt.colorbar(p2,ticks=[0.25,0.75])\n",
    "cbar.ax.set_yticklabels([\"incorrect\",\"correct\"]) \n",
    "if violent_saving == True:\n",
    "    plt.savefig(f\"{Path_pictures}/Kmeans_latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-means in input data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_input_space = KMeans(n_clusters=N, random_state=0, n_init=\"auto\").fit(input_dataset.reshape(-1,D).detach())\n",
    "kmeans_input_space_labels = kmeans_input_space.labels_\n",
    "print(f\"k-means clusterisation to {N} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 6))\n",
    "fig,(ax1,ax2) = plt.subplots(2,1,figsize=(8, 12))\n",
    "p1 = ax1.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=kmeans_input_space_labels, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.colorbar(p1,ticks=range(N))\n",
    "ax1.title.set_text(f\"K-means clusterization on input data, K = {N}, \\n Euclidean metric in input space $R^D$\")\n",
    "ax1.grid(True)\n",
    "\n",
    "correcltly_detected_labels = abs(kmeans_input_space_labels - gt_labels)\n",
    "if correcltly_detected_labels.sum() < len(gt_labels)//2:\n",
    "    correcltly_detected_labels = np.logical_not(correcltly_detected_labels)\n",
    "\n",
    "p2 = ax2.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=correcltly_detected_labels, marker='o', edgecolor='none', cmap=plt.cm.get_cmap(\"viridis\", N))\n",
    "cbar = plt.colorbar(p2,ticks=[0.25,0.75])\n",
    "cbar.ax.set_yticklabels([\"incorrect\",\"correct\"]) \n",
    "ax1.title.set_text(f\"K-means clusterization on input data, K = {N}, \\n Euclidean metric in input space $R^D$\")\n",
    "ax1.grid(True)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f\"{Path_pictures}/Kmeans_input_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. K-means in a output data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_recon_space = KMeans(n_clusters=N, random_state=0, n_init=\"auto\").fit(recon_dataset.detach())\n",
    "kmeans_recon_space_labels = kmeans_recon_space.labels_\n",
    "print(f\"k-means clusterisation to {N} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(encoded_points_no_grad[:,0],encoded_points_no_grad[:,1], c=kmeans_recon_space_labels, marker='o', edgecolor='none', cmap=discrete_cmap(N, 'jet'))\n",
    "plt.colorbar(ticks=range(N))\n",
    "plt.title(f\"K-means clusterization on reconstructed data, K = {N}, \\n Euclidean metric in output space $R^D$\")\n",
    "plt.grid(True)\n",
    "if violent_saving == True:\n",
    "    plt.savefig(f\"{Path_pictures}/Kmeans_latent_space.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. F-score comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_latent_space_euclidean_permuted_labels = abs(kmeans_latent_space_euclidean_labels - 1)\n",
    "kmeans_recon_space_permuted_labels = abs(kmeans_recon_space_labels - 1)\n",
    "\n",
    "kmeans_input_space_permuted_labels = abs(kmeans_input_space_labels - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "F_score_latent_space_eucl = max(sklearn.metrics.f1_score(gt_labels,kmeans_latent_space_euclidean_labels),\n",
    "              sklearn.metrics.f1_score(gt_labels,kmeans_latent_space_euclidean_permuted_labels))\n",
    "\n",
    "F_score_input_space_eucl = max(sklearn.metrics.f1_score(gt_labels,kmeans_input_space_labels),\n",
    "              sklearn.metrics.f1_score(gt_labels,kmeans_input_space_permuted_labels))\n",
    "\n",
    "F_score_recon_space_eucl = max(sklearn.metrics.f1_score(gt_labels,kmeans_recon_space_labels),\n",
    "              sklearn.metrics.f1_score(gt_labels,kmeans_recon_space_permuted_labels))\n",
    "curv_w = json_config[\"losses\"][\"curv_w\"]\n",
    "print(f\"Curvature penalization weight: {curv_w}\")\n",
    "print(f\"F-score Euclidean k-means in latent space vs ground truth: \\n{F_score_latent_space_eucl}\")\n",
    "print(f\"F-score Euclidean k-means in input data space vs ground truth: \\n{F_score_input_space_eucl}\")\n",
    "print(f\"F-score Euclidean k-means in reconstructed data space vs ground truth: \\n{F_score_recon_space_eucl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\n",
    "    \"curv_w\" : curv_w,\n",
    "    \"labels\": selected_labels,\n",
    "    \"F-score Euclidean k-means in latent space vs ground truth\" : F_score_latent_space_eucl,\n",
    "    \"F-score Euclidean k-means in reconstructed data space vs ground truth\" : F_score_recon_space_eucl,\n",
    "    \"F-score Euclidean k-means in input data space vs ground truth\" : F_score_input_space_eucl\n",
    "}\n",
    "with open(f'{Path_pictures}/K-means_exp{experiment_number}.json', 'w') as json_file:\n",
    "    json.dump(dict, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ricci2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
